{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e8471e4-1f8a-40ce-a22f-6323aa614e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 7c94e57] Auto update (nb+data) - 2025-10-16 06:47:26\n",
      " 3 files changed, 1660 insertions(+), 1564 deletions(-)\n",
      "Current branch main is up to date.\n",
      "branch 'main' set up to track 'origin/main'.\n",
      "Pushed: PredictNHL.ipynb, enhanced_game_data.csv, predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import hashlib, shutil, subprocess, os\n",
    "from datetime import datetime\n",
    "\n",
    "REPO   = Path(r\"C:\\Users\\Nic\\Desktop\\NHLPredictor\")\n",
    "DESK   = Path(r\"C:\\Users\\Nic\\Desktop\")\n",
    "NBNAME = \"PredictNHL.ipynb\"\n",
    "EXTS   = {\".csv\", \".json\", \".xlsx\"}\n",
    "BRANCH = \"main\"\n",
    "\n",
    "# --- Force a CSV to \"update\" even if content is the same ---\n",
    "FORCE_REFRESH_CSV = True\n",
    "CSV_WHITELIST = []  # e.g. [\"predictions.csv\", \"enhanced_game_data.csv\"]; empty = all CSVs in repo\n",
    "\n",
    "def sha(p):\n",
    "    import hashlib\n",
    "    h=hashlib.sha256()\n",
    "    with p.open(\"rb\") as f:\n",
    "        for b in iter(lambda:f.read(1<<20), b\"\"): h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def bump_csv_bytes(path: Path):\n",
    "    \"\"\"Toggle trailing newline to force a harmless byte change.\"\"\"\n",
    "    b = path.read_bytes()\n",
    "    if b.endswith(b\"\\n\"):\n",
    "        path.write_bytes(b.rstrip(b\"\\n\"))      # remove last newline\n",
    "    else:\n",
    "        path.write_bytes(b + b\"\\n\")            # add last newline\n",
    "\n",
    "def run(cmd):\n",
    "    r = subprocess.run(cmd, cwd=str(REPO), capture_output=True, text=True)\n",
    "    if r.stdout: print(r.stdout.strip())\n",
    "    if r.stderr and r.returncode != 0: print(r.stderr.strip())\n",
    "    return r.returncode\n",
    "\n",
    "assert REPO.exists()\n",
    "os.chdir(REPO)\n",
    "\n",
    "# 1) Build targets: notebook + tracked csv/json/xlsx\n",
    "targets = {NBNAME}\n",
    "targets |= {p.name for p in REPO.iterdir() if p.is_file() and p.suffix.lower() in EXTS}\n",
    "\n",
    "# 2) Copy Desktop -> repo when content differs\n",
    "changed = []\n",
    "for name in sorted(targets):\n",
    "    src, dst = DESK/name, REPO/name\n",
    "    if src.exists():\n",
    "        if (not dst.exists()) or sha(src) != sha(dst):\n",
    "            shutil.copy2(src, dst); changed.append(name)\n",
    "\n",
    "# 3) Optionally force-refresh CSVs (toggle EOF newline)\n",
    "if FORCE_REFRESH_CSV:\n",
    "    csvs = [p for p in REPO.iterdir() if p.is_file() and p.suffix.lower()==\".csv\"]\n",
    "    if CSV_WHITELIST:\n",
    "        csvs = [p for p in csvs if p.name in CSV_WHITELIST]\n",
    "    for p in csvs:\n",
    "        # only bump if not already modified by step 2 (to avoid double-noise)\n",
    "        if p.name not in changed:\n",
    "            bump_csv_bytes(p); changed.append(p.name)\n",
    "\n",
    "# 4) Commit & push (only if something actually changed)\n",
    "if changed:\n",
    "    run([\"git\",\"add\"] + changed)\n",
    "    msg = f\"Auto update (nb+data) - {datetime.now():%Y-%m-%d %H:%M:%S}\"\n",
    "    run([\"git\",\"commit\",\"-m\", msg])\n",
    "    run([\"git\",\"pull\",\"--rebase\",\"origin\", BRANCH])\n",
    "    run([\"git\",\"push\",\"-u\",\"origin\", BRANCH])\n",
    "    print(\"Pushed:\", \", \".join(changed))\n",
    "else:\n",
    "    print(\"Nothing to update. (No content changes and force-refresh off or nothing matched.)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0af2c54-99e1-49ea-a78d-1509524b2587",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (2.18.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (70.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from xgboost) (2.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from xgboost) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (1.41.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (2.0.0)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (5.29.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.19.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (2.0.0)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (1.6.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (2.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (2.0.0)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (1.14.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install xgboost\n",
    "!pip install streamlit\n",
    "!pip install imbalanced-learn\n",
    "!pip install shap\n",
    "!pip install statsmodels\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e8701d-ae59-47be-acc0-320e91c564b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, TimeSeriesSplit, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score, brier_score_loss, accuracy_score, log_loss, classification_report, make_scorer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import mutual_info_classif, RFECV, SelectFromModel, SelectKBest\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import re\n",
    "from scipy.stats import loguniform, uniform\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "import unicodedata\n",
    "import os, joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a78d45-fb52-49b6-b4ea-0d46d29c6729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Team  Rank                 Team Rank\n",
      "0           Winnipeg Jets     1          Winnipeg Jets* 1\n",
      "1     Washington Capitals     2    Washington Capitals* 2\n",
      "2    Vegas Golden Knights     3   Vegas Golden Knights* 3\n",
      "3     Toronto Maple Leafs     4    Toronto Maple Leafs* 4\n",
      "4            Dallas Stars     5           Dallas Stars* 5\n",
      "5       Los Angeles Kings     6      Los Angeles Kings* 6\n",
      "6     Tampa Bay Lightning     7    Tampa Bay Lightning* 7\n",
      "7      Colorado Avalanche     8     Colorado Avalanche* 8\n",
      "8         Edmonton Oilers     9        Edmonton Oilers* 9\n",
      "9     Carolina Hurricanes    10   Carolina Hurricanes* 10\n",
      "10       Florida Panthers    11      Florida Panthers* 11\n",
      "11         Minnesota Wild    12        Minnesota Wild* 12\n",
      "12        Ottawa Senators    13       Ottawa Senators* 13\n",
      "13         Calgary Flames    14         Calgary Flames 14\n",
      "14        St. Louis Blues    15       St. Louis Blues* 15\n",
      "15     Montreal Canadiens    16    Montreal Canadiens* 16\n",
      "16      New Jersey Devils    17     New Jersey Devils* 17\n",
      "17      Vancouver Canucks    18      Vancouver Canucks 18\n",
      "18  Columbus Blue Jackets    19  Columbus Blue Jackets 19\n",
      "19       Utah Hockey Club    20       Utah Hockey Club 20\n",
      "20      Detroit Red Wings    21      Detroit Red Wings 21\n",
      "21       New York Rangers    22       New York Rangers 22\n",
      "22     New York Islanders    23     New York Islanders 23\n",
      "23    Pittsburgh Penguins    24    Pittsburgh Penguins 24\n",
      "24          Anaheim Ducks    25          Anaheim Ducks 25\n",
      "25         Buffalo Sabres    26         Buffalo Sabres 26\n",
      "26          Boston Bruins    27          Boston Bruins 27\n",
      "27         Seattle Kraken    28         Seattle Kraken 28\n",
      "28    Philadelphia Flyers    29    Philadelphia Flyers 29\n",
      "29    Nashville Predators    30    Nashville Predators 30\n",
      "30     Chicago Blackhawks    31     Chicago Blackhawks 31\n",
      "31        San Jose Sharks    32        San Jose Sharks 32\n"
     ]
    }
   ],
   "source": [
    "#Retrieve the rank of each teams\n",
    "\n",
    "url = 'https://www.hockey-reference.com/leagues/NHL_2025.html#all_stats'\n",
    "\n",
    "with webdriver.Chrome() as driver:\n",
    "    driver.get(url)\n",
    "    time.sleep(2) \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "table = soup.find('table', id='stats')\n",
    "\n",
    "if table is None:\n",
    "    print(\"Team Statistics table not found\")\n",
    "else:\n",
    "    \n",
    "    rows = table.find_all('tr')[1:] \n",
    "    teams = [\n",
    "        row.find_all('td')[0].text.strip()\n",
    "        for row in rows\n",
    "        if row.find_all('td')\n",
    "    ]\n",
    "    ranks = list(range(1, len(teams) + 1)) \n",
    "\n",
    "    \n",
    "    df_rank = pd.DataFrame({\n",
    "        'Team': teams,\n",
    "        'Rank': ranks,\n",
    "        'Team Rank': [f\"{team} {rank}\" for team, rank in zip(teams, ranks)]\n",
    "    })\n",
    "    df_rank = df_rank[df_rank['Team'] != 'League Average'].reset_index(drop=True)\n",
    "    df_rank['Team'] = df_rank['Team'].str.replace('*', '', regex=False).str.strip()\n",
    "\n",
    "print(df_rank)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00ddb38-a370-48ed-a70a-f0bea4f8315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2624 | Played: 1383\n"
     ]
    }
   ],
   "source": [
    "\n",
    "UA = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "to_csv = lambda u: re.sub(r\"/results/(nhl-\\d{4})$\", r\"/download/\\1-UTC.csv\", u)\n",
    "TIMEZONE = \"America/Toronto\" \n",
    "\n",
    "def _parse_utc_datetime(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Parse the CSV 'Date' column (which is UTC text) into tz-aware UTC timestamps.\n",
    "    Tries multiple formats and both day-first and month-first just in case.\n",
    "    \"\"\"\n",
    "    s = series.astype(str)\n",
    "\n",
    "    # 1) Try day-first (site is typically DD/MM/YYYY HH:MM[:SS]) \n",
    "    dt = pd.to_datetime(s, errors=\"coerce\", utc=True, dayfirst=True)\n",
    "\n",
    "    # 2) For anything still NaT, try month-first (fallback for odd rows)\n",
    "    m = dt.isna()\n",
    "    if m.any():\n",
    "        dt.loc[m] = pd.to_datetime(s[m], errors=\"coerce\", utc=True, dayfirst=False)\n",
    "\n",
    "    return dt\n",
    "\n",
    "def load(u: str) -> pd.DataFrame:\n",
    "    url = to_csv(u)  \n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "    except Exception:\n",
    "        r = requests.get(url, headers=UA, timeout=20); r.raise_for_status()\n",
    "        df = pd.read_csv(StringIO(r.text))\n",
    "\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    lc = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    date_col = lc.get(\"date\") or next(c for c in df.columns if \"date\" in c.lower())\n",
    "    home_col = lc.get(\"home team\") or lc.get(\"home\") or next(c for c in df.columns if \"home\" in c.lower())\n",
    "    away_col = lc.get(\"away team\") or lc.get(\"away\") or next(c for c in df.columns if \"away\" in c.lower())\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"Date_str\": df[date_col].astype(str),\n",
    "        \"Home Team\": df[home_col].astype(str),\n",
    "        \"Away Team\": df[away_col].astype(str),\n",
    "    })\n",
    "\n",
    "    # --- scores/result mapping (unchanged idea) ---\n",
    "    if {\"Home Score\",\"Away Score\"}.issubset(df.columns):\n",
    "        out[\"Home Score\"] = pd.to_numeric(df[\"Home Score\"], errors=\"coerce\")\n",
    "        out[\"Away Score\"] = pd.to_numeric(df[\"Away Score\"], errors=\"coerce\")\n",
    "    elif \"Score\" in df.columns:\n",
    "        s = (df[\"Score\"].astype(str)\n",
    "             .str.replace(\"\\u2013\",\"-\",regex=False)\n",
    "             .str.replace(\"\\u2212\",\"-\",regex=False))\n",
    "        g = s.str.extract(r\"(\\d+)\\s*-\\s*(\\d+)\")\n",
    "        out[\"Home Score\"] = pd.to_numeric(g[0], errors=\"coerce\")\n",
    "        out[\"Away Score\"] = pd.to_numeric(g[1], errors=\"coerce\")\n",
    "    else:\n",
    "        out[\"Home Score\"] = pd.NA; out[\"Away Score\"] = pd.NA\n",
    "\n",
    "    out[\"Result\"] = df[lc[\"result\"]] if \"result\" in lc else \"\"\n",
    "\n",
    "    need = out[\"Home Score\"].isna() | out[\"Away Score\"].isna()\n",
    "    if need.any():\n",
    "        rnum = out.loc[need, \"Result\"].astype(str).str.extract(r\"(\\d+)\\s*-\\s*(\\d+)\")\n",
    "        out.loc[need, \"Home Score\"] = pd.to_numeric(rnum[0], errors=\"coerce\")\n",
    "        out.loc[need, \"Away Score\"] = pd.to_numeric(rnum[1], errors=\"coerce\")\n",
    "\n",
    "    # --- team name cleanup (keep accents; remove weird chars/spaces) ---\n",
    "    for c in (\"Home Team\",\"Away Team\"):\n",
    "        out[c] = (out[c].str.replace(r\"[^A-Za-zÀ-ÿ .'\\-]\", \"\", regex=True)\n",
    "                        .str.replace(r\"\\s{2,}\", \" \", regex=True)\n",
    "                        .str.strip())\n",
    "\n",
    "    # === CRITICAL: keep UTC and derive Local ===\n",
    "    out[\"Date_UTC\"]   = _parse_utc_datetime(out[\"Date_str\"])\n",
    "    out[\"Date_Local\"] = out[\"Date_UTC\"].dt.tz_convert(TIMEZONE)\n",
    "    out[\"LocalDate\"]  = out[\"Date_Local\"].dt.date\n",
    "\n",
    "    # sort/dedupe on UTC (stable total order)\n",
    "    out = (out.dropna(subset=[\"Date_UTC\"])\n",
    "              .sort_values(\"Date_UTC\")\n",
    "              .drop_duplicates([\"Date_UTC\",\"Home Team\",\"Away Team\"], keep=\"last\")\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "    return out[[\n",
    "        \"Date_UTC\",\"Date_Local\",\"LocalDate\",\n",
    "        \"Home Team\",\"Away Team\",\"Home Score\",\"Away Score\",\"Result\"\n",
    "    ]]\n",
    "\n",
    "# --- load seasons, merge, save ---\n",
    "df_2024 = load(\"https://fixturedownload.com/results/nhl-2024\"); df_2024[\"Season\"], df_2024[\"weight\"] = \"2024-2025\", 1.0\n",
    "df_2025 = load(\"https://fixturedownload.com/results/nhl-2025\"); df_2025[\"Season\"], df_2025[\"weight\"] = \"2025-2026\", 2.0\n",
    "\n",
    "df_all = pd.concat([df_2024, df_2025], ignore_index=True)\n",
    "df_all[\"Played\"] = df_all[\"Home Score\"].notna() & df_all[\"Away Score\"].notna()\n",
    "print(f\"Total rows: {len(df_all)} | Played: {int(df_all['Played'].sum())}\")\n",
    "\n",
    "df_all.to_csv(\"nhl_results_2024_2026_weighted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78714b40-09da-4645-94c4-7e5a42897d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize both data sources\n",
    "team_name_mapping = {\n",
    "    \"Montréal Canadiens\": \"Montreal Canadiens\"\n",
    "}\n",
    "\n",
    "df_all[\"Home Team\"] = df_all[\"Home Team\"].replace(team_name_mapping)\n",
    "df_all[\"Away Team\"] = df_all[\"Away Team\"].replace(team_name_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1bdd65-499a-43fd-b2f3-ef4c1c9e38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Missing 41 ranks in Home Team Rank (check team name aliases).\n",
      "⚠️ Missing 41 ranks in Away Team Rank (check team name aliases).\n"
     ]
    }
   ],
   "source": [
    "# --- Normalize team names to avoid silent mismatches ---\n",
    "for c in [\"Home Team\", \"Away Team\"]:\n",
    "    df_all[c] = df_all[c].astype(str).str.strip()\n",
    "\n",
    "df_rank = df_rank.copy()\n",
    "df_rank[\"Team\"] = df_rank[\"Team\"].astype(str).str.strip()\n",
    "df_rank[\"Rank\"] = pd.to_numeric(df_rank[\"Rank\"], errors=\"coerce\")\n",
    "\n",
    "# --- Build minimal rank frames (only needed columns!) ---\n",
    "rank_home = (df_rank.loc[:, [\"Team\", \"Rank\"]]\n",
    "                     .rename(columns={\"Team\": \"Home Team\", \"Rank\": \"Home Team Rank\"}))\n",
    "\n",
    "rank_away = (df_rank.loc[:, [\"Team\", \"Rank\"]]\n",
    "                     .rename(columns={\"Team\": \"Away Team\", \"Rank\": \"Away Team Rank\"}))\n",
    "\n",
    "# --- Drop any stale columns from previous merges to avoid collisions ---\n",
    "for col in [\"Home Team Rank\", \"Away Team Rank\", \"Rank\", \"Team\", \"Team Rank_x\", \"Team Rank_y\"]:\n",
    "    if col in df_all.columns:\n",
    "        df_all = df_all.drop(columns=col)\n",
    "\n",
    "# --- Merge one side at a time (no suffixes needed) ---\n",
    "df_all = df_all.merge(rank_home, on=\"Home Team\", how=\"left\")\n",
    "df_all = df_all.merge(rank_away, on=\"Away Team\", how=\"left\")\n",
    "\n",
    "# --- Home Win indicator (safe when scores are present) ---\n",
    "df_all[\"Home Win\"] = (\n",
    "    df_all[\"Home Score\"].notna() &\n",
    "    df_all[\"Away Score\"].notna() &\n",
    "    (df_all[\"Home Score\"] > df_all[\"Away Score\"])\n",
    ").astype(int)\n",
    "\n",
    "# --- If you want a naive local datetime \"Date\" for downstream code ---\n",
    "if \"Date_Local\" in df_all.columns:\n",
    "    df_all[\"Date\"] = df_all[\"Date_Local\"].dt.tz_localize(None)\n",
    "\n",
    "# --- Pick your final view ---\n",
    "final_columns = [\n",
    "    \"LocalDate\", \"Date_Local\", \"Date\",  # keep all three if useful\n",
    "    \"Home Team\", \"Home Score\", \"Away Team\", \"Away Score\",\n",
    "    \"Home Team Rank\", \"Away Team Rank\", \"Home Win\"\n",
    "]\n",
    "df_final = df_all.loc[:, [c for c in final_columns if c in df_all.columns]].copy()\n",
    "\n",
    "# --- Sanity checks ---\n",
    "for col in [\"Home Team Rank\", \"Away Team Rank\"]:\n",
    "    miss = df_final[col].isna().sum()\n",
    "    if miss:\n",
    "        print(f\"⚠️ Missing {miss} ranks in {col} (check team name aliases).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1682fe-26a9-4a15-92ba-893ccb32f182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date             Home Team            Away Team  \\\n",
      "1373 2025-10-16 19:00:00   Philadelphia Flyers        Winnipeg Jets   \n",
      "1374 2025-10-16 19:00:00     New Jersey Devils     Florida Panthers   \n",
      "1375 2025-10-16 19:00:00   Toronto Maple Leafs     New York Rangers   \n",
      "1376 2025-10-16 19:00:00    Montreal Canadiens  Nashville Predators   \n",
      "1377 2025-10-16 19:00:00       Ottawa Senators       Seattle Kraken   \n",
      "1378 2025-10-16 19:30:00    New York Islanders      Edmonton Oilers   \n",
      "1379 2025-10-16 20:00:00          Dallas Stars    Vancouver Canucks   \n",
      "1380 2025-10-16 22:00:00         Anaheim Ducks  Carolina Hurricanes   \n",
      "1381 2025-10-16 22:00:00  Vegas Golden Knights        Boston Bruins   \n",
      "1382 2025-10-16 22:00:00     Los Angeles Kings  Pittsburgh Penguins   \n",
      "\n",
      "      Home Opponent Strength  Away Opponent Strength  Home Last 10 Wins  \\\n",
      "1373                    18.1                    14.2                  4   \n",
      "1374                    19.2                    20.3                  5   \n",
      "1375                    17.9                    16.5                  7   \n",
      "1376                    19.3                     NaN                  6   \n",
      "1377                    19.8                    14.4                  5   \n",
      "1378                    14.8                    17.1                  2   \n",
      "1379                    14.7                    12.6                  3   \n",
      "1380                    15.2                    18.8                  4   \n",
      "1381                    19.6                    19.1                  6   \n",
      "1382                    13.6                    20.5                  5   \n",
      "\n",
      "      Away Last 10 Wins  Home Played Yesterday  Away Played Yesterday  \\\n",
      "1373                  7                  False                  False   \n",
      "1374                  6                  False                   True   \n",
      "1375                  5                  False                  False   \n",
      "1376                  5                  False                  False   \n",
      "1377                  6                  False                  False   \n",
      "1378                  6                  False                  False   \n",
      "1379                  5                  False                  False   \n",
      "1380                  4                  False                  False   \n",
      "1381                  6                  False                  False   \n",
      "1382                  6                  False                  False   \n",
      "\n",
      "      Home Win Rate  Away Win Rate  Home Team Overall Win Streak Before Game  \\\n",
      "1373       0.500000       0.642857                                         1   \n",
      "1374       0.463415       0.465116                                         2   \n",
      "1375       0.659091       0.511628                                         1   \n",
      "1376       0.571429       0.255814                                         3   \n",
      "1377       0.642857       0.404762                                         0   \n",
      "1378       0.441860       0.571429                                         0   \n",
      "1379       0.690476       0.500000                                         3   \n",
      "1380       0.523810       0.404762                                         2   \n",
      "1381       0.690476       0.333333                                         1   \n",
      "1382       0.738095       0.325581                                         0   \n",
      "\n",
      "      Away Team Overall Win Streak Before Game  \\\n",
      "1373                                         2   \n",
      "1374                                         0   \n",
      "1375                                         0   \n",
      "1376                                         0   \n",
      "1377                                         0   \n",
      "1378                                         2   \n",
      "1379                                         0   \n",
      "1380                                         3   \n",
      "1381                                         0   \n",
      "1382                                         0   \n",
      "\n",
      "      Away Rest Days Since Last Game  Home Rest Days Since Last Game  \n",
      "1373                             3.0                             3.0  \n",
      "1374                             1.0                             3.0  \n",
      "1375                             2.0                             2.0  \n",
      "1376                             2.0                             2.0  \n",
      "1377                             2.0                             1.0  \n",
      "1378                             2.0                             3.0  \n",
      "1379                             3.0                             1.0  \n",
      "1380                             2.0                             1.0  \n",
      "1381                             3.0                             2.0  \n",
      "1382                             1.0                             3.0  \n"
     ]
    }
   ],
   "source": [
    "#DATA MANIPULATION\n",
    "\n",
    "\n",
    "# Filter out the Unplayed Games\n",
    "df_final = df_final.dropna(subset=[\"Home Score\", \"Away Score\"])\n",
    "\n",
    "# Convert Scores and Dates to Appropriate Data Types\n",
    "df_final[\"Date\"] = pd.to_datetime(df_final[\"Date\"], format=\"%d/%m/%Y\")\n",
    "df_final[[\"Home Score\", \"Away Score\"]] = df_final[[\"Home Score\", \"Away Score\"]].astype(int)\n",
    "df_final[\"Home Win\"] = df_final[\"Home Win\"].astype(bool)\n",
    "\n",
    "# Sort Data by Date for Chronological Calculations\n",
    "df_final = df_final.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Function: Calculate Last 10 Games Stats\n",
    "def calculate_last_10_stats(df, team_column):\n",
    "    last_10_wins = []\n",
    "    team_games = {team: [] for team in pd.concat([df[\"Home Team\"], df[\"Away Team\"]]).unique()}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        team = row[team_column]\n",
    "        recent_games = team_games[team][-10:]  # Last 10 games\n",
    "        last_10_wins.append(sum(recent_games))\n",
    "        team_games[row[\"Home Team\"]].append(row[\"Home Win\"])\n",
    "        team_games[row[\"Away Team\"]].append(not row[\"Home Win\"])\n",
    "    return last_10_wins\n",
    "\n",
    "# Add Last 10 Wins for Home and Away Teams\n",
    "df_final[\"Home Last 10 Wins\"] = calculate_last_10_stats(df_final, \"Home Team\")\n",
    "df_final[\"Away Last 10 Wins\"] = calculate_last_10_stats(df_final, \"Away Team\")\n",
    "\n",
    "# Add Whether Teams Played Yesterday\n",
    "def calculate_played_yesterday(df, team_column):\n",
    "    played_yesterday = []\n",
    "    last_game_date = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        team = row[team_column]\n",
    "        played_yesterday.append(last_game_date.get(team) == row[\"Date\"] - pd.Timedelta(days=1))\n",
    "        last_game_date[team] = row[\"Date\"]\n",
    "    return played_yesterday\n",
    "\n",
    "df_final[\"Home Played Yesterday\"] = calculate_played_yesterday(df_final, \"Home Team\")\n",
    "df_final[\"Away Played Yesterday\"] = calculate_played_yesterday(df_final, \"Away Team\")\n",
    "\n",
    "# Add Win Rate for Home and Away Teams\n",
    "def calculate_win_rate(df, team_column, is_home_column):\n",
    "    win_rate = []\n",
    "    team_stats = {team: {\"wins\": 0, \"games\": 0} for team in pd.concat([df[\"Home Team\"], df[\"Away Team\"]]).unique()}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        team = row[team_column]\n",
    "        stats = team_stats[team]\n",
    "        win_rate.append(stats[\"wins\"] / stats[\"games\"] if stats[\"games\"] > 0 else 0)\n",
    "        \n",
    "        \n",
    "        if is_home_column:\n",
    "            stats[\"wins\"] += row[\"Home Win\"]\n",
    "        else:\n",
    "            stats[\"wins\"] += not row[\"Home Win\"]\n",
    "        stats[\"games\"] += 1\n",
    "    return win_rate\n",
    "\n",
    "df_final[\"Home Win Rate\"] = calculate_win_rate(df_final, \"Home Team\", is_home_column=True)\n",
    "df_final[\"Away Win Rate\"] = calculate_win_rate(df_final, \"Away Team\", is_home_column=False)\n",
    "\n",
    "# Add Overall Win Streak for Home and Away Teams\n",
    "def calculate_overall_win_streak(df):\n",
    "    streak = {}\n",
    "    home_streaks = []\n",
    "    away_streaks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        home_team = row[\"Home Team\"]\n",
    "        away_team = row[\"Away Team\"]\n",
    "\n",
    "        \n",
    "        home_streaks.append(streak.get(home_team, 0))\n",
    "        away_streaks.append(streak.get(away_team, 0))\n",
    "\n",
    "        \n",
    "        if row[\"Home Win\"]:\n",
    "            streak[home_team] = streak.get(home_team, 0) + 1\n",
    "            streak[away_team] = 0\n",
    "        else:\n",
    "            streak[home_team] = 0\n",
    "            streak[away_team] = streak.get(away_team, 0) + 1\n",
    "    return home_streaks, away_streaks\n",
    "\n",
    "home_streaks, away_streaks = calculate_overall_win_streak(df_final)\n",
    "df_final[\"Home Team Overall Win Streak Before Game\"] = home_streaks\n",
    "df_final[\"Away Team Overall Win Streak Before Game\"] = away_streaks\n",
    "\n",
    "# Add Average Opponent Strength for Home and Away Teams\n",
    "def calculate_avg_opponent_rank(df, team_column, opponent_rank_column):\n",
    "    avg_opponent_rank = []\n",
    "    opponent_stats = {team: [] for team in pd.concat([df[\"Home Team\"], df[\"Away Team\"]]).unique()}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        team = row[team_column]\n",
    "        avg_opponent_rank.append(\n",
    "            np.mean(opponent_stats[team][-10:]) if opponent_stats[team] else np.nan\n",
    "        )\n",
    "        opponent_stats[row[\"Home Team\"]].append(row[\"Away Team Rank\"])\n",
    "        opponent_stats[row[\"Away Team\"]].append(row[\"Home Team Rank\"])\n",
    "    return avg_opponent_rank\n",
    "\n",
    "df_final[\"Home Opponent Strength\"] = calculate_avg_opponent_rank(df_final, \"Home Team\", \"Away Team Rank\")\n",
    "df_final[\"Away Opponent Strength\"] = calculate_avg_opponent_rank(df_final, \"Away Team\", \"Home Team Rank\")\n",
    "\n",
    "OFFSEASON_GAP_DAYS = 45  \n",
    "\n",
    "def calculate_days_since_last_game(df, gap=OFFSEASON_GAP_DAYS):\n",
    "    last_game_date = {}\n",
    "    home_rest, away_rest = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        d = row[\"Date\"]\n",
    "        h = row[\"Home Team\"]; a = row[\"Away Team\"]\n",
    "\n",
    "        # home\n",
    "        prev = last_game_date.get(h)\n",
    "        if prev is None:\n",
    "            home_rest.append(None)\n",
    "        else:\n",
    "            delta = (d - prev).days\n",
    "            home_rest.append(delta if delta <= gap else None)\n",
    "\n",
    "        # away\n",
    "        prev = last_game_date.get(a)\n",
    "        if prev is None:\n",
    "            away_rest.append(None)\n",
    "        else:\n",
    "            delta = (d - prev).days\n",
    "            away_rest.append(delta if delta <= gap else None)\n",
    "\n",
    "        # update last seen dates\n",
    "        last_game_date[h] = d\n",
    "        last_game_date[a] = d\n",
    "\n",
    "    return home_rest, away_rest\n",
    "\n",
    "# Apply\n",
    "home_days, away_days = calculate_days_since_last_game(df_final)\n",
    "df_final[\"Home Rest Days Since Last Game\"] = home_days\n",
    "df_final[\"Away Rest Days Since Last Game\"] = away_days\n",
    "\n",
    "print(df_final[[\"Date\", \"Home Team\", \"Away Team\", \"Home Opponent Strength\", \"Away Opponent Strength\",\"Home Last 10 Wins\",\"Away Last 10 Wins\",\"Home Played Yesterday\",\"Away Played Yesterday\",\"Home Win Rate\",\"Away Win Rate\",\"Home Team Overall Win Streak Before Game\",\"Away Team Overall Win Streak Before Game\",\"Away Rest Days Since Last Game\",\"Home Rest Days Since Last Game\"]].tail(10))\n",
    "\n",
    "\n",
    "df_final.to_csv(\"enhanced_game_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6507280b-353c-4375-ac48-415d2b8060dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"Rank Difference\"] = df_final[\"Home Team Rank\"] - df_final[\"Away Team Rank\"]\n",
    "df_final[\"Home Advantage\"] = df_final[\"Home Win Rate\"] - df_final[\"Away Win Rate\"]\n",
    "df_final[\"Win Streak Impact\"] = df_final[\"Home Team Overall Win Streak Before Game\"] - df_final[\"Away Team Overall Win Streak Before Game\"]\n",
    "df_final[\"Opponent Strength\"] = df_final[\"Home Opponent Strength\"] - df_final[\"Away Opponent Strength\"]\n",
    "df_final[\"Last 10 Wins\"] = df_final[\"Home Last 10 Wins\"] - df_final[\"Away Last 10 Wins\"]\n",
    "df_final[\"Opponent Strength\"] = df_final[\"Home Opponent Strength\"] - df_final[\"Away Opponent Strength\"]\n",
    "df_final = df_final.dropna().reset_index(drop=True)\n",
    "\n",
    "results1 = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c7fdff-562e-4210-8890-a4e8a975d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Always Home) — F1: 0.4078, ROC AUC: 0.5, Brier: 0.4351\n",
      "Baseline (Always Away) — F1: 0.2638, ROC AUC: 0.5, Brier: 0.5649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scorer = make_scorer(f1_score, pos_label=None, average='weighted')\n",
    "\n",
    "y_true = df_final[\"Home Win\"].astype(int).values\n",
    "\n",
    "y_pred = np.ones_like(y_true)                   \n",
    "y_proba = np.ones_like(y_true, dtype=float)     \n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "\n",
    "try:\n",
    "    roc = roc_auc_score(y_true, y_proba)\n",
    "except ValueError:\n",
    "    roc = float(\"nan\")  # undefined for constant scores\n",
    "\n",
    "\n",
    "brier = brier_score_loss(y_true, y_proba)\n",
    "\n",
    "print(f\"Baseline (Always Home) — F1: {f1:.4f}, ROC AUC: {roc}, Brier: {brier:.4f}\")\n",
    "y_pred_away = np.zeros_like(y_true)\n",
    "y_proba_away = np.zeros_like(y_true, dtype=float)\n",
    "\n",
    "f1_away = f1_score(y_true, y_pred_away, average=\"weighted\")\n",
    "try:\n",
    "    roc_away = roc_auc_score(y_true, y_proba_away)\n",
    "except ValueError:\n",
    "    roc_away = float(\"nan\")\n",
    "brier_away = brier_score_loss(y_true, y_proba_away)\n",
    "\n",
    "print(f\"Baseline (Always Away) — F1: {f1_away:.4f}, ROC AUC: {roc_away}, Brier: {brier_away:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae520b5-6880-4f84-ad35-8524ec7fb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_final.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "feature_cols = [\n",
    "    \"Opponent Strength\",\"Rank Difference\",\"Last 10 Wins\",\n",
    "    \"Home Played Yesterday\",\"Away Played Yesterday\",\n",
    "    \"Home Advantage\",\"Win Streak Impact\",\n",
    "    \"Away Rest Days Since Last Game\",\"Home Rest Days Since Last Game\"\n",
    "]\n",
    "target_col = \"Home Win\"\n",
    "\n",
    "X_all = df_sorted[feature_cols]\n",
    "y_all = df_sorted[target_col].astype(int)\n",
    "\n",
    "split_idx = int(0.8 * len(df_sorted))\n",
    "X_train, X_test = X_all.iloc[:split_idx], X_all.iloc[split_idx:]\n",
    "y_train, y_test = y_all.iloc[:split_idx], y_all.iloc[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd3ea4a-bdd7-4c69-ad7d-5ead3e5f0d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF:\n",
      " Home Rest Days Since Last Game    2.083885\n",
      "Away Rest Days Since Last Game    2.082895\n",
      "Last 10 Wins                      1.769676\n",
      "Rank Difference                   1.539153\n",
      "Home Advantage                    1.435472\n",
      "Win Streak Impact                 1.297874\n",
      "Opponent Strength                 1.034779\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_vif(df):\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "    X = sm.add_constant(df)\n",
    "    vif = pd.Series(\n",
    "        [variance_inflation_factor(X.values, i) for i in range(1, X.shape[1])],\n",
    "        index=df.columns\n",
    "    )\n",
    "    return vif.sort_values(ascending=False)\n",
    "\n",
    "vif_series = compute_vif(X_train.select_dtypes(include=[np.number]))\n",
    "print(\"VIF:\\n\", vif_series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3905c7bd-49ec-4e30-9814-104e15413bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 596, number of negative: 470\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 1066, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.559099 -> initscore=0.237508\n",
      "[LightGBM] [Info] Start training from score 0.237508\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 470\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 1066, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.559099 -> initscore=0.237508\n",
      "[LightGBM] [Info] Start training from score 0.237508\n",
      "\n",
      "=== Models ===\n",
      "           Model        F1   ROC_AUC     Brier\n",
      "0      Logistic  0.628320  0.667805  0.224073\n",
      "1           MLP  0.621220  0.658222  0.224275\n",
      "2  RandomForest  0.574439  0.626433  0.234957\n",
      "3      LightGBM  0.567637  0.607585  0.258388\n",
      "\n",
      "Selected features:\n",
      " {'Logistic': ['Rank_Difference', 'Last_10_Wins', 'Home_Played_Yesterday', 'Away_Played_Yesterday', 'Home_Advantage', 'Away_Rest_Days_Since_Last_Game', 'Home_Rest_Days_Since_Last_Game'], 'MLP': ['Rank_Difference', 'Away_Played_Yesterday', 'Home_Advantage', 'Home_Rest_Days_Since_Last_Game'], 'RandomForest': ['Opponent_Strength', 'Rank_Difference', 'Last_10_Wins', 'Home_Advantage', 'Win_Streak_Impact'], 'LightGBM': ['Opponent_Strength', 'Rank_Difference', 'Last_10_Wins', 'Home_Advantage', 'Win_Streak_Impact']}\n",
      "\n",
      "Best: Logistic\n",
      "Final metrics: {'F1': 0.628319724072118, 'ROC_AUC': np.float64(0.6678054429646786), 'Brier': np.float64(0.22407320911362646)}\n"
     ]
    }
   ],
   "source": [
    "# 0) Features & split\n",
    "feature_cols = [\n",
    "    \"Opponent Strength\",\"Rank Difference\",\"Last 10 Wins\",\n",
    "    \"Home Played Yesterday\",\"Away Played Yesterday\",\n",
    "    \"Home Advantage\",\"Win Streak Impact\",\n",
    "    \"Away Rest Days Since Last Game\",\"Home Rest Days Since Last Game\"\n",
    "]\n",
    "target_col = \"Home Win\"\n",
    "\n",
    "df = df_final.sort_values(\"Date\").reset_index(drop=True)\n",
    "rename_map = {c: c.replace(\" \", \"_\") for c in feature_cols}\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "feat = [rename_map[c] for c in feature_cols]\n",
    "X, y = df[feat], df[target_col].astype(int)\n",
    "\n",
    "split = int(0.8 * len(df))\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "cv5 = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# 1) Name-preserving selectors\n",
    "class NamePreservingSelectFromModel(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, estimator, threshold=\"median\"):\n",
    "        self.estimator = estimator\n",
    "        self.threshold = threshold\n",
    "        self.selected_cols_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        if not hasattr(X, \"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        est = clone(self.estimator).fit(X, y)\n",
    "        sfm = SelectFromModel(est, threshold=self.threshold, prefit=True)\n",
    "        self.selected_cols_ = list(X.columns[sfm.get_support()])\n",
    "        return self\n",
    "    def transform(self, X): return X[self.selected_cols_]\n",
    "\n",
    "class NamePreservingSelectKBest(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, score_func=mutual_info_classif, k=5):\n",
    "        self.score_func = score_func; self.k = k; self.selected_cols_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        if not hasattr(X, \"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        skb = SelectKBest(self.score_func, k=self.k).fit(X, y)\n",
    "        self.selected_cols_ = list(X.columns[skb.get_support()])\n",
    "        return self\n",
    "    def transform(self, X): return X[self.selected_cols_]\n",
    "\n",
    "class NamePreservingRFECV(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, estimator, step=1, cv=None, scoring=\"neg_brier_score\", min_features_to_select=1):\n",
    "        self.estimator = estimator; self.step = step; self.cv = cv\n",
    "        self.scoring = scoring; self.min_features_to_select = min_features_to_select\n",
    "        self.selected_cols_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        if not hasattr(X, \"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        r = RFECV(self.estimator, step=self.step, cv=self.cv, scoring=self.scoring,\n",
    "                  min_features_to_select=self.min_features_to_select).fit(X, y)\n",
    "        self.selected_cols_ = list(X.columns[r.support_]); return self\n",
    "    def transform(self, X): return X[self.selected_cols_]\n",
    "\n",
    "# 2) Pipelines\n",
    "pipe_logistic = Pipeline([\n",
    "    (\"rfe\", NamePreservingRFECV(LogisticRegression(max_iter=1000), step=1, cv=cv5, scoring=\"neg_brier_score\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipe_mlp = Pipeline([\n",
    "    (\"skb\", NamePreservingSelectKBest(k=max(3, len(feat)//2))),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", MLPClassifier(max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "pipe_lgbm = Pipeline([\n",
    "    (\"sfm\", NamePreservingSelectFromModel(LGBMClassifier(random_state=42), threshold=\"median\")),\n",
    "    (\"clf\", LGBMClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    (\"sfm\", NamePreservingSelectFromModel(RandomForestClassifier(n_estimators=400, random_state=42), threshold=\"median\")),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=400, random_state=42))\n",
    "])\n",
    "\n",
    "candidates = {\n",
    "    \"Logistic\": pipe_logistic,\n",
    "    \"MLP\": pipe_mlp,\n",
    "    \"RandomForest\": pipe_rf,\n",
    "    \"LightGBM\": pipe_lgbm,\n",
    "}\n",
    "\n",
    "# 3) Fit / evaluate / save\n",
    "def evaluate(model, X_te, y_te):\n",
    "    y_hat = model.predict(X_te)\n",
    "    p = model.predict_proba(X_te)[:, 1]\n",
    "    return {\"F1\": f1_score(y_te, y_hat, average=\"weighted\"),\n",
    "            \"ROC_AUC\": roc_auc_score(y_te, p),\n",
    "            \"Brier\": brier_score_loss(y_te, p)}\n",
    "\n",
    "results, selected = [], {}\n",
    "\n",
    "for name, model in candidates.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    results.append({\"Model\": name, **evaluate(model, X_test, y_test)})\n",
    "    # grab selected cols from whichever selector exists\n",
    "    sel_cols = None\n",
    "    for key in (\"rfe\", \"skb\", \"sfm\"):\n",
    "        if key in model.named_steps and hasattr(model.named_steps[key], \"selected_cols_\"):\n",
    "            sel_cols = model.named_steps[key].selected_cols_\n",
    "    selected[name] = sel_cols\n",
    "    joblib.dump(model, f\"model_{name}.joblib\")\n",
    "\n",
    "with open(\"selected_features.json\", \"w\") as f:\n",
    "    json.dump({\"rename_map\": rename_map, \"selected_features\": selected}, f, indent=2)\n",
    "\n",
    "res = (pd.DataFrame(results)\n",
    "         .sort_values([\"Brier\",\"ROC_AUC\",\"F1\"], ascending=[True, False, False])\n",
    "         .reset_index(drop=True))\n",
    "print(\"\\n=== Models ===\\n\", res[[\"Model\",\"F1\",\"ROC_AUC\",\"Brier\"]])\n",
    "print(\"\\nSelected features:\\n\", selected)\n",
    "\n",
    "# 4) Best by Brier; calibrate if not Logistic\n",
    "best = res.iloc[0][\"Model\"]\n",
    "pipe = joblib.load(f\"model_{best}.joblib\")\n",
    "\n",
    "final_model = pipe if best == \"Logistic\" else CalibratedClassifierCV(pipe, method=\"isotonic\", cv=5).fit(X_train, y_train)\n",
    "joblib.dump(final_model, f\"model_{best}_CALIBRATED.joblib\")\n",
    "\n",
    "print(\"\\nBest:\", best)\n",
    "print(\"Final metrics:\", evaluate(final_model, X_test, y_test))\n",
    "\n",
    "# 5) Load & predict helper\n",
    "def load_model_and_predict(model_name: str, X_new: pd.DataFrame) -> np.ndarray:\n",
    "    with open(\"selected_features.json\", \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    Xn = X_new.rename(columns={k: v for k, v in meta[\"rename_map\"].items() if k in X_new.columns})\n",
    "    path = f\"model_{model_name}_CALIBRATED.joblib\"\n",
    "    if not os.path.exists(path): path = f\"model_{model_name}.joblib\"\n",
    "    mdl = joblib.load(path)\n",
    "    return mdl.predict_proba(Xn)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5245cfd9-5b3f-4445-86f0-4df61557dd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n",
      "Fitting 6 folds for each of 200 candidates, totalling 1200 fits\n",
      "L2: {'F1': 0.6241007029448048, 'ROC_AUC': np.float64(0.6679212507237985), 'Brier': np.float64(0.22432383817675844)} \n",
      "EN: {'F1': 0.6465678619030885, 'ROC_AUC': np.float64(0.6669658367110597), 'Brier': np.float64(0.22448722112109268)} \n",
      "MLP: {'F1': 0.6023792646871187, 'ROC_AUC': np.float64(0.6565141864504922), 'Brier': np.float64(0.23155605431026416)}\n",
      "Final Logistic: {'F1': 0.6241007029448048, 'ROC_AUC': np.float64(0.6679212507237985), 'Brier': np.float64(0.22432383817675844)} \n",
      "Final MLP: {'F1': 0.6268117881919214, 'ROC_AUC': np.float64(0.6540532715691951), 'Brier': np.float64(0.22838572051485992)}\n",
      "Ensemble: {'F1': 0.6301033653354774, 'ROC_AUC': np.float64(0.6611464968152866), 'Brier': np.float64(0.22570816025375073)}\n"
     ]
    }
   ],
   "source": [
    "# ==== CONFIG ====\n",
    "SEED=42\n",
    "CV_SPLITS=6\n",
    "N_ITER_LOG_L2=40\n",
    "N_ITER_LOG_EN=40\n",
    "N_ITER_MLP=200              \n",
    "RFE_MIN_FEATS=1\n",
    "MLP_MAX_ITER=2000           \n",
    "MLP_EARLY_STOP=True\n",
    "MLP_VAL_FRAC=0.12           # ↓ slightly smaller val set\n",
    "MLP_PATIENCE=20             # ↑ give early stopping time to work\n",
    "TEST_RATIO=0.2\n",
    "\n",
    "FEATURE_COLS=[\n",
    "    \"Opponent Strength\",\"Rank Difference\",\"Last 10 Wins\",\n",
    "    \"Home Played Yesterday\",\"Away Played Yesterday\",\n",
    "    \"Home Advantage\",\"Win Streak Impact\",\n",
    "    \"Away Rest Days Since Last Game\",\"Home Rest Days Since Last Game\"\n",
    "]\n",
    "TARGET_COL=\"Home Win\"\n",
    "\n",
    "# seeds\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ==== DATA (time-ordered split) ====\n",
    "df = df_final.sort_values(\"Date\").reset_index(drop=True)\n",
    "rename_map = {c: c.replace(\" \",\"_\") for c in FEATURE_COLS}\n",
    "df = df.rename(columns=rename_map)\n",
    "feat = [rename_map[c] for c in FEATURE_COLS]\n",
    "X, y = df[feat], df[TARGET_COL].astype(int)\n",
    "\n",
    "cut = int((1-TEST_RATIO)*len(df))\n",
    "X_tr, X_te = X.iloc[:cut], X.iloc[cut:]\n",
    "y_tr, y_te = y.iloc[:cut], y.iloc[cut:]\n",
    "\n",
    "# --- IMPORTANT: time-series CV with a small gap to reduce leakage ---\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=CV_SPLITS, gap=3)\n",
    "\n",
    "# ==== HELPERS ====\n",
    "def evaluate(m, Xt, yt):\n",
    "    p = m.predict_proba(Xt)[:,1]; yhat = (p>=0.5).astype(int)\n",
    "    return {\"F1\": f1_score(yt,yhat,average=\"weighted\"),\n",
    "            \"ROC_AUC\": roc_auc_score(yt,p),\n",
    "            \"Brier\": brier_score_loss(yt,p)}\n",
    "\n",
    "# name-preserving selectors\n",
    "class NPSFM(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self,estimator,threshold=\"median\"):\n",
    "        self.estimator=estimator; self.threshold=threshold; self.selected_cols_=None\n",
    "    def fit(self,X,y=None):\n",
    "        if not hasattr(X,\"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        sfm=SelectFromModel(clone(self.estimator).fit(X,y),threshold=self.threshold,prefit=True)\n",
    "        self.selected_cols_=list(X.columns[sfm.get_support()]); return self\n",
    "    def transform(self,X): return X[self.selected_cols_]\n",
    "\n",
    "class NPSKB(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self,score_func=mutual_info_classif,k=\"all\"):   # default: keep all\n",
    "        self.score_func=score_func; self.k=k; self.selected_cols_=None\n",
    "    def fit(self,X,y=None):\n",
    "        if not hasattr(X,\"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        skb=SelectKBest(self.score_func,k=self.k).fit(X,y)\n",
    "        self.selected_cols_=list(X.columns[skb.get_support()]); return self\n",
    "    def transform(self,X): return X[self.selected_cols_]\n",
    "\n",
    "class NPRFECV(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self,estimator,step=1,cv=None,scoring=\"neg_brier_score\",min_features_to_select=1):\n",
    "        self.estimator=estimator; self.step=step; self.cv=cv; self.scoring=scoring; self.min_features_to_select=min_features_to_select\n",
    "        self.selected_cols_=None\n",
    "    def fit(self,X,y=None):\n",
    "        if not hasattr(X,\"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        r=RFECV(self.estimator,step=self.step,cv=self.cv,scoring=self.scoring,\n",
    "                min_features_to_select=self.min_features_to_select).fit(X,y)\n",
    "        self.selected_cols_=list(X.columns[r.support_]); return self\n",
    "    def transform(self,X): return X[self.selected_cols_]\n",
    "\n",
    "# ==== PIPELINES ====\n",
    "from sklearn.preprocessing import RobustScaler  # more robust than StandardScaler for MLP\n",
    "pipe_log_l2 = Pipeline([\n",
    "    (\"rfe\",NPRFECV(LogisticRegression(max_iter=2000,solver=\"lbfgs\"),\n",
    "                   step=1,cv=tscv,scoring=\"neg_brier_score\",min_features_to_select=RFE_MIN_FEATS)),\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"clf\",LogisticRegression(max_iter=2000,solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "pipe_log_en = Pipeline([\n",
    "    (\"rfe\",NPRFECV(LogisticRegression(max_iter=2000,solver=\"saga\",penalty=\"elasticnet\",l1_ratio=0.5,random_state=SEED),\n",
    "                   step=1,cv=tscv,scoring=\"neg_brier_score\",min_features_to_select=RFE_MIN_FEATS)),\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"clf\",LogisticRegression(max_iter=2000,solver=\"saga\",penalty=\"elasticnet\",random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_mlp = Pipeline([\n",
    "    (\"skb\",NPSKB(k=\"all\")),                   # allow 'all' features as an option\n",
    "    (\"scaler\",RobustScaler()),                # swap to RobustScaler for outlier resistance\n",
    "    (\"clf\",MLPClassifier(max_iter=MLP_MAX_ITER,random_state=SEED,\n",
    "                         early_stopping=MLP_EARLY_STOP,n_iter_no_change=MLP_PATIENCE,\n",
    "                         validation_fraction=MLP_VAL_FRAC,learning_rate=\"adaptive\"))\n",
    "])\n",
    "\n",
    "# ==== SEARCH SPACES ====\n",
    "param_log_l2={\"clf__C\":loguniform(1e-3,1e1),\"clf__class_weight\":[None,\"balanced\"]}\n",
    "param_log_en={\"clf__C\":loguniform(1e-3,1e1),\"clf__l1_ratio\":uniform(0,1),\"clf__class_weight\":[None,\"balanced\"]}\n",
    "\n",
    "# broadened MLP space; SGD options are ignored automatically if solver='adam'\n",
    "param_mlp={\n",
    "    \"skb__k\":[\"all\", max(4,len(feat)//2), max(6,len(feat)//2+2)],\n",
    "    \"clf__solver\":[\"adam\",\"sgd\"],\n",
    "    \"clf__hidden_layer_sizes\":[(64,),(128,),(256,),(64,32),(128,64)],\n",
    "    \"clf__activation\":[\"relu\",\"tanh\"],\n",
    "    \"clf__alpha\":loguniform(1e-6,1e-1),\n",
    "    \"clf__learning_rate_init\":loguniform(5e-4,1e-2),\n",
    "    \"clf__batch_size\":[32,64,128],\n",
    "    \"clf__learning_rate\":[\"adaptive\",\"invscaling\"],  # sgd only\n",
    "    \"clf__momentum\":uniform(0.6,0.39),               # sgd only, 0.6–0.99\n",
    "    \"clf__nesterovs_momentum\":[True,False],          # sgd only\n",
    "}\n",
    "\n",
    "scoring={\"brier\":\"neg_brier_score\",\"roc_auc\":\"roc_auc\",\"f1w\":\"f1_weighted\"}\n",
    "\n",
    "# ==== TUNE + TRAIN ====\n",
    "rs_log_l2=RandomizedSearchCV(pipe_log_l2,param_log_l2,n_iter=N_ITER_LOG_L2,scoring=scoring,\n",
    "                             refit=\"brier\",cv=tscv,n_jobs=-1,verbose=1,random_state=SEED).fit(X_tr,y_tr)\n",
    "rs_log_en=RandomizedSearchCV(pipe_log_en,param_log_en,n_iter=N_ITER_LOG_EN,scoring=scoring,\n",
    "                             refit=\"brier\",cv=tscv,n_jobs=-1,verbose=1,random_state=SEED).fit(X_tr,y_tr)\n",
    "rs_mlp   =RandomizedSearchCV(pipe_mlp,   param_mlp,   n_iter=N_ITER_MLP,   scoring=scoring,\n",
    "                             refit=\"brier\",cv=tscv,n_jobs=-1,verbose=1,random_state=SEED).fit(X_tr,y_tr)\n",
    "\n",
    "best_log_l2, best_log_en, best_mlp = rs_log_l2.best_estimator_, rs_log_en.best_estimator_, rs_mlp.best_estimator_\n",
    "\n",
    "# ==== HOLDOUT ====\n",
    "m_l2, m_en, m_mlp = evaluate(best_log_l2,X_te,y_te), evaluate(best_log_en,X_te,y_te), evaluate(best_mlp,X_te,y_te)\n",
    "print(\"L2:\",m_l2,\"\\nEN:\",m_en,\"\\nMLP:\",m_mlp)\n",
    "\n",
    "# choose logistic winner; calibrate MLP if it helps Brier\n",
    "log_final, log_metrics = (best_log_l2,m_l2) if m_l2[\"Brier\"]<=m_en[\"Brier\"] else (best_log_en,m_en)\n",
    "\n",
    "def calibrate_if_better(model,Xtr,ytr,Xte,yte):\n",
    "    base=evaluate(model,Xte,yte)\n",
    "    cal=CalibratedClassifierCV(model,method=\"isotonic\",cv=5).fit(Xtr,ytr)\n",
    "    calm=evaluate(cal,Xte,yte)\n",
    "    return (cal,calm) if calm[\"Brier\"]<=base[\"Brier\"] else (model,base)\n",
    "\n",
    "mlp_final, mlp_metrics = calibrate_if_better(best_mlp,X_tr,y_tr,X_te,y_te)\n",
    "print(\"Final Logistic:\",log_metrics,\"\\nFinal MLP:\",mlp_metrics)\n",
    "\n",
    "# ==== SAVE MODELS ====\n",
    "joblib.dump(log_final,\"model_Logistic_TUNED.joblib\")\n",
    "joblib.dump(mlp_final,\"model_MLP_TUNED.joblib\")\n",
    "\n",
    "# ==== SELECTED FEATURES (SAFE WITH CALIBRATION WRAPPER) ====\n",
    "def _unwrap_pipeline(model):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    if isinstance(model, Pipeline):\n",
    "        return model\n",
    "    if isinstance(model, CalibratedClassifierCV):\n",
    "        be = getattr(model, \"base_estimator\", None)\n",
    "        if isinstance(be, Pipeline):\n",
    "            return be\n",
    "        ccs = getattr(model, \"calibrated_classifiers_\", None)\n",
    "        if ccs and hasattr(ccs[0], \"estimator\") and isinstance(ccs[0].estimator, Pipeline):\n",
    "            return ccs[0].estimator\n",
    "    return None\n",
    "\n",
    "def selected_cols_from(model, default=None):\n",
    "    pipe = _unwrap_pipeline(model)\n",
    "    if pipe is None:\n",
    "        return default\n",
    "    for k in (\"rfe\",\"skb\",\"sfm\"):\n",
    "        step = pipe.named_steps.get(k)\n",
    "        if step is not None and hasattr(step,\"selected_cols_\"):\n",
    "            return step.selected_cols_\n",
    "    return default\n",
    "\n",
    "with open(\"selected_features.json\",\"w\") as f:\n",
    "    json.dump({\n",
    "        \"rename_map\": rename_map,\n",
    "        \"selected_features\": {\n",
    "            \"Logistic\": selected_cols_from(log_final, default=feat),\n",
    "            \"MLP\":      selected_cols_from(mlp_final,  default=feat)\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "# ==== SIMPLE ENSEMBLE (avg probs) ====\n",
    "p_log = log_final.predict_proba(X_te)[:,1]\n",
    "p_mlp = mlp_final.predict_proba(X_te)[:,1]\n",
    "p_avg = 0.5*p_log + 0.5*p_mlp\n",
    "ens = {\"F1\": f1_score(y_te,(p_avg>=0.5).astype(int),average=\"weighted\"),\n",
    "       \"ROC_AUC\": roc_auc_score(y_te,p_avg),\n",
    "       \"Brier\": brier_score_loss(y_te,p_avg)}\n",
    "print(\"Ensemble:\", ens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d293965c-875a-40c1-9e52-cfe330c48b6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Target slate date set to: 2025-10-18\n",
      "\n",
      "Target date: 2025-10-18 | games found: 13\n",
      "Nearby slates (games per day):\n",
      "  2025-10-17: 4\n",
      "  2025-10-18: 13  (today)\n",
      "  2025-10-19: 4\n",
      "  2025-10-20: 5\n",
      "  2025-10-21: 10\n",
      "\n",
      "Enter AMERICAN odds (e.g., -120, +135).\n",
      "Press Enter to leave a side blank, 's' to skip a game, 'q' to quit.\n",
      "\n",
      "===========================================\n",
      "[1/13]  Florida Panthers  @  Buffalo Sabres\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Florida Panthers  American odds:  -147\n",
      "  (HOME)  Buffalo Sabres  American odds:  130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "[2/13]  New York Islanders  @  Ottawa Senators\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  New York Islanders  American odds:  125\n",
      "  (HOME)  Ottawa Senators  American odds:  -147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "[3/13]  Edmonton Oilers  @  New Jersey Devils\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Edmonton Oilers  American odds:  -104\n",
      "  (HOME)  New Jersey Devils  American odds:  -112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "[4/13]  Nashville Predators  @  Winnipeg Jets\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Nashville Predators  American odds:  158\n",
      "  (HOME)  Winnipeg Jets  American odds:  -189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "[5/13]  Dallas Stars  @  St. Louis Blues\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Dallas Stars  American odds:  -136\n",
      "  (HOME)  St. Louis Blues  American odds:  118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================\n",
      "[6/13]  Tampa Bay Lightning  @  Columbus Blue Jackets\n",
      "=====================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Tampa Bay Lightning  American odds:  -114\n",
      "  (HOME)  Columbus Blue Jackets  American odds:  -103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "[7/13]  Minnesota Wild  @  Philadelphia Flyers\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Minnesota Wild  American odds:  -110\n",
      "  (HOME)  Philadelphia Flyers  American odds:  -106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "[8/13]  New York Rangers  @  Montreal Canadiens\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  New York Rangers  American odds:  -103\n",
      "  (HOME)  Montreal Canadiens  American odds:  -114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "[9/13]  Seattle Kraken  @  Toronto Maple Leafs\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Seattle Kraken  American odds:  175\n",
      "  (HOME)  Toronto Maple Leafs  American odds:  -208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "[10/13]  Boston Bruins  @  Colorado Avalanche\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Boston Bruins  American odds:  205\n",
      "  (HOME)  Colorado Avalanche  American odds:  -250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "[11/13]  Carolina Hurricanes  @  Los Angeles Kings\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Carolina Hurricanes  American odds:  -130\n",
      "  (HOME)  Los Angeles Kings  American odds:  110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================\n",
      "[12/13]  Calgary Flames  @  Vegas Golden Knights\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Calgary Flames  American odds:  198\n",
      "  (HOME)  Vegas Golden Knights  American odds:  -238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================\n",
      "[13/13]  Pittsburgh Penguins  @  San Jose Sharks\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Pittsburgh Penguins  American odds:  -135\n",
      "  (HOME)  San Jose Sharks  American odds:  115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "✅ Saved 13 matchup(s) with odds to odds.csv\n",
      "\n",
      "Saved rows preview:\n",
      "                 Date            Away Team Away American Odds Away Odds  \\\n",
      "0 2025-10-18 13:00:00     Florida Panthers               -147  1.680272   \n",
      "1 2025-10-18 15:00:00   New York Islanders                125      2.25   \n",
      "2 2025-10-18 15:30:00      Edmonton Oilers               -104  1.961538   \n",
      "3 2025-10-18 19:00:00  Nashville Predators                158      2.58   \n",
      "4 2025-10-18 19:00:00         Dallas Stars               -136  1.735294   \n",
      "5 2025-10-18 19:00:00  Tampa Bay Lightning               -114  1.877193   \n",
      "6 2025-10-18 19:00:00       Minnesota Wild               -110  1.909091   \n",
      "7 2025-10-18 19:00:00     New York Rangers               -103  1.970874   \n",
      "8 2025-10-18 19:00:00       Seattle Kraken                175      2.75   \n",
      "9 2025-10-18 21:00:00        Boston Bruins                205      3.05   \n",
      "\n",
      "               Home Team Home American Odds Home Odds  \n",
      "0         Buffalo Sabres                130       2.3  \n",
      "1        Ottawa Senators               -147  1.680272  \n",
      "2      New Jersey Devils               -112  1.892857  \n",
      "3          Winnipeg Jets               -189  1.529101  \n",
      "4        St. Louis Blues                118      2.18  \n",
      "5  Columbus Blue Jackets               -103  1.970874  \n",
      "6    Philadelphia Flyers               -106  1.943396  \n",
      "7     Montreal Canadiens               -114  1.877193  \n",
      "8    Toronto Maple Leafs               -208  1.480769  \n",
      "9     Colorado Avalanche               -250       1.4  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATE_OFFSET = +1\n",
    "TARGET_DATE = (datetime.now() + timedelta(days=DATE_OFFSET)).date()\n",
    "print(f\"📅 Target slate date set to: {TARGET_DATE}\")\n",
    "\n",
    "CSV_PATH = \"odds.csv\"\n",
    "\n",
    "def _strip_accents(s: str) -> str:\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFKD\", str(s)) if not unicodedata.combining(c))\n",
    "\n",
    "def _american_to_decimal(a):\n",
    "    try: a = int(a)\n",
    "    except Exception: return None\n",
    "    if a == 0 or abs(a) < 100 or a == -100: return None\n",
    "    return 1.0 + (a/100.0) if a > 0 else 1.0 + (100.0/abs(a))\n",
    "\n",
    "def _parse_odds(s: str):\n",
    "    if s is None: return (None, None, None)\n",
    "    s = s.strip().lower().replace(\" \", \"\")\n",
    "    if s in {\"s\",\"skip\"}:  return (None, None, \"skip\")\n",
    "    if s in {\"q\",\"quit\"}:  return (None, None, \"quit\")\n",
    "    if \".\" in s or \",\" in s:   # accept decimal as a convenience\n",
    "        try:\n",
    "            dec = float(s.replace(\",\", \".\"))\n",
    "            return (None, dec if dec > 1.01 else None, None)\n",
    "        except Exception:\n",
    "            return (None, None, None)\n",
    "    m = re.fullmatch(r\"([+-]?)(\\d{2,4})\", s)\n",
    "    if not m: return (None, None, None)\n",
    "    sign, num = m.groups(); num = int(num)\n",
    "    american = -num if sign == \"-\" else +num\n",
    "    if american == 0 or abs(american) < 100 or american == -100: return (None, None, None)\n",
    "    return (american, _american_to_decimal(american), None)\n",
    "\n",
    "def _mk_template(df_games, target_date):\n",
    "    g = df_games.copy()\n",
    "    g[\"Date\"] = pd.to_datetime(g[\"Date\"], errors=\"coerce\")\n",
    "    g = g[g[\"Date\"].dt.date == target_date]\n",
    "    out = (g.drop_duplicates(subset=[\"Date\",\"Home Team\",\"Away Team\"])\n",
    "             .loc[:, [\"Date\",\"Away Team\",\"Home Team\"]]\n",
    "             .assign(**{\"Away American Odds\": None, \"Away Odds\": None,\n",
    "                        \"Home American Odds\": None, \"Home Odds\": None})\n",
    "             .loc[:, [\"Date\",\"Away Team\",\"Away American Odds\",\"Away Odds\",\n",
    "                      \"Home Team\",\"Home American Odds\",\"Home Odds\"]]\n",
    "             .reset_index(drop=True))\n",
    "    out[\"Away Team\"] = out[\"Away Team\"].map(_strip_accents)\n",
    "    out[\"Home Team\"] = out[\"Home Team\"].map(_strip_accents)\n",
    "    return out\n",
    "\n",
    "def _slate_counts_nearby(df_games, center_date, span=3):\n",
    "    g = df_games.copy()\n",
    "    g[\"Date\"] = pd.to_datetime(g[\"Date\"], errors=\"coerce\")\n",
    "    counts = []\n",
    "    for delta in range(-1, span+1):\n",
    "        d = center_date + timedelta(days=delta)\n",
    "        n = int((g[\"Date\"].dt.date == d).sum())\n",
    "        counts.append((d, n))\n",
    "    return counts\n",
    "\n",
    "def enter_american_odds(df_games, date_str=None):\n",
    "    target = (pd.to_datetime(date_str).date() if date_str else datetime.now().date())\n",
    "    tmpl = _mk_template(df_games, target)\n",
    "\n",
    "    print(f\"\\nTarget date: {target} | games found: {len(tmpl)}\")\n",
    "    nearby = _slate_counts_nearby(df_games, target, span=3)\n",
    "    print(\"Nearby slates (games per day):\")\n",
    "    for d, n in nearby:\n",
    "        mark = \"  (today)\" if d == target else \"\"\n",
    "        print(f\"  {d}: {n}{mark}\")\n",
    "\n",
    "    if tmpl.empty:\n",
    "        print(\"No games for this date in df_all. Pick another date (e.g., enter_american_odds(df_all, '2025-10-12')).\")\n",
    "        return tmpl  # empty\n",
    "\n",
    "    print(\"\\nEnter AMERICAN odds (e.g., -120, +135).\")\n",
    "    print(\"Press Enter to leave a side blank, 's' to skip a game, 'q' to quit.\\n\")\n",
    "\n",
    "    for i in range(len(tmpl)):\n",
    "        away = tmpl.at[i, \"Away Team\"]\n",
    "        home = tmpl.at[i, \"Home Team\"]\n",
    "        header = f\"[{i+1}/{len(tmpl)}]  {away}  @  {home}\"\n",
    "        print(\"=\"*len(header))\n",
    "        print(header)\n",
    "        print(\"=\"*len(header))\n",
    "\n",
    "        # Away (AWAY TEAM odds)\n",
    "        while True:\n",
    "            a_in = input(f\"  (AWAY)  {away}  American odds: \").strip()\n",
    "            if a_in == \"\":  a_american, a_decimal, cmd = (None, None, None); break\n",
    "            a_american, a_decimal, cmd = _parse_odds(a_in)\n",
    "            if cmd in {\"quit\",\"skip\"} or a_decimal is not None or a_american is None: break\n",
    "            print(\"    -> invalid (try -120, +135, or 1.95)\")\n",
    "        if cmd == \"quit\": break\n",
    "        if cmd == \"skip\": print(\"  skipped game\\n\"); continue\n",
    "\n",
    "        # Home (HOME TEAM odds)\n",
    "        while True:\n",
    "            h_in = input(f\"  (HOME)  {home}  American odds: \").strip()\n",
    "            if h_in == \"\":  h_american, h_decimal, cmd2 = (None, None, None); break\n",
    "            h_american, h_decimal, cmd2 = _parse_odds(h_in)\n",
    "            if cmd2 in {\"quit\",\"skip\"} or h_decimal is not None or h_american is None: break\n",
    "            print(\"    -> invalid (try -120, +135, or 1.95)\")\n",
    "        if cmd2 == \"quit\": break\n",
    "        if cmd2 == \"skip\": print(\"  skipped game\\n\"); continue\n",
    "\n",
    "        tmpl.at[i, \"Away American Odds\"] = a_american\n",
    "        tmpl.at[i, \"Away Odds\"]          = a_decimal\n",
    "        tmpl.at[i, \"Home American Odds\"] = h_american\n",
    "        tmpl.at[i, \"Home Odds\"]          = h_decimal\n",
    "        print()\n",
    "\n",
    "    complete = tmpl.dropna(subset=[\"Away Odds\",\"Home Odds\"]).reset_index(drop=True)\n",
    "    complete.to_csv(CSV_PATH, index=False)\n",
    "    print(f\"\\n✅ Saved {len(complete)} matchup(s) with odds to {CSV_PATH}\")\n",
    "    return complete\n",
    "\n",
    "# ===== RUN =====\n",
    "# Today by default (change to a specific date string if you want):\n",
    "df_odds = enter_american_odds(df_all, TARGET_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print(\"\\nSaved rows preview:\")\n",
    "print(df_odds.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97c88034-7149-4649-b9b9-d43c1e4ab3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SlateDate            Away Team  Away Odds              Home Team  \\\n",
      "0   2025-10-17     Florida Panthers   1.680272         Buffalo Sabres   \n",
      "1   2025-10-17   New York Islanders   2.250000        Ottawa Senators   \n",
      "2   2025-10-17      Edmonton Oilers   1.961538      New Jersey Devils   \n",
      "3   2025-10-17  Nashville Predators   2.580000          Winnipeg Jets   \n",
      "4   2025-10-17         Dallas Stars   1.735294        St. Louis Blues   \n",
      "5   2025-10-17  Tampa Bay Lightning   1.877193  Columbus Blue Jackets   \n",
      "6   2025-10-17       Minnesota Wild   1.909091    Philadelphia Flyers   \n",
      "7   2025-10-17     New York Rangers   1.970874     Montreal Canadiens   \n",
      "8   2025-10-17       Seattle Kraken   2.750000    Toronto Maple Leafs   \n",
      "9   2025-10-17        Boston Bruins   3.050000     Colorado Avalanche   \n",
      "10  2025-10-17  Carolina Hurricanes   1.769231      Los Angeles Kings   \n",
      "11  2025-10-17       Calgary Flames   2.980000   Vegas Golden Knights   \n",
      "12  2025-10-17  Pittsburgh Penguins   1.740741        San Jose Sharks   \n",
      "\n",
      "    Home Odds  p_home_ens  Home Bet  Away Bet  Scaled  \n",
      "0    2.300000      0.3966         0         3    True  \n",
      "1    1.680272      0.6739        26         0    True  \n",
      "2    1.892857      0.3299         0        44    True  \n",
      "3    1.529101      0.8054        59         0    True  \n",
      "4    2.180000      0.3840         0        13    True  \n",
      "5    1.970874      0.3508         0        34    True  \n",
      "6    1.943396      0.2821         0        55    True  \n",
      "7    1.877193      0.6403        31         0    True  \n",
      "8    1.480769      0.7837        45         0    True  \n",
      "9    1.400000      0.7983        40         0    True  \n",
      "10   2.100000      0.6094        34         0    True  \n",
      "11   1.420168      0.6714         0         0    True  \n",
      "12   2.150000      0.5618        24         0    True  \n",
      "\n",
      "Saved 13 rows to predictions.csv (mode='a', header=False)\n"
     ]
    }
   ],
   "source": [
    "# ===================== CONFIG (edit if needed) =====================\n",
    "MODEL_LOG_PATH = \"model_Logistic_TUNED.joblib\"\n",
    "MODEL_MLP_PATH = \"model_MLP_TUNED.joblib\"\n",
    "ENSEMBLE_WEIGHTS = (0.5, 0.5)     # (logistic, mlp)\n",
    "BANKROLL = 409\n",
    "PREDICTIONS_CSV = \"predictions.csv\"\n",
    "DATE_OFFSET = 0                   # 0=today, +1=tomorrow, etc.\n",
    "DATE_COL_IN_HISTORY = \"Date\"      # must exist in df_final\n",
    "# ===================================================================\n",
    "\n",
    "# ---- imports you MUST have ----\n",
    "import os, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ---- target date ----\n",
    "TARGET_DATE = (datetime.now() + timedelta(days=DATE_OFFSET)).date()\n",
    "\n",
    "# ---- safety: required dataframes/objects ----\n",
    "required = {\n",
    "    \"df_odds\": \"DataFrame of today's games with columns: Home Team, Away Team, Home Odds, Away Odds\",\n",
    "    \"df_final\": \"Historical features per game (used to build X_one)\",\n",
    "    \"df_rank\": \"Team ranking table with columns: Team, Rank\",\n",
    "    \"rename_map\": \"dict mapping training feature names (keys in feats) to model input names\"\n",
    "}\n",
    "for name in required:\n",
    "    if name not in globals():\n",
    "        raise RuntimeError(f\"Missing required object `{name}`: {required[name]}\")\n",
    "\n",
    "# ===== MODELS & ENSEMBLE SETUP =====\n",
    "assert os.path.exists(MODEL_LOG_PATH), f\"Missing model file: {MODEL_LOG_PATH}\"\n",
    "assert os.path.exists(MODEL_MLP_PATH), f\"Missing model file: {MODEL_MLP_PATH}\"\n",
    "log_model = joblib.load(MODEL_LOG_PATH)\n",
    "mlp_model = joblib.load(MODEL_MLP_PATH)\n",
    "\n",
    "assert hasattr(log_model, \"predict_proba\"), \"log_model must support predict_proba()\"\n",
    "assert hasattr(mlp_model, \"predict_proba\"), \"mlp_model must support predict_proba()\"\n",
    "\n",
    "# ensemble weights (normalized)\n",
    "try:\n",
    "    w_log, w_mlp = ENSEMBLE_WEIGHTS\n",
    "except Exception:\n",
    "    w_log, w_mlp = 0.5, 0.5\n",
    "ws = (w_log or 0) + (w_mlp or 0)\n",
    "if ws <= 0:\n",
    "    w_log, w_mlp = 0.5, 0.5\n",
    "else:\n",
    "    w_log, w_mlp = w_log / ws, w_mlp / ws\n",
    "\n",
    "# ---- helpers ----\n",
    "def _kelly(p_win: float, dec_odds: float) -> float:\n",
    "    b = dec_odds - 1.0\n",
    "    if b <= 0:\n",
    "        return 0.0\n",
    "    q = 1.0 - p_win\n",
    "    return max(0.0, (b * p_win - q) / b)\n",
    "\n",
    "def _assert_sorted(df_hist: pd.DataFrame, date_col: str):\n",
    "    if not df_hist[date_col].is_monotonic_increasing:\n",
    "        df_hist.sort_values(date_col, inplace=True, kind=\"mergesort\")  # stable\n",
    "\n",
    "def _latest_value_asof(df_hist: pd.DataFrame, team: str, col_if_home: str, col_if_away: str,\n",
    "                       as_of_dt: pd.Timestamp, date_col: str):\n",
    "    # history strictly before slate day boundary (prevent leakage)\n",
    "    m = (((df_hist[\"Home Team\"] == team) | (df_hist[\"Away Team\"] == team))\n",
    "         & (df_hist[date_col] < as_of_dt))\n",
    "    if not m.any():\n",
    "        raise ValueError(f\"No history for {team} up to {as_of_dt}\")\n",
    "    last = df_hist.loc[m].iloc[-1]\n",
    "    return last[col_if_home] if last[\"Home Team\"] == team else last[col_if_away]\n",
    "\n",
    "def build_features_for_match(home_team, away_team, df_hist, df_rank, as_of_dt, date_col: str):\n",
    "    # ranks with guard\n",
    "    def _rank(team):\n",
    "        r = df_rank.loc[df_rank[\"Team\"] == team, \"Rank\"]\n",
    "        if r.empty:\n",
    "            raise ValueError(f\"Rank missing for team: {team}\")\n",
    "        return int(r.iloc[0])\n",
    "\n",
    "    r_home, r_away = _rank(home_team), _rank(away_team)\n",
    "    _assert_sorted(df_hist, date_col)\n",
    "\n",
    "    L = lambda tm, ch, ca: _latest_value_asof(df_hist, tm, ch, ca, as_of_dt, date_col)\n",
    "    feats = {\n",
    "        \"Rank Difference\": r_home - r_away,\n",
    "        \"Last 10 Wins\": L(home_team, \"Home Last 10 Wins\", \"Away Last 10 Wins\")\n",
    "                        - L(away_team, \"Away Last 10 Wins\", \"Home Last 10 Wins\"),\n",
    "        \"Home Played Yesterday\": int(bool(L(home_team, \"Home Played Yesterday\", \"Away Played Yesterday\"))),\n",
    "        \"Away Played Yesterday\": int(bool(L(away_team, \"Away Played Yesterday\", \"Home Played Yesterday\"))),\n",
    "        \"Home Advantage\": L(home_team, \"Home Win Rate\", \"Away Win Rate\")\n",
    "                          - L(away_team, \"Away Win Rate\", \"Home Win Rate\"),\n",
    "        \"Win Streak Impact\": L(home_team, \"Home Team Overall Win Streak Before Game\", \"Away Team Overall Win Streak Before Game\")\n",
    "                             - L(away_team, \"Away Team Overall Win Streak Before Game\", \"Home Team Overall Win Streak Before Game\"),\n",
    "        \"Away Rest Days Since Last Game\": L(away_team, \"Away Rest Days Since Last Game\", \"Home Rest Days Since Last Game\"),\n",
    "        \"Home Rest Days Since Last Game\": L(home_team, \"Home Rest Days Since Last Game\", \"Away Rest Days Since Last Game\"),\n",
    "        \"Opponent Strength\": L(home_team, \"Home Opponent Strength\", \"Away Opponent Strength\")\n",
    "                             - L(away_team, \"Away Opponent Strength\", \"Home Opponent Strength\"),\n",
    "    }\n",
    "\n",
    "    # map to training-time column names expected by the pipelines\n",
    "    row = {rename_map.get(k, k): v for k, v in feats.items()}\n",
    "    X = pd.DataFrame([row])\n",
    "    return X\n",
    "\n",
    "# ==== PREDICT & SIZE BETS ====\n",
    "as_of_dt = pd.Timestamp(TARGET_DATE)  # naive local midnight of target day\n",
    "\n",
    "# clean team strings\n",
    "for c in [\"Home Team\", \"Away Team\"]:\n",
    "    if c in df_odds.columns:\n",
    "        df_odds[c] = df_odds[c].astype(str).str.strip()\n",
    "    if c in df_final.columns:\n",
    "        df_final[c] = df_final[c].astype(str).str.strip()\n",
    "if \"Team\" in df_rank.columns:\n",
    "    df_rank[\"Team\"] = df_rank[\"Team\"].astype(str).str.strip()\n",
    "\n",
    "pred_rows, pre_bets, total_pre = [], [], 0.0\n",
    "\n",
    "for _, r in df_odds.iterrows():\n",
    "    h, a = str(r[\"Home Team\"]), str(r[\"Away Team\"])\n",
    "\n",
    "    # odds cleaning\n",
    "    try:\n",
    "        oh, oa = float(r[\"Home Odds\"]), float(r[\"Away Odds\"])\n",
    "    except Exception:\n",
    "        # skip rows with missing/invalid odds\n",
    "        continue\n",
    "\n",
    "    # build feature row\n",
    "    X_one = build_features_for_match(h, a, df_final, df_rank, as_of_dt=as_of_dt, date_col=DATE_COL_IN_HISTORY)\n",
    "\n",
    "    # model probabilities\n",
    "    p_h = (\n",
    "        w_log * log_model.predict_proba(X_one)[:, 1].item()\n",
    "        + w_mlp * mlp_model.predict_proba(X_one)[:, 1].item()\n",
    "    )\n",
    "\n",
    "    # Kelly stakes (unscaled)\n",
    "    bh_pre = _kelly(p_h, oh) * BANKROLL\n",
    "    ba_pre = _kelly(1.0 - p_h, oa) * BANKROLL\n",
    "    pre_bets.append((bh_pre, ba_pre))\n",
    "    total_pre += bh_pre + ba_pre\n",
    "\n",
    "    pred_rows.append({\n",
    "        \"SlateDate\": TARGET_DATE.isoformat(),\n",
    "        \"Away Team\": a, \"Away Odds\": oa,\n",
    "        \"Home Team\": h, \"Home Odds\": oh,\n",
    "        \"p_home_ens\": round(p_h, 4)\n",
    "    })\n",
    "\n",
    "# scale proportionally if total stake > bankroll\n",
    "for i, row in enumerate(pred_rows):\n",
    "    bh, ba = pre_bets[i]\n",
    "    if BANKROLL > 0 and total_pre > BANKROLL:\n",
    "        s = BANKROLL / total_pre\n",
    "        bh, ba = bh * s, ba * s\n",
    "        row[\"Scaled\"] = True\n",
    "    else:\n",
    "        row[\"Scaled\"] = False\n",
    "    row[\"Home Bet\"] = int(round(bh)) if bh > 0 else 0\n",
    "    row[\"Away Bet\"] = int(round(ba)) if ba > 0 else 0\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows)\n",
    "cols = [\"SlateDate\",\"Away Team\",\"Away Odds\",\"Home Team\",\"Home Odds\",\"p_home_ens\",\"Home Bet\",\"Away Bet\",\"Scaled\"]\n",
    "print(pred_df[cols] if set(cols).issubset(pred_df.columns) else pred_df)\n",
    "\n",
    "# append/save\n",
    "mode = \"a\" if os.path.exists(PREDICTIONS_CSV) else \"w\"\n",
    "header = not os.path.exists(PREDICTIONS_CSV)\n",
    "pred_df.to_csv(PREDICTIONS_CSV, index=False, mode=mode, header=header)\n",
    "print(f\"\\nSaved {len(pred_df)} rows to {PREDICTIONS_CSV} (mode='{mode}', header={header})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b34069-01b8-41a3-b8e7-de1be82a8059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
