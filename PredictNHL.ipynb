{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e8471e4-1f8a-40ce-a22f-6323aa614e58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main f2c313e] Auto update (nb+data) - 2025-10-17 22:34:59\n",
      " 4 files changed, 1659 insertions(+), 1589 deletions(-)\n",
      "Current branch main is up to date.\n",
      "branch 'main' set up to track 'origin/main'.\n",
      "Pushed: PredictNHL.ipynb, enhanced_game_data.csv, predictions.csv, selected_features.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import hashlib, shutil, subprocess, os\n",
    "from datetime import datetime\n",
    "\n",
    "REPO   = Path(r\"C:\\Users\\Nic\\Desktop\\NHLPredictor\")\n",
    "DESK   = Path(r\"C:\\Users\\Nic\\Desktop\")\n",
    "NBNAME = \"PredictNHL.ipynb\"\n",
    "EXTS   = {\".csv\", \".json\", \".xlsx\"}\n",
    "BRANCH = \"main\"\n",
    "\n",
    "# --- Force a CSV to \"update\" even if content is the same ---\n",
    "FORCE_REFRESH_CSV = True\n",
    "CSV_WHITELIST = []  # e.g. [\"predictions.csv\", \"enhanced_game_data.csv\"]; empty = all CSVs in repo\n",
    "\n",
    "def sha(p):\n",
    "    import hashlib\n",
    "    h=hashlib.sha256()\n",
    "    with p.open(\"rb\") as f:\n",
    "        for b in iter(lambda:f.read(1<<20), b\"\"): h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def bump_csv_bytes(path: Path):\n",
    "    \"\"\"Toggle trailing newline to force a harmless byte change.\"\"\"\n",
    "    b = path.read_bytes()\n",
    "    if b.endswith(b\"\\n\"):\n",
    "        path.write_bytes(b.rstrip(b\"\\n\"))      # remove last newline\n",
    "    else:\n",
    "        path.write_bytes(b + b\"\\n\")            # add last newline\n",
    "\n",
    "def run(cmd):\n",
    "    r = subprocess.run(cmd, cwd=str(REPO), capture_output=True, text=True)\n",
    "    if r.stdout: print(r.stdout.strip())\n",
    "    if r.stderr and r.returncode != 0: print(r.stderr.strip())\n",
    "    return r.returncode\n",
    "\n",
    "assert REPO.exists()\n",
    "os.chdir(REPO)\n",
    "\n",
    "# 1) Build targets: notebook + tracked csv/json/xlsx\n",
    "targets = {NBNAME}\n",
    "targets |= {p.name for p in REPO.iterdir() if p.is_file() and p.suffix.lower() in EXTS}\n",
    "\n",
    "# 2) Copy Desktop -> repo when content differs\n",
    "changed = []\n",
    "for name in sorted(targets):\n",
    "    src, dst = DESK/name, REPO/name\n",
    "    if src.exists():\n",
    "        if (not dst.exists()) or sha(src) != sha(dst):\n",
    "            shutil.copy2(src, dst); changed.append(name)\n",
    "\n",
    "# 3) Optionally force-refresh CSVs (toggle EOF newline)\n",
    "if FORCE_REFRESH_CSV:\n",
    "    csvs = [p for p in REPO.iterdir() if p.is_file() and p.suffix.lower()==\".csv\"]\n",
    "    if CSV_WHITELIST:\n",
    "        csvs = [p for p in csvs if p.name in CSV_WHITELIST]\n",
    "    for p in csvs:\n",
    "        # only bump if not already modified by step 2 (to avoid double-noise)\n",
    "        if p.name not in changed:\n",
    "            bump_csv_bytes(p); changed.append(p.name)\n",
    "\n",
    "# 4) Commit & push (only if something actually changed)\n",
    "if changed:\n",
    "    run([\"git\",\"add\"] + changed)\n",
    "    msg = f\"Auto update (nb+data) - {datetime.now():%Y-%m-%d %H:%M:%S}\"\n",
    "    run([\"git\",\"commit\",\"-m\", msg])\n",
    "    run([\"git\",\"pull\",\"--rebase\",\"origin\", BRANCH])\n",
    "    run([\"git\",\"push\",\"-u\",\"origin\", BRANCH])\n",
    "    print(\"Pushed:\", \", \".join(changed))\n",
    "else:\n",
    "    print(\"Nothing to update. (No content changes and force-refresh off or nothing matched.)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0af2c54-99e1-49ea-a78d-1509524b2587",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (70.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/15.6 MB 8.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.1/15.6 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.6 MB 8.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.6/15.6 MB 8.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.9/15.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.0/15.6 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 9.4 MB/s  0:00:01\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from xgboost) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (1.41.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (5.29.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.19.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (0.13.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (1.6.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Requirement already satisfied: shap in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (2.0.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (1.14.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from lightgbm) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from lightgbm) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install xgboost\n",
    "!pip install streamlit\n",
    "!pip install imbalanced-learn\n",
    "!pip install shap\n",
    "!pip install statsmodels\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e8701d-ae59-47be-acc0-320e91c564b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, TimeSeriesSplit, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score, brier_score_loss, accuracy_score, log_loss, classification_report, make_scorer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import mutual_info_classif, RFECV, SelectFromModel, SelectKBest\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import re\n",
    "from scipy.stats import loguniform, uniform\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "import unicodedata\n",
    "import os, joblib\n",
    "from selenium import webdriver\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a78d45-fb52-49b6-b4ea-0d46d29c6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EXTRACT BOTH SEASONS\n",
    "SEASONS = [2025, 2026]\n",
    "FEATURES_STATS = {\n",
    "    'points_pct': 'PTS%', 'srs': 'SRS',\n",
    "    'goals_for_per_game': 'GF/G', 'goals_against_per_game': 'GA/G',\n",
    "    'power_play_pct': 'PP%', 'pen_kill_pct': 'PK%',\n",
    "    'save_pct': 'SV%', 'shots': 'S', 'shots_against': 'SA'\n",
    "}\n",
    "FEATURES_5V5 = {\n",
    "    'corsi_pct_5on5': 'CF%',\n",
    "    'fenwick_pct_5on5': 'FF%',\n",
    "    'exp_on_goals_for': 'xGF',\n",
    "    'exp_on_goals_against': 'xGA',\n",
    "    'hdsc_for_pct': 'HDCF%',\n",
    "    'pdo': 'PDO'\n",
    "}\n",
    "\n",
    "_clean = lambda n: n.replace('*', '').strip() if n else ''\n",
    "_to_num = lambda x: pd.to_numeric(str(x).replace('%', '').replace(',', '').strip(), errors='coerce')\n",
    "\n",
    "def scrape_season(season):\n",
    "    url = f\"https://www.hockey-reference.com/leagues/NHL_{season}.html\"\n",
    "\n",
    "    with webdriver.Chrome() as driver:\n",
    "        driver.get(url)\n",
    "        time.sleep(2.5)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    table_stats = soup.find('table', id='stats')\n",
    "    records = []\n",
    "    for i, row in enumerate(table_stats.find_all('tr')[1:]):\n",
    "        cols = row.find_all('td')\n",
    "        if not cols: continue\n",
    "        team = _clean(cols[0].text)\n",
    "        if team == \"League Average\": continue\n",
    "        rec = {'Team': team, 'Rank': i + 1}\n",
    "        for k, lbl in FEATURES_STATS.items():\n",
    "            el = row.find(\"td\", {\"data-stat\": k})\n",
    "            rec[lbl] = _to_num(el.text) if el else None\n",
    "        records.append(rec)\n",
    "    df_stats = pd.DataFrame(records)\n",
    "    df_stats[\"Season\"] = season\n",
    "\n",
    "    #Stats #5v5\n",
    "    table_adv = None\n",
    "    for c in soup.find_all(string=lambda t: isinstance(t, Comment)):\n",
    "        if 'stats_adv' in c:\n",
    "            table_adv = BeautifulSoup(c, 'html.parser').find('table', id='stats_adv')\n",
    "            break\n",
    "\n",
    "    adv_records = []\n",
    "    for row in table_adv.find_all('tr')[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        if not cols: continue\n",
    "        team = _clean(cols[0].text)\n",
    "        if team == \"League Average\": continue\n",
    "        rec = {'Team': team}\n",
    "        for k, lbl in FEATURES_5V5.items():\n",
    "            el = row.find(\"td\", {\"data-stat\": k}) or row.find(\"td\", {\"data-stat\": k.lower()}) or row.find(\"td\", {\"data-stat\": k.upper()})\n",
    "            rec[lbl] = _to_num(el.text) if el else None\n",
    "        adv_records.append(rec)\n",
    "\n",
    "    df_5v5 = pd.DataFrame(adv_records)\n",
    "    df_5v5[\"xGF%\"] = (df_5v5[\"xGF\"] / (df_5v5[\"xGF\"] + df_5v5[\"xGA\"]) * 100).round(1)\n",
    "    df_5v5[\"Season\"] = season\n",
    "\n",
    "    # ---------- MERGE ----------\n",
    "    df = (\n",
    "        pd.merge(df_stats, df_5v5, on=[\"Team\", \"Season\"], how=\"left\")\n",
    "          .sort_values(\"Rank\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df_2025 = scrape_season(2025)\n",
    "df_2026 = scrape_season(2026)\n",
    "\n",
    "# Combine both datasets\n",
    "df_combined = pd.concat([df_2025, df_2026], ignore_index=True).sort_values([\"Team\", \"Season\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00ddb38-a370-48ed-a70a-f0bea4f8315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "UA = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "TIMEZONE = \"America/Toronto\"\n",
    "\n",
    "def to_csv_url(url: str) -> str:\n",
    "    return re.sub(r\"/results/(nhl-\\d{4})$\", r\"/download/\\1-UTC.csv\", url)\n",
    "\n",
    "def parse_datetime_column(s: pd.Series) -> pd.Series:\n",
    "    dt = pd.to_datetime(s, errors=\"coerce\", utc=True, dayfirst=True)\n",
    "    fallback = dt.isna()\n",
    "    if fallback.any():\n",
    "        dt.loc[fallback] = pd.to_datetime(s[fallback], errors=\"coerce\", utc=True, dayfirst=False)\n",
    "    return dt\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# TEAM NORMALIZATION SECTION\n",
    "# ==========================\n",
    "\n",
    "TEAM_NAME_MAP = {\n",
    "    \"Montreal Canadiens\": \"Montreal Canadiens\",\n",
    "    \"Montréal Canadiens\": \"Montreal Canadiens\",\n",
    "\n",
    "    \"Utah Hockey Club\": \"Utah Mammoth\",\n",
    "    \"Utah HC\": \"Utah Mammoth\",\n",
    "    \"Utah Hockey C\": \"Utah Mammoth\",\n",
    "    \"Utah Mammoth\": \"Utah Mammoth\",\n",
    "}\n",
    "\n",
    "def normalize_team_name(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = str(s).strip()\n",
    "\n",
    "    # Remove accents\n",
    "    s = \"\".join(c for c in unicodedata.normalize(\"NFKD\", s)\n",
    "                if not unicodedata.combining(c))\n",
    "\n",
    "    # Normalize multiple spaces\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
    "\n",
    "    return TEAM_NAME_MAP.get(s, s)\n",
    "\n",
    "\n",
    "def load_game_results(url: str) -> pd.DataFrame:\n",
    "    csv_url = to_csv_url(url)\n",
    "    try:\n",
    "        df = pd.read_csv(csv_url)\n",
    "    except:\n",
    "        r = requests.get(csv_url, headers=UA, timeout=20)\n",
    "        r.raise_for_status()\n",
    "        df = pd.read_csv(StringIO(r.text))\n",
    "\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    lc = {col.lower(): col for col in df.columns}\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"Date_str\": df[lc.get(\"date\")],\n",
    "        \"Home Team\": df[lc.get(\"home team\", \"home\")],\n",
    "        \"Away Team\": df[lc.get(\"away team\", \"away\")],\n",
    "    })\n",
    "\n",
    "    # Scores\n",
    "    if \"Home Score\" in df.columns and \"Away Score\" in df.columns:\n",
    "        out[\"Home Score\"] = pd.to_numeric(df[\"Home Score\"], errors=\"coerce\")\n",
    "        out[\"Away Score\"] = pd.to_numeric(df[\"Away Score\"], errors=\"coerce\")\n",
    "    elif \"Score\" in df.columns:\n",
    "        scores = df[\"Score\"].astype(str).str.extract(r\"(\\d+)\\s*[-–−]\\s*(\\d+)\")\n",
    "        out[\"Home Score\"] = pd.to_numeric(scores[0], errors=\"coerce\")\n",
    "        out[\"Away Score\"] = pd.to_numeric(scores[1], errors=\"coerce\")\n",
    "    else:\n",
    "        out[\"Home Score\"] = pd.NA\n",
    "        out[\"Away Score\"] = pd.NA\n",
    "\n",
    "    # Fill from \"result\"\n",
    "    if \"result\" in lc:\n",
    "        missing = out[\"Home Score\"].isna() | out[\"Away Score\"].isna()\n",
    "        result_scores = df[lc[\"result\"]].astype(str).str.extract(r\"(\\d+)\\s*[-–−]\\s*(\\d+)\")\n",
    "        out.loc[missing, \"Home Score\"] = pd.to_numeric(result_scores[0], errors=\"coerce\")\n",
    "        out.loc[missing, \"Away Score\"] = pd.to_numeric(result_scores[1], errors=\"coerce\")\n",
    "\n",
    "    out[\"Date_UTC\"] = parse_datetime_column(out[\"Date_str\"])\n",
    "    out[\"Date_Local\"] = out[\"Date_UTC\"].dt.tz_convert(TIMEZONE)\n",
    "    out[\"LocalDate\"] = out[\"Date_Local\"].dt.date\n",
    "\n",
    "    # Clean rows\n",
    "    out = (\n",
    "        out.dropna(subset=[\"Date_UTC\"])\n",
    "           .sort_values(\"Date_UTC\")\n",
    "           .drop_duplicates(subset=[\"Date_UTC\", \"Home Team\", \"Away Team\"], keep=\"last\")\n",
    "           .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Normalize TEAM NAMES exactly ONCE\n",
    "    for col in [\"Home Team\", \"Away Team\"]:\n",
    "        out[col] = out[col].apply(normalize_team_name)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0140f76-bad9-4cce-84ab-2705257e6cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ df_all built: (2624, 11)\n",
      "✔ df_games_master built: (2624, 7)\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# ==== BUILD df_all AFTER loading game results ====\n",
    "# ================================================\n",
    "\n",
    "df_2024 = load_game_results(\"https://fixturedownload.com/results/nhl-2024\")\n",
    "df_2024[\"Season\"], df_2024[\"weight\"] = \"2024-2025\", 1.0\n",
    "\n",
    "df_2025 = load_game_results(\"https://fixturedownload.com/results/nhl-2025\")\n",
    "df_2025[\"Season\"], df_2025[\"weight\"] = \"2025-2026\", 2.0\n",
    "\n",
    "df_all = pd.concat([df_2024, df_2025], ignore_index=True)\n",
    "\n",
    "# Played flag\n",
    "df_all[\"Played\"] = df_all[\"Home Score\"].notna() & df_all[\"Away Score\"].notna()\n",
    "\n",
    "# Build master list\n",
    "df_games_master = (\n",
    "    df_all[[\"LocalDate\", \"Home Team\", \"Away Team\", \"Home Score\", \"Away Score\", \"Season\", \"Played\"]]\n",
    "        .rename(columns={\"LocalDate\": \"Date\"})\n",
    "        .sort_values(\"Date\")\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"✔ df_all built:\", df_all.shape)\n",
    "print(\"✔ df_games_master built:\", df_games_master.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ac4720-ca45-4059-81f6-1abda6d891e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ df_final built: (1722, 12)\n",
      "           Date_str          Home Team           Away Team Home Score  \\\n",
      "0  04/10/2024 17:00     Buffalo Sabres   New Jersey Devils          1   \n",
      "1  05/10/2024 14:00  New Jersey Devils      Buffalo Sabres          3   \n",
      "2  08/10/2024 20:30     Seattle Kraken     St. Louis Blues          2   \n",
      "3  08/10/2024 23:00   Florida Panthers       Boston Bruins          6   \n",
      "4  09/10/2024 02:00       Utah Mammoth  Chicago Blackhawks          5   \n",
      "\n",
      "  Away Score                  Date_UTC                Date_Local   LocalDate  \\\n",
      "0          4 2024-10-04 17:00:00+00:00 2024-10-04 13:00:00-04:00  2024-10-04   \n",
      "1          1 2024-10-05 14:00:00+00:00 2024-10-05 10:00:00-04:00  2024-10-05   \n",
      "2          3 2024-10-08 20:30:00+00:00 2024-10-08 16:30:00-04:00  2024-10-08   \n",
      "3          4 2024-10-08 23:00:00+00:00 2024-10-08 19:00:00-04:00  2024-10-08   \n",
      "4          2 2024-10-09 02:00:00+00:00 2024-10-08 22:00:00-04:00  2024-10-08   \n",
      "\n",
      "      Season  weight  Played       Date  \n",
      "0  2024-2025     1.0    True 2024-10-04  \n",
      "1  2024-2025     1.0    True 2024-10-05  \n",
      "2  2024-2025     1.0    True 2024-10-08  \n",
      "3  2024-2025     1.0    True 2024-10-08  \n",
      "4  2024-2025     1.0    True 2024-10-08  \n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# ==== BUILD df_final (Played only) ===\n",
    "# =====================================\n",
    "\n",
    "df_final = (\n",
    "    df_all[df_all[\"Played\"]]\n",
    "    .copy()\n",
    "    .sort_values(\"LocalDate\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Standardize \"Date\" used by the model\n",
    "df_final[\"Date\"] = df_final[\"LocalDate\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "print(\"✔ df_final built:\", df_final.shape)\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1682fe-26a9-4a15-92ba-893ccb32f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATA MANIPULATION ---\n",
    "\n",
    "df_final[\"Date\"] = df_final[\"Date_Local\"].dt.tz_localize(None)\n",
    "\n",
    "# Add Home Win flag if missing\n",
    "if \"Home Win\" not in df_final.columns:\n",
    "    df_final[\"Home Win\"] = (df_final[\"Home Score\"] > df_final[\"Away Score\"]).astype(bool)\n",
    "\n",
    "# Sort by chronological order\n",
    "df_final = df_final.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- 1️⃣ LAST 10 WINS ---\n",
    "def calculate_last_10_stats(df, team_column):\n",
    "    last_10_wins = []\n",
    "    team_games = {}  # Key: (team, season)\n",
    "    for _, row in df.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        team = row[team_column]\n",
    "        key = (team, season)\n",
    "        recent_games = team_games.get(key, [])[-10:]\n",
    "        last_10_wins.append(sum(recent_games))\n",
    "        home_key = (row[\"Home Team\"], season)\n",
    "        away_key = (row[\"Away Team\"], season)\n",
    "        team_games.setdefault(home_key, []).append(row[\"Home Win\"])\n",
    "        team_games.setdefault(away_key, []).append(not row[\"Home Win\"])\n",
    "    return last_10_wins\n",
    "\n",
    "df_final[\"Home Last 10 Wins\"] = calculate_last_10_stats(df_final, \"Home Team\")\n",
    "df_final[\"Away Last 10 Wins\"] = calculate_last_10_stats(df_final, \"Away Team\")\n",
    "\n",
    "\n",
    "# --- 2️⃣ PLAYED YESTERDAY ---\n",
    "def calculate_played_yesterday(df):\n",
    "    last_game_date = {}\n",
    "    home_played_yesterday, away_played_yesterday = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        date = row[\"Date\"]\n",
    "        home = row[\"Home Team\"]\n",
    "        away = row[\"Away Team\"]\n",
    "        yesterday = date - pd.Timedelta(days=1)\n",
    "        home_key = (home, season)\n",
    "        away_key = (away, season)\n",
    "        home_played_yesterday.append(last_game_date.get(home_key) == yesterday)\n",
    "        away_played_yesterday.append(last_game_date.get(away_key) == yesterday)\n",
    "        last_game_date[home_key] = date\n",
    "        last_game_date[away_key] = date\n",
    "    return home_played_yesterday, away_played_yesterday\n",
    "\n",
    "df_final[\"Home Played Yesterday\"], df_final[\"Away Played Yesterday\"] = calculate_played_yesterday(df_final)\n",
    "\n",
    "\n",
    "# --- 3️⃣ WIN RATE ---\n",
    "def calculate_win_rate(df, team_column, is_home_column):\n",
    "    win_rate = []\n",
    "    team_stats = {}  # Key: (team, season)\n",
    "    for _, row in df.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        team = row[team_column]\n",
    "        key = (team, season)\n",
    "        stats = team_stats.setdefault(key, {\"wins\": 0, \"games\": 0})\n",
    "        win_rate.append(stats[\"wins\"] / stats[\"games\"] if stats[\"games\"] > 0 else 0)\n",
    "        stats[\"wins\"] += row[\"Home Win\"] if is_home_column else not row[\"Home Win\"]\n",
    "        stats[\"games\"] += 1\n",
    "    return win_rate\n",
    "\n",
    "df_final[\"Home Win Rate\"] = calculate_win_rate(df_final, \"Home Team\", is_home_column=True)\n",
    "df_final[\"Away Win Rate\"] = calculate_win_rate(df_final, \"Away Team\", is_home_column=False)\n",
    "\n",
    "\n",
    "# --- 4️⃣ OVERALL STREAK ---\n",
    "def calculate_overall_win_streak(df):\n",
    "    streak = {}\n",
    "    home_streaks, away_streaks = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        home_key = (row[\"Home Team\"], season)\n",
    "        away_key = (row[\"Away Team\"], season)\n",
    "        home_streaks.append(streak.get(home_key, 0))\n",
    "        away_streaks.append(streak.get(away_key, 0))\n",
    "        if row[\"Home Win\"]:\n",
    "            streak[home_key] = streak.get(home_key, 0) + 1\n",
    "            streak[away_key] = 0\n",
    "        else:\n",
    "            streak[home_key] = 0\n",
    "            streak[away_key] = streak.get(away_key, 0) + 1\n",
    "    return home_streaks, away_streaks\n",
    "\n",
    "home_streaks, away_streaks = calculate_overall_win_streak(df_final)\n",
    "df_final[\"Home Team Overall Win Streak Before Game\"] = home_streaks\n",
    "df_final[\"Away Team Overall Win Streak Before Game\"] = away_streaks\n",
    "\n",
    "\n",
    "# --- 5️⃣ REST DAYS ---\n",
    "OFFSEASON_GAP_DAYS = 45\n",
    "def calculate_days_since_last_game(df, gap=OFFSEASON_GAP_DAYS):\n",
    "    last_game_date = {}\n",
    "    home_rest, away_rest = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        date = row[\"Date\"]\n",
    "        home_key = (row[\"Home Team\"], season)\n",
    "        away_key = (row[\"Away Team\"], season)\n",
    "        prev_home = last_game_date.get(home_key)\n",
    "        prev_away = last_game_date.get(away_key)\n",
    "        home_rest.append((date - prev_home).days if prev_home and (date - prev_home).days <= gap else None)\n",
    "        away_rest.append((date - prev_away).days if prev_away and (date - prev_away).days <= gap else None)\n",
    "        last_game_date[home_key] = date\n",
    "        last_game_date[away_key] = date\n",
    "    return home_rest, away_rest\n",
    "\n",
    "df_final[\"Home Rest Days Since Last Game\"], df_final[\"Away Rest Days Since Last Game\"] = calculate_days_since_last_game(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6507280b-353c-4375-ac48-415d2b8060dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_final[\"Home Advantage\"] = df_final[\"Home Win Rate\"] - df_final[\"Away Win Rate\"]\n",
    "df_final[\"Win Streak Impact\"] = df_final[\"Home Team Overall Win Streak Before Game\"] - df_final[\"Away Team Overall Win Streak Before Game\"]\n",
    "df_final[\"Last 10 Wins\"] = df_final[\"Home Last 10 Wins\"] - df_final[\"Away Last 10 Wins\"]\n",
    "df_final = df_final.dropna().reset_index(drop=True)\n",
    "df_final[\"Date\"] = pd.to_datetime(df_final[\"Date\"])\n",
    "games_2025 = df_final[df_final[\"Date\"] < \"2025-10-01\"].copy()\n",
    "games_2026 = df_final[df_final[\"Date\"] >= \"2025-10-01\"].copy()\n",
    "stats_2025 = df_combined[df_combined[\"Season\"] == 2025].copy()\n",
    "stats_2025[\"Team\"] = stats_2025[\"Team\"].astype(str).str.strip()\n",
    "games_2025 = games_2025.merge(\n",
    "    stats_2025.add_prefix(\"Home_\"), left_on=\"Home Team\", right_on=\"Home_Team\", how=\"left\"\n",
    ")\n",
    "games_2025 = games_2025.merge(\n",
    "    stats_2025.add_prefix(\"Away_\"), left_on=\"Away Team\", right_on=\"Away_Team\", how=\"left\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6c2c58-2386-462d-96ce-429814728d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date_str             Home Team              Away Team  \\\n",
      "0     05/10/2024 14:00     New Jersey Devils         Buffalo Sabres   \n",
      "1     10/10/2024 23:00         Boston Bruins     Montreal Canadiens   \n",
      "2     10/10/2024 23:00     New Jersey Devils    Toronto Maple Leafs   \n",
      "3     12/10/2024 00:00         Winnipeg Jets     Chicago Blackhawks   \n",
      "4     12/10/2024 02:00  Vegas Golden Knights        St. Louis Blues   \n",
      "...                ...                   ...                    ...   \n",
      "1677  02/12/2025 00:00   Philadelphia Flyers    Pittsburgh Penguins   \n",
      "1678  02/12/2025 00:00     New Jersey Devils  Columbus Blue Jackets   \n",
      "1679  02/12/2025 00:30        Buffalo Sabres          Winnipeg Jets   \n",
      "1680  02/12/2025 01:00       St. Louis Blues          Anaheim Ducks   \n",
      "1681  02/12/2025 03:00       San Jose Sharks           Utah Mammoth   \n",
      "\n",
      "     Home Score Away Score                  Date_UTC  \\\n",
      "0             3          1 2024-10-05 14:00:00+00:00   \n",
      "1             6          4 2024-10-10 23:00:00+00:00   \n",
      "2             2          4 2024-10-10 23:00:00+00:00   \n",
      "3             2          1 2024-10-12 00:00:00+00:00   \n",
      "4             4          3 2024-10-12 02:00:00+00:00   \n",
      "...         ...        ...                       ...   \n",
      "1677        1.0        5.0 2025-12-02 00:00:00+00:00   \n",
      "1678        3.0        5.0 2025-12-02 00:00:00+00:00   \n",
      "1679        5.0        1.0 2025-12-02 00:30:00+00:00   \n",
      "1680        1.0        4.0 2025-12-02 01:00:00+00:00   \n",
      "1681        6.0        3.0 2025-12-02 03:00:00+00:00   \n",
      "\n",
      "                    Date_Local   LocalDate     Season  weight  ...  \\\n",
      "0    2024-10-05 10:00:00-04:00  2024-10-05  2024-2025     1.0  ...   \n",
      "1    2024-10-10 19:00:00-04:00  2024-10-10  2024-2025     1.0  ...   \n",
      "2    2024-10-10 19:00:00-04:00  2024-10-10  2024-2025     1.0  ...   \n",
      "3    2024-10-11 20:00:00-04:00  2024-10-11  2024-2025     1.0  ...   \n",
      "4    2024-10-11 22:00:00-04:00  2024-10-11  2024-2025     1.0  ...   \n",
      "...                        ...         ...        ...     ...  ...   \n",
      "1677 2025-12-01 19:00:00-05:00  2025-12-01  2025-2026     2.0  ...   \n",
      "1678 2025-12-01 19:00:00-05:00  2025-12-01  2025-2026     2.0  ...   \n",
      "1679 2025-12-01 19:30:00-05:00  2025-12-01  2025-2026     2.0  ...   \n",
      "1680 2025-12-01 20:00:00-05:00  2025-12-01  2025-2026     2.0  ...   \n",
      "1681 2025-12-01 22:00:00-05:00  2025-12-01  2025-2026     2.0  ...   \n",
      "\n",
      "      Away Played Yesterday Home Win Rate  Away Win Rate  \\\n",
      "0                     False      0.000000       0.000000   \n",
      "1                      True      0.000000       0.000000   \n",
      "2                      True      1.000000       0.000000   \n",
      "3                     False      0.000000       0.000000   \n",
      "4                     False      1.000000       1.000000   \n",
      "...                     ...           ...            ...   \n",
      "1677                  False      0.615385       0.500000   \n",
      "1678                  False      0.818182       0.428571   \n",
      "1679                  False      0.533333       0.538462   \n",
      "1680                  False      0.357143       0.461538   \n",
      "1681                  False      0.533333       0.333333   \n",
      "\n",
      "      Home Team Overall Win Streak Before Game  \\\n",
      "0                                            1   \n",
      "1                                            0   \n",
      "2                                            2   \n",
      "3                                            1   \n",
      "4                                            1   \n",
      "...                                        ...   \n",
      "1677                                         3   \n",
      "1678                                         0   \n",
      "1679                                         1   \n",
      "1680                                         2   \n",
      "1681                                         0   \n",
      "\n",
      "      Away Team Overall Win Streak Before Game  \\\n",
      "0                                            0   \n",
      "1                                            1   \n",
      "2                                            0   \n",
      "3                                            0   \n",
      "4                                            2   \n",
      "...                                        ...   \n",
      "1677                                         0   \n",
      "1678                                         0   \n",
      "1679                                         1   \n",
      "1680                                         0   \n",
      "1681                                         0   \n",
      "\n",
      "      Home Rest Days Since Last Game  Away Rest Days Since Last Game  \\\n",
      "0                                0.0                             0.0   \n",
      "1                                2.0                             1.0   \n",
      "2                                5.0                             1.0   \n",
      "3                                1.0                             2.0   \n",
      "4                                2.0                             0.0   \n",
      "...                              ...                             ...   \n",
      "1677                             2.0                             2.0   \n",
      "1678                             2.0                             3.0   \n",
      "1679                             1.0                             2.0   \n",
      "1680                             2.0                             1.0   \n",
      "1681                             2.0                             2.0   \n",
      "\n",
      "      Home Advantage  Win Streak Impact  Last 10 Wins  \n",
      "0           0.000000                  1             1  \n",
      "1           0.000000                 -1            -1  \n",
      "2           1.000000                  2             2  \n",
      "3           0.000000                  1             1  \n",
      "4           0.000000                 -1            -1  \n",
      "...              ...                ...           ...  \n",
      "1677        0.115385                  3             2  \n",
      "1678        0.389610                  0             1  \n",
      "1679       -0.005128                  0             1  \n",
      "1680       -0.104396                  2             0  \n",
      "1681        0.200000                  0             2  \n",
      "\n",
      "[1682 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6091e974-0f5e-42fa-a2a3-eedf1b1c5e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Snapshot saved for 2025-12-03. Total entries: 416\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SNAPSHOT_PATH = \"team_snapshots.csv\"\n",
    "SNAPSHOT_SEASON = 2026\n",
    "\n",
    "today = pd.Timestamp.now().normalize().date()\n",
    "\n",
    "snapshot = df_combined[df_combined[\"Season\"] == SNAPSHOT_SEASON].copy()\n",
    "snapshot[\"Snapshot Date\"] = pd.Timestamp(today)\n",
    "snapshot[\"Team\"] = snapshot[\"Team\"].astype(str).str.strip()\n",
    "\n",
    "if os.path.exists(SNAPSHOT_PATH):\n",
    "    df_existing = pd.read_csv(SNAPSHOT_PATH, parse_dates=[\"Snapshot Date\"])\n",
    "    df_existing = df_existing[df_existing[\"Snapshot Date\"] != pd.Timestamp(today)]\n",
    "    df_all_snapshots = pd.concat([df_existing, snapshot], ignore_index=True)\n",
    "else:\n",
    "    df_all_snapshots = snapshot\n",
    "\n",
    "df_all_snapshots.to_csv(SNAPSHOT_PATH, index=False)\n",
    "print(f\"✅ Snapshot saved for {today}. Total entries: {len(df_all_snapshots)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca97918-50e1-4367-9aa7-a0a9b403ed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged: 2024-2025 uses final stats, 2025-2026 uses dynamic snapshots.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "snapshots = pd.read_csv(\"team_snapshots.csv\", parse_dates=[\"Snapshot Date\"])\n",
    "snapshots[\"Team\"] = snapshots[\"Team\"].astype(str).str.strip()\n",
    "\n",
    "final_2025_stats = df_combined[df_combined[\"Season\"] == 2025].copy()\n",
    "final_2025_stats[\"Team\"] = final_2025_stats[\"Team\"].astype(str).str.strip()\n",
    "final_2025_stats[\"Snapshot Date\"] = pd.Timestamp(\"2025-07-01\")  # after season end\n",
    "final_2025_stats[\"Season\"] = \"2024-2025\"\n",
    "\n",
    "def merge_snapshot_stats(df_games, df_snapshots, team_column, prefix):\n",
    "    result = []\n",
    "\n",
    "    for idx, row in df_games.iterrows():\n",
    "        game_date = row[\"Date\"]\n",
    "        team = row[team_column]\n",
    "        season = row[\"Season\"]\n",
    "\n",
    "        if season == \"2025-2026\":\n",
    "            # ✅ Dynamic: use most recent snapshot for ongoing season\n",
    "            team_snapshots = df_snapshots[\n",
    "                (df_snapshots[\"Team\"] == team)\n",
    "                & (df_snapshots[\"Snapshot Date\"] <= game_date)\n",
    "            ]\n",
    "            if not team_snapshots.empty:\n",
    "                latest_snapshot = team_snapshots.sort_values(\"Snapshot Date\").iloc[-1]\n",
    "                renamed = latest_snapshot.rename(lambda x: f\"{prefix}_{x}\" if x not in [\"Team\"] else x)\n",
    "                result.append(renamed)\n",
    "                continue\n",
    "\n",
    "        elif season == \"2024-2025\":\n",
    "            # ✅ Static: use final 2025 stats\n",
    "            team_stats = final_2025_stats[final_2025_stats[\"Team\"] == team]\n",
    "            if not team_stats.empty:\n",
    "                latest_snapshot = team_stats.iloc[-1]\n",
    "                renamed = latest_snapshot.rename(lambda x: f\"{prefix}_{x}\" if x not in [\"Team\"] else x)\n",
    "                result.append(renamed)\n",
    "                continue\n",
    "\n",
    "        # ❌ No data found\n",
    "        result.append(pd.Series(dtype=\"float64\"))\n",
    "\n",
    "    snapshot_df = pd.DataFrame(result, index=df_games.index)\n",
    "    return pd.concat([df_games, snapshot_df], axis=1)\n",
    "\n",
    "# --- Apply to both Home and Away teams ---\n",
    "df_final = merge_snapshot_stats(df_final, snapshots, team_column=\"Home Team\", prefix=\"Home\")\n",
    "df_final = merge_snapshot_stats(df_final, snapshots, team_column=\"Away Team\", prefix=\"Away\")\n",
    "\n",
    "# --- Save and confirm ---\n",
    "df_final.to_csv(\"games_with_snapshots.csv\", index=False)\n",
    "print(\"✅ Merged: 2024-2025 uses final stats, 2025-2026 uses dynamic snapshots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf75e840-a4da-434a-8429-f7e7c31b19a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date_str             Home Team              Away Team  \\\n",
      "0     05/10/2024 14:00     New Jersey Devils         Buffalo Sabres   \n",
      "1     10/10/2024 23:00         Boston Bruins     Montreal Canadiens   \n",
      "2     10/10/2024 23:00     New Jersey Devils    Toronto Maple Leafs   \n",
      "3     12/10/2024 00:00         Winnipeg Jets     Chicago Blackhawks   \n",
      "4     12/10/2024 02:00  Vegas Golden Knights        St. Louis Blues   \n",
      "...                ...                   ...                    ...   \n",
      "1677  02/12/2025 00:00   Philadelphia Flyers    Pittsburgh Penguins   \n",
      "1678  02/12/2025 00:00     New Jersey Devils  Columbus Blue Jackets   \n",
      "1679  02/12/2025 00:30        Buffalo Sabres          Winnipeg Jets   \n",
      "1680  02/12/2025 01:00       St. Louis Blues          Anaheim Ducks   \n",
      "1681  02/12/2025 03:00       San Jose Sharks           Utah Mammoth   \n",
      "\n",
      "     Home Score Away Score                  Date_UTC  \\\n",
      "0             3          1 2024-10-05 14:00:00+00:00   \n",
      "1             6          4 2024-10-10 23:00:00+00:00   \n",
      "2             2          4 2024-10-10 23:00:00+00:00   \n",
      "3             2          1 2024-10-12 00:00:00+00:00   \n",
      "4             4          3 2024-10-12 02:00:00+00:00   \n",
      "...         ...        ...                       ...   \n",
      "1677        1.0        5.0 2025-12-02 00:00:00+00:00   \n",
      "1678        3.0        5.0 2025-12-02 00:00:00+00:00   \n",
      "1679        5.0        1.0 2025-12-02 00:30:00+00:00   \n",
      "1680        1.0        4.0 2025-12-02 01:00:00+00:00   \n",
      "1681        6.0        3.0 2025-12-02 03:00:00+00:00   \n",
      "\n",
      "                    Date_Local   LocalDate     Season  weight  ...  Away_SA  \\\n",
      "0    2024-10-05 10:00:00-04:00  2024-10-05  2024-2025     1.0  ...   2368.0   \n",
      "1    2024-10-10 19:00:00-04:00  2024-10-10  2024-2025     1.0  ...   2383.0   \n",
      "2    2024-10-10 19:00:00-04:00  2024-10-10  2024-2025     1.0  ...   2405.0   \n",
      "3    2024-10-11 20:00:00-04:00  2024-10-11  2024-2025     1.0  ...   2550.0   \n",
      "4    2024-10-11 22:00:00-04:00  2024-10-11  2024-2025     1.0  ...   2236.0   \n",
      "...                        ...         ...        ...     ...  ...      ...   \n",
      "1677 2025-12-01 19:00:00-05:00  2025-12-01  2025-2026     2.0  ...    679.0   \n",
      "1678 2025-12-01 19:00:00-05:00  2025-12-01  2025-2026     2.0  ...    770.0   \n",
      "1679 2025-12-01 19:30:00-05:00  2025-12-01  2025-2026     2.0  ...    699.0   \n",
      "1680 2025-12-01 20:00:00-05:00  2025-12-01  2025-2026     2.0  ...    718.0   \n",
      "1681 2025-12-01 22:00:00-05:00  2025-12-01  2025-2026     2.0  ...    625.0   \n",
      "\n",
      "     Away_Season  Away_CF%  Away_FF%  Away_xGF  Away_xGA  Away_HDCF%  \\\n",
      "0      2024-2025      50.4      49.4     158.5     181.0        45.8   \n",
      "1      2024-2025      48.2      47.4     160.1     176.0        44.5   \n",
      "2      2024-2025      48.1      48.2     173.6     163.0        47.5   \n",
      "3      2024-2025      44.8      43.7     146.6     195.4        40.5   \n",
      "4      2024-2025      49.2      48.7     169.0     152.5        48.0   \n",
      "...          ...       ...       ...       ...       ...         ...   \n",
      "1677        2026      49.6      49.4      56.2      55.6        46.5   \n",
      "1678        2026      51.1      49.9      55.7      60.4        51.7   \n",
      "1679        2026      46.6      46.0      46.5      52.7        45.1   \n",
      "1680        2026      51.6      50.6      49.2      59.8        51.5   \n",
      "1681        2026      54.5      54.9      58.1      48.9        52.4   \n",
      "\n",
      "      Away_PDO  Away_xGF%  Away_Snapshot Date  \n",
      "0        100.4       46.7          2025-07-01  \n",
      "1         99.7       47.6          2025-07-01  \n",
      "2        101.7       51.6          2025-07-01  \n",
      "3         99.3       42.9          2025-07-01  \n",
      "4        101.4       52.6          2025-07-01  \n",
      "...        ...        ...                 ...  \n",
      "1677      99.4       50.3          2025-11-30  \n",
      "1678      99.6       48.0          2025-11-30  \n",
      "1679     101.3       46.9          2025-11-30  \n",
      "1680     100.9       45.1          2025-11-30  \n",
      "1681      98.3       54.3          2025-11-30  \n",
      "\n",
      "[1682 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_final)\n",
    "df_final.to_csv(\"df_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed30122-bf99-4dc9-b546-6900773d69b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final dataset exported: df_final_with_rank_features.csv\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ RANK DIFFERENCE\n",
    "if \"Home_Rank\" in df_final.columns and \"Away_Rank\" in df_final.columns:\n",
    "    df_final[\"Rank Difference\"] = df_final[\"Home_Rank\"] - df_final[\"Away_Rank\"]\n",
    "else:\n",
    "    print(\"⚠️ Columns Home_Rank / Away_Rank not found. Skipping Rank Difference.\")\n",
    "\n",
    "\n",
    "# 2️⃣ RELATIVE SRS (strength differential)\n",
    "if \"Home_SRS\" in df_final.columns and \"Away_SRS\" in df_final.columns:\n",
    "    df_final[\"SRS_Diff\"] = df_final[\"Home_SRS\"] - df_final[\"Away_SRS\"]\n",
    "else:\n",
    "    print(\"⚠️ Columns Home_SRS / Away_SRS not found. Skipping SRS_Diff.\")\n",
    "\n",
    "\n",
    "# 3️⃣ OPPONENT STRENGTH (rolling average of opponents' ranks)\n",
    "def calculate_avg_opponent_rank(df):\n",
    "    team_opponent_ranks = {team: [] for team in pd.concat([df[\"Home Team\"], df[\"Away Team\"]]).unique()}\n",
    "    home_strengths, away_strengths = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        home = row[\"Home Team\"]\n",
    "        away = row[\"Away Team\"]\n",
    "        home_opponents = team_opponent_ranks[home]\n",
    "        away_opponents = team_opponent_ranks[away]\n",
    "\n",
    "        # average of last 10 opponents’ ranks before this game\n",
    "        home_strengths.append(np.mean(home_opponents[-10:]) if home_opponents else np.nan)\n",
    "        away_strengths.append(np.mean(away_opponents[-10:]) if away_opponents else np.nan)\n",
    "\n",
    "        # update AFTER the current game (to avoid data leakage)\n",
    "        if not pd.isna(row.get(\"Away_Rank\", np.nan)):\n",
    "            team_opponent_ranks[home].append(row[\"Away_Rank\"])\n",
    "        if not pd.isna(row.get(\"Home_Rank\", np.nan)):\n",
    "            team_opponent_ranks[away].append(row[\"Home_Rank\"])\n",
    "\n",
    "    return home_strengths, away_strengths\n",
    "\n",
    "\n",
    "df_final[\"Home Opponent Strength\"], df_final[\"Away Opponent Strength\"] = calculate_avg_opponent_rank(df_final)\n",
    "\n",
    "\n",
    "# 4️⃣ CLEAN-UP (optional)\n",
    "df_final = df_final.dropna(subset=[\"Home_Rank\", \"Away_Rank\"])\n",
    "df_final = df_final.dropna().reset_index(drop=True)\n",
    "\n",
    "# 5️⃣ EXPORT\n",
    "df_final.to_csv(\"df_final_with_rank_features.csv\", index=False)\n",
    "print(\"✅ Final dataset exported: df_final_with_rank_features.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89c7fdff-562e-4210-8890-a4e8a975d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Always Home) — F1: 0.4057, ROC AUC: 0.5, Brier: 0.4369\n",
      "Baseline (Always Away) — F1: 0.2657, ROC AUC: 0.5, Brier: 0.5631\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scorer = make_scorer(f1_score, pos_label=None, average='weighted')\n",
    "\n",
    "y_true = df_final[\"Home Win\"].astype(int).values\n",
    "\n",
    "y_pred = np.ones_like(y_true)                   \n",
    "y_proba = np.ones_like(y_true, dtype=float)     \n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "\n",
    "try:\n",
    "    roc = roc_auc_score(y_true, y_proba)\n",
    "except ValueError:\n",
    "    roc = float(\"nan\")  # undefined for constant scores\n",
    "\n",
    "\n",
    "brier = brier_score_loss(y_true, y_proba)\n",
    "\n",
    "print(f\"Baseline (Always Home) — F1: {f1:.4f}, ROC AUC: {roc}, Brier: {brier:.4f}\")\n",
    "y_pred_away = np.zeros_like(y_true)\n",
    "y_proba_away = np.zeros_like(y_true, dtype=float)\n",
    "\n",
    "f1_away = f1_score(y_true, y_pred_away, average=\"weighted\")\n",
    "try:\n",
    "    roc_away = roc_auc_score(y_true, y_proba_away)\n",
    "except ValueError:\n",
    "    roc_away = float(\"nan\")\n",
    "brier_away = brier_score_loss(y_true, y_proba_away)\n",
    "\n",
    "print(f\"Baseline (Always Away) — F1: {f1_away:.4f}, ROC AUC: {roc_away}, Brier: {brier_away:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae520b5-6880-4f84-ad35-8524ec7fb24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model dataset ready: 1323 games, 18 features.\n",
      "Home win rate: 56.31%\n"
     ]
    }
   ],
   "source": [
    "# --- Feature selection (all existing + clean) ---\n",
    "base_feature_cols = [\n",
    "    # Game context / form\n",
    "    \"Home Played Yesterday\",\n",
    "    \"Away Played Yesterday\",\n",
    "    \"Home Rest Days Since Last Game\",\n",
    "    \"Away Rest Days Since Last Game\",\n",
    "\n",
    "    # Comparative metrics\n",
    "    \"Home Advantage\",\n",
    "    \"Win Streak Impact\",\n",
    "    \"Last 10 Wins\",\n",
    "    \"Home Opponent Strength\",\n",
    "    \"Away Opponent Strength\",\n",
    "    \"SRS_Diff\",\n",
    "\n",
    "    # Snapshot strength metrics (team stats)\n",
    "    \"Home_PP%\",\n",
    "    \"Away_PP%\",\n",
    "    \"Home_PK%\",\n",
    "    \"Away_PK%\",\n",
    "    \"Home_SV%\",\n",
    "    \"Away_SV%\",\n",
    "    \"Home_xGF%\",\n",
    "    \"Away_xGF%\",\n",
    "]\n",
    "\n",
    "df_model = df_final.dropna(subset=base_feature_cols + [\"Home Win\"]).copy()\n",
    "df_model = df_model.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "X = df_model[base_feature_cols]\n",
    "y = df_model[\"Home Win\"].astype(int)\n",
    "\n",
    "print(f\"✅ Model dataset ready: {X.shape[0]} games, {X.shape[1]} features.\")\n",
    "print(f\"Home win rate: {y.mean():.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5245cfd9-5b3f-4445-86f0-4df61557dd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running random searches...\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n",
      "Fitting 6 folds for each of 20 candidates, totalling 120 fits\n",
      "Fitting 6 folds for each of 20 candidates, totalling 120 fits\n",
      "[LightGBM] [Info] Number of positive: 595, number of negative: 463\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 1058, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562382 -> initscore=0.250834\n",
      "[LightGBM] [Info] Start training from score 0.250834\n",
      "Fitting 6 folds for each of 200 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nic\\Desktop\\PythonDrop\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison ===\n",
      "           Model     F1  ROC_AUC  Brier\n",
      "    RandomForest 0.5136   0.5641 0.2439\n",
      "        Ensemble 0.5357   0.5661 0.2447\n",
      "Logistic (Final) 0.5483   0.5643 0.2459\n",
      "      ElasticNet 0.5483   0.5643 0.2459\n",
      "     Logistic L2 0.5482   0.5641 0.2461\n",
      "     MLP (Final) 0.5433   0.5654 0.2480\n",
      "      MLP (Base) 0.5526   0.5607 0.2511\n",
      "        LightGBM 0.5152   0.5522 0.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nic\\Desktop\\PythonDrop\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# ==== CONFIG & GLOBAL PARAMETERS ======\n",
    "# ======================================\n",
    "\n",
    "SEED = 42\n",
    "CV_SPLITS = 6\n",
    "GAP = 3\n",
    "TEST_RATIO = 0.2\n",
    "\n",
    "# --- Iteration controls ---\n",
    "N_ITER_LOG_L2 = 40\n",
    "N_ITER_LOG_EN = 40\n",
    "N_ITER_RF = 20\n",
    "N_ITER_LGBM = 20\n",
    "N_ITER_MLP = 200\n",
    "\n",
    "MLP_MAX_ITER = 2000\n",
    "MLP_EARLY_STOP = True\n",
    "MLP_VAL_FRAC = 0.12\n",
    "MLP_PATIENCE = 20\n",
    "\n",
    "# ======================================\n",
    "# ==== FEATURES ========================\n",
    "# ======================================\n",
    "\n",
    "base_feature_cols = [\n",
    "    # Game context / rest\n",
    "    \"Home Played Yesterday\",\n",
    "    \"Away Played Yesterday\",\n",
    "    \"Home Rest Days Since Last Game\",\n",
    "    \"Away Rest Days Since Last Game\",\n",
    "\n",
    "    # Absolute form (avant le match)\n",
    "    \"Home Last 10 Wins\",\n",
    "    \"Away Last 10 Wins\",\n",
    "    \"Home Win Rate\",\n",
    "    \"Away Win Rate\",\n",
    "    \"Home Team Overall Win Streak Before Game\",\n",
    "    \"Away Team Overall Win Streak Before Game\",\n",
    "    \"Home Opponent Strength\",\n",
    "    \"Away Opponent Strength\",\n",
    "\n",
    "\n",
    "    # Saison / force structurelle\n",
    "    \"Home_SRS\",\n",
    "    \"Away_SRS\",\n",
    "    \"Home_PP%\",\n",
    "    \"Away_PP%\",\n",
    "    \"Home_PK%\",\n",
    "    \"Away_PK%\",\n",
    "    \"Home_SV%\",\n",
    "    \"Away_SV%\",\n",
    "    \"Home_xGF%\",\n",
    "    \"Away_xGF%\",\n",
    "]\n",
    "TARGET_COL = \"Home Win\"\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# ==== PARAM GRIDS =====================\n",
    "# ======================================\n",
    "\n",
    "PARAMS_LOG_L2 = {\n",
    "    \"clf__C\": loguniform(1e-3, 1e1),\n",
    "    \"clf__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "PARAMS_LOG_EN = {\n",
    "    \"clf__C\": loguniform(1e-3, 1e1),\n",
    "    \"clf__l1_ratio\": uniform(0, 1),\n",
    "    \"clf__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "PARAMS_RF = {\n",
    "    \"clf__n_estimators\": [300, 500, 800],\n",
    "    \"clf__max_depth\": [None, 5, 10, 15],\n",
    "    \"clf__min_samples_split\": [2, 5, 10],\n",
    "    \"clf__min_samples_leaf\": [1, 2, 5],\n",
    "}\n",
    "\n",
    "PARAMS_LGBM = {\n",
    "    \"clf__num_leaves\": [15, 31, 63],\n",
    "    \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"clf__n_estimators\": [200, 400, 600],\n",
    "    \"clf__subsample\": [0.8, 0.9, 1.0],\n",
    "    \"clf__colsample_bytree\": [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "PARAMS_MLP = {\n",
    "    \"clf__solver\": [\"adam\", \"sgd\"],\n",
    "    \"clf__max_iter\": [3000],\n",
    "    \"clf__activation\": [\"relu\", \"tanh\"],\n",
    "    \"clf__alpha\": loguniform(1e-6, 1e-2),\n",
    "    \"clf__learning_rate_init\": loguniform(5e-4, 1e-2),\n",
    "    \"clf__batch_size\": [32, 64, 128],\n",
    "    \"clf__learning_rate\": [\"adaptive\", \"invscaling\"],\n",
    "    \"clf__momentum\": uniform(0.6, 0.39),\n",
    "    \"clf__nesterovs_momentum\": [True, False],\n",
    "}\n",
    "\n",
    "SCORING = {\n",
    "    \"brier\": \"neg_brier_score\",\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"f1w\": \"f1_weighted\"\n",
    "}\n",
    "\n",
    "# ======================================\n",
    "# ==== DATA PREPARATION ================\n",
    "# ======================================\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "df = df_final.sort_values(\"Date\").reset_index(drop=True)\n",
    "missing = [c for c in base_feature_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(f\"⚠️ Missing columns in df_final (skipped): {missing}\")\n",
    "feature_cols = [c for c in base_feature_cols if c in df.columns]\n",
    "\n",
    "# Base : on garde seulement les lignes complètes sur ces features + la cible\n",
    "df_base = df.dropna(subset=feature_cols + [TARGET_COL]).copy()\n",
    "\n",
    "# Version complète avec les matchs futurs (NE PAS DROP)\n",
    "df_final_full = df_final.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Version training (matchs joués seulement)\n",
    "df_final_clean = df_final.dropna(subset=feature_cols + [TARGET_COL]).copy()\n",
    "df_final_clean = df_final_clean.sort_values(\"Date\").reset_index(drop=True)\n",
    "# Historique utilisé pour la construction des features en prod\n",
    "df_hist_for_pred = df_final_clean.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Ajout des colonnes d'identité d'équipe (catégorielles)\n",
    "df_base[\"Home_Team\"] = df_base[\"Home Team\"].astype(\"category\")\n",
    "df_base[\"Away_Team\"] = df_base[\"Away Team\"].astype(\"category\")\n",
    "\n",
    "# Renommage des features numériques (espaces -> _)\n",
    "rename_map = {c: c.replace(\" \", \"_\") for c in feature_cols}\n",
    "df_base = df_base.rename(columns=rename_map)\n",
    "\n",
    "# Liste finale des features numériques renommées\n",
    "feat = [rename_map[c] for c in feature_cols]\n",
    "\n",
    "# Features catégorielles (on garde ces noms là)\n",
    "cat_features = [\"Home_Team\", \"Away_Team\"]\n",
    "\n",
    "# Matrice X = numériques + catégorielles, y = cible\n",
    "X = df_base[feat + cat_features]\n",
    "y = df_base[TARGET_COL].astype(int)\n",
    "\n",
    "# Only keep numeric columns (ignore team categorical)\n",
    "num_df = df_base[feat].copy()\n",
    "\n",
    "\n",
    "cut = int((1 - TEST_RATIO) * len(df_base))\n",
    "X_tr, X_te = X.iloc[:cut], X.iloc[cut:]\n",
    "y_tr, y_te = y.iloc[:cut], y.iloc[cut:]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=CV_SPLITS, gap=GAP)\n",
    "\n",
    "# ======================================\n",
    "# ==== PREPROCESSING ===================\n",
    "# ======================================\n",
    "\n",
    "num_features = feat            # features numériques (déjà renommées)\n",
    "cat_features = [\"Home_Team\", \"Away_Team\"]  # features catégorielles\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ======================================\n",
    "# ==== HELPERS ========================\n",
    "# ======================================\n",
    "\n",
    "def evaluate(model, Xt, yt):\n",
    "    p = model.predict_proba(Xt)[:, 1]\n",
    "    yhat = (p >= 0.5).astype(int)\n",
    "    return {\n",
    "        \"F1\": f1_score(yt, yhat, average=\"weighted\"),\n",
    "        \"ROC_AUC\": roc_auc_score(yt, p),\n",
    "        \"Brier\": brier_score_loss(yt, p)\n",
    "    }\n",
    "\n",
    "def calibrate_if_better(model, Xtr, ytr, Xte, yte):\n",
    "    base = evaluate(model, Xte, yte)\n",
    "    cal = CalibratedClassifierCV(model, method=\"isotonic\", cv=5).fit(Xtr, ytr)\n",
    "    calm = evaluate(cal, Xte, yte)\n",
    "    return (cal, calm) if calm[\"Brier\"] <= base[\"Brier\"] else (model, base)\n",
    "# ======================================\n",
    "# ==== PIPELINES =======================\n",
    "# ======================================\n",
    "\n",
    "pipe_log_l2 = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"lbfgs\", random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_log_en = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"saga\", penalty=\"elasticnet\", random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", RandomForestClassifier(random_state=SEED, n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipe_lgbm = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LGBMClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_mlp = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", MLPClassifier(\n",
    "        max_iter=MLP_MAX_ITER,\n",
    "        random_state=SEED,\n",
    "        early_stopping=MLP_EARLY_STOP,\n",
    "        n_iter_no_change=MLP_PATIENCE,\n",
    "        validation_fraction=MLP_VAL_FRAC,\n",
    "        learning_rate=\"adaptive\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# ==== RANDOM SEARCHES ================\n",
    "# ======================================\n",
    "\n",
    "print(\"Running random searches...\")\n",
    "\n",
    "rs_log_l2 = RandomizedSearchCV(pipe_log_l2, PARAMS_LOG_L2, n_iter=N_ITER_LOG_L2,\n",
    "    scoring=SCORING, refit=\"brier\", cv=tscv, n_jobs=-1, verbose=1, random_state=SEED).fit(X_tr, y_tr)\n",
    "\n",
    "rs_log_en = RandomizedSearchCV(pipe_log_en, PARAMS_LOG_EN, n_iter=N_ITER_LOG_EN,\n",
    "    scoring=SCORING, refit=\"brier\", cv=tscv, n_jobs=-1, verbose=1, random_state=SEED).fit(X_tr, y_tr)\n",
    "\n",
    "rs_rf = RandomizedSearchCV(pipe_rf, PARAMS_RF, n_iter=N_ITER_RF,\n",
    "    scoring=SCORING, refit=\"brier\", cv=tscv, n_jobs=-1, verbose=1, random_state=SEED).fit(X_tr, y_tr)\n",
    "\n",
    "rs_lgbm = RandomizedSearchCV(pipe_lgbm, PARAMS_LGBM, n_iter=N_ITER_LGBM,\n",
    "    scoring=SCORING, refit=\"brier\", cv=tscv, n_jobs=-1, verbose=1, random_state=SEED).fit(X_tr, y_tr)\n",
    "\n",
    "rs_mlp = RandomizedSearchCV(pipe_mlp, PARAMS_MLP, n_iter=N_ITER_MLP,\n",
    "    scoring=SCORING, refit=\"brier\", cv=tscv, n_jobs=-1, verbose=1, random_state=SEED).fit(X_tr, y_tr)\n",
    "\n",
    "best_log_l2, best_log_en = rs_log_l2.best_estimator_, rs_log_en.best_estimator_\n",
    "best_rf, best_lgbm, best_mlp = rs_rf.best_estimator_, rs_lgbm.best_estimator_, rs_mlp.best_estimator_\n",
    "\n",
    "# ======================================\n",
    "# ==== EVALUATION ======================\n",
    "# ======================================\n",
    "\n",
    "m_l2 = evaluate(best_log_l2, X_te, y_te)\n",
    "m_en = evaluate(best_log_en, X_te, y_te)\n",
    "m_rf = evaluate(best_rf, X_te, y_te)\n",
    "m_lgbm = evaluate(best_lgbm, X_te, y_te)\n",
    "m_mlp = evaluate(best_mlp, X_te, y_te)\n",
    "\n",
    "# Pick best logistic variant\n",
    "log_final, log_metrics = (best_log_l2, m_l2) if m_l2[\"Brier\"] <= m_en[\"Brier\"] else (best_log_en, m_en)\n",
    "\n",
    "# Calibrate MLP\n",
    "mlp_final, mlp_metrics = calibrate_if_better(best_mlp, X_tr, y_tr, X_te, y_te)\n",
    "\n",
    "# === Ensemble (equal weights)\n",
    "p_log = log_final.predict_proba(X_te)[:, 1]\n",
    "p_rf = best_rf.predict_proba(X_te)[:, 1]\n",
    "p_lgbm = best_lgbm.predict_proba(X_te)[:, 1]\n",
    "p_mlp = mlp_final.predict_proba(X_te)[:, 1]\n",
    "\n",
    "p_avg = (p_log + p_rf + p_lgbm + p_mlp) / 4\n",
    "ens_metrics = {\n",
    "    \"F1\": f1_score(y_te, (p_avg >= 0.5).astype(int), average=\"weighted\"),\n",
    "    \"ROC_AUC\": roc_auc_score(y_te, p_avg),\n",
    "    \"Brier\": brier_score_loss(y_te, p_avg)\n",
    "}\n",
    "\n",
    "# === Collect results\n",
    "results = pd.DataFrame([\n",
    "    {\"Model\": \"Logistic L2\", **m_l2},\n",
    "    {\"Model\": \"ElasticNet\", **m_en},\n",
    "    {\"Model\": \"RandomForest\", **m_rf},\n",
    "    {\"Model\": \"LightGBM\", **m_lgbm},\n",
    "    {\"Model\": \"MLP (Base)\", **m_mlp},\n",
    "    {\"Model\": \"Logistic (Final)\", **log_metrics},\n",
    "    {\"Model\": \"MLP (Final)\", **mlp_metrics},\n",
    "    {\"Model\": \"Ensemble\", **ens_metrics},\n",
    "])\n",
    "\n",
    "results = results.sort_values(\"Brier\").reset_index(drop=True)\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(results.round(4).to_string(index=False))\n",
    "\n",
    "# ======================================\n",
    "# ==== SAVE MODELS =====================\n",
    "# ======================================\n",
    "\n",
    "joblib.dump(log_final, \"model_Logistic_TUNED.joblib\")\n",
    "joblib.dump(best_rf, \"model_RF_TUNED.joblib\")\n",
    "joblib.dump(best_lgbm, \"model_LGBM_TUNED.joblib\")\n",
    "joblib.dump(mlp_final, \"model_MLP_TUNED.joblib\")\n",
    "results.to_csv(\"model_results_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e024876-e95b-493b-932b-ed3e379cb551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Away_SV%      float64\n",
      "Home_xGF%     float64\n",
      "Away_xGF%     float64\n",
      "Home_Team    category\n",
      "Away_Team    category\n",
      "dtype: object\n",
      "         Home_Team          Away_Team\n",
      "0    Winnipeg Jets     Minnesota Wild\n",
      "1  Edmonton Oilers     Calgary Flames\n",
      "2     Dallas Stars     Seattle Kraken\n",
      "3    Boston Bruins   Florida Panthers\n",
      "4  Ottawa Senators  Los Angeles Kings\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes.tail(5))\n",
    "print(X[[\"Home_Team\", \"Away_Team\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b842bab-d43e-47c8-a1a4-9e3c0c45d77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Quality dataset (numerical including team dummies) ===\n",
      "   Date_str  Home Team  Away Team  Home Score  Away Score  \\\n",
      "0       NaN        NaN        NaN           2           1   \n",
      "1       NaN        NaN        NaN           1           4   \n",
      "2       NaN        NaN        NaN           2           0   \n",
      "3       NaN        NaN        NaN           3           4   \n",
      "4       NaN        NaN        NaN           8           7   \n",
      "\n",
      "              Date_UTC           Date_Local  LocalDate  Season  weight  ...  \\\n",
      "0  1728856800000000000  1728856800000000000        NaN     NaN     1.0  ...   \n",
      "1  1728864000000000000  1728864000000000000        NaN     NaN     1.0  ...   \n",
      "2  1728864000000000000  1728864000000000000        NaN     NaN     1.0  ...   \n",
      "3  1728925200000000000  1728925200000000000        NaN     NaN     1.0  ...   \n",
      "4  1728925200000000000  1728925200000000000        NaN     NaN     1.0  ...   \n",
      "\n",
      "   Away_Team_San Jose Sharks  Away_Team_Seattle Kraken  \\\n",
      "0                      False                     False   \n",
      "1                      False                     False   \n",
      "2                      False                      True   \n",
      "3                      False                     False   \n",
      "4                      False                     False   \n",
      "\n",
      "   Away_Team_St. Louis Blues  Away_Team_Tampa Bay Lightning  \\\n",
      "0                      False                          False   \n",
      "1                      False                          False   \n",
      "2                      False                          False   \n",
      "3                      False                          False   \n",
      "4                      False                          False   \n",
      "\n",
      "   Away_Team_Toronto Maple Leafs  Away_Team_Utah Mammoth  \\\n",
      "0                          False                   False   \n",
      "1                          False                   False   \n",
      "2                          False                   False   \n",
      "3                          False                   False   \n",
      "4                          False                   False   \n",
      "\n",
      "   Away_Team_Vancouver Canucks  Away_Team_Vegas Golden Knights  \\\n",
      "0                        False                           False   \n",
      "1                        False                           False   \n",
      "2                        False                           False   \n",
      "3                        False                           False   \n",
      "4                        False                           False   \n",
      "\n",
      "   Away_Team_Washington Capitals  Away_Team_Winnipeg Jets  \n",
      "0                          False                    False  \n",
      "1                          False                    False  \n",
      "2                          False                    False  \n",
      "3                          False                    False  \n",
      "4                          False                    False  \n",
      "\n",
      "[5 rows x 131 columns]\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# ==== QUALITY DATASET WITH TEAMS ======\n",
    "# ======================================\n",
    "\n",
    "# On remet une copie complète pour analyser la multicolinéarité réelle\n",
    "df_quality = df_base.copy()\n",
    "\n",
    "# Encodage one-hot complet des équipes (pour analyser leur impact)\n",
    "df_quality = pd.get_dummies(df_quality, columns=[\"Home_Team\", \"Away_Team\"], drop_first=True)\n",
    "\n",
    "# On retire la target\n",
    "if TARGET_COL in df_quality.columns:\n",
    "    df_quality = df_quality.drop(columns=[TARGET_COL])\n",
    "\n",
    "# Ne garder que valeurs numériques\n",
    "df_quality = df_quality.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "print(\"\\n=== Quality dataset (numerical including team dummies) ===\")\n",
    "print(df_quality.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d293965c-875a-40c1-9e52-cfe330c48b6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Target slate date set to: 2025-12-03\n",
      "\n",
      "Target date: 2025-12-03 | games found: 5\n",
      "Nearby slates (games per day):\n",
      "  2025-12-02: 10\n",
      "  2025-12-03: 5  (today)\n",
      "  2025-12-04: 10\n",
      "  2025-12-05: 5\n",
      "  2025-12-06: 12\n",
      "\n",
      "Enter AMERICAN odds (e.g., -120, +135).\n",
      "Press Enter to leave a side blank, 's' to skip a game, 'q' to quit.\n",
      "\n",
      "=====================================\n",
      "[1/5]  Utah Mammoth  @  Anaheim Ducks\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Utah Mammoth  American odds:  -108\n",
      "  (HOME)  Anaheim Ducks  American odds:  -110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "[2/5]  Buffalo Sabres  @  Philadelphia Flyers\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Buffalo Sabres  American odds:  -103\n",
      "  (HOME)  Philadelphia Flyers  American odds:  -114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "[3/5]  Washington Capitals  @  San Jose Sharks\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Washington Capitals  American odds:  -143\n",
      "  (HOME)  San Jose Sharks  American odds:  121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================\n",
      "[4/5]  Dallas Stars  @  New Jersey Devils\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Dallas Stars  American odds:  -101\n",
      "  (HOME)  New Jersey Devils  American odds:  -116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n",
      "[5/5]  Winnipeg Jets  @  Montreal Canadiens\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Winnipeg Jets  American odds:  -114\n",
      "  (HOME)  Montreal Canadiens  American odds:  -103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "✅ Saved 5 matchup(s) with odds to odds.csv\n",
      "\n",
      "Saved rows preview:\n",
      "        Date            Away Team Away American Odds Away Odds  \\\n",
      "0 2025-12-03         Utah Mammoth               -108  1.925926   \n",
      "1 2025-12-03       Buffalo Sabres               -103  1.970874   \n",
      "2 2025-12-03  Washington Capitals               -143  1.699301   \n",
      "3 2025-12-03         Dallas Stars               -101  1.990099   \n",
      "4 2025-12-03        Winnipeg Jets               -114  1.877193   \n",
      "\n",
      "             Home Team Home American Odds Home Odds  \n",
      "0        Anaheim Ducks               -110  1.909091  \n",
      "1  Philadelphia Flyers               -114  1.877193  \n",
      "2      San Jose Sharks                121      2.21  \n",
      "3    New Jersey Devils               -116  1.862069  \n",
      "4   Montreal Canadiens               -103  1.970874  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATE_OFFSET = +0\n",
    "TARGET_DATE = (datetime.now() + timedelta(days=DATE_OFFSET)).date()\n",
    "print(f\"📅 Target slate date set to: {TARGET_DATE}\")\n",
    "\n",
    "CSV_PATH = \"odds.csv\"\n",
    "\n",
    "# Ignore games that don't have final scores (cancelled / not played)\n",
    "ONLY_PLAYED_GAMES = True\n",
    "\n",
    "def _strip_accents(s: str) -> str:\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFKD\", str(s)) if not unicodedata.combining(c))\n",
    "\n",
    "def _american_to_decimal(a):\n",
    "    try: a = int(a)\n",
    "    except Exception: return None\n",
    "    if a == 0 or abs(a) < 100 or a == -100: return None\n",
    "    return 1.0 + (a/100.0) if a > 0 else 1.0 + (100.0/abs(a))\n",
    "\n",
    "def _parse_odds(s: str):\n",
    "    if s is None: return (None, None, None)\n",
    "    s = s.strip().lower().replace(\" \", \"\")\n",
    "    if s in {\"s\",\"skip\"}:  return (None, None, \"skip\")\n",
    "    if s in {\"q\",\"quit\"}:  return (None, None, \"quit\")\n",
    "    if \".\" in s or \",\" in s:   # accept decimal as a convenience\n",
    "        try:\n",
    "            dec = float(s.replace(\",\", \".\"))\n",
    "            return (None, dec if dec > 1.01 else None, None)\n",
    "        except Exception:\n",
    "            return (None, None, None)\n",
    "    m = re.fullmatch(r\"([+-]?)(\\d{2,4})\", s)\n",
    "    if not m: return (None, None, None)\n",
    "    sign, num = m.groups(); num = int(num)\n",
    "    american = -num if sign == \"-\" else +num\n",
    "    if american == 0 or abs(american) < 100 or american == -100: return (None, None, None)\n",
    "    return (american, _american_to_decimal(american), None)\n",
    "    \n",
    "def _mk_template(df_games, target_date):\n",
    "    g = df_games.copy()\n",
    "    g[\"Date\"] = pd.to_datetime(g[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "    # === NEW FIX ===\n",
    "    # Pour les dates passées → garder seulement les matchs joués\n",
    "    # Pour les dates futures → ne rien filtrer (sinon on supprime tous les matchs futurs)\n",
    "    today = datetime.now().date()\n",
    "\n",
    "    if target_date < today:\n",
    "        if {\"Home Score\", \"Away Score\"}.issubset(g.columns):\n",
    "            g = g[g[\"Home Score\"].notna() & g[\"Away Score\"].notna()]\n",
    "    # === END FIX ===\n",
    "\n",
    "    # Filtrer par date (après le filtre intelligent)\n",
    "    g = g[g[\"Date\"].dt.date == target_date]\n",
    "\n",
    "    out = (\n",
    "        g.drop_duplicates(subset=[\"Date\",\"Home Team\",\"Away Team\"])\n",
    "         .loc[:, [\"Date\",\"Away Team\",\"Home Team\"]]\n",
    "         .assign(**{\n",
    "             \"Away American Odds\": None, \"Away Odds\": None,\n",
    "             \"Home American Odds\": None, \"Home Odds\": None\n",
    "         })\n",
    "         .loc[:, [\n",
    "             \"Date\", \"Away Team\", \"Away American Odds\", \"Away Odds\",\n",
    "             \"Home Team\", \"Home American Odds\", \"Home Odds\"\n",
    "         ]]\n",
    "         .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    out[\"Away Team\"] = out[\"Away Team\"].map(_strip_accents)\n",
    "    out[\"Home Team\"] = out[\"Home Team\"].map(_strip_accents)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def _slate_counts_nearby(df_games, center_date, span=3):\n",
    "    g = df_games.copy()\n",
    "    g[\"Date\"] = pd.to_datetime(g[\"Date\"], errors=\"coerce\")\n",
    "    counts = []\n",
    "    for delta in range(-1, span+1):\n",
    "        d = center_date + timedelta(days=delta)\n",
    "        n = int((g[\"Date\"].dt.date == d).sum())\n",
    "        counts.append((d, n))\n",
    "    return counts\n",
    "\n",
    "def enter_american_odds(df_games, date_str=None):\n",
    "    target = (pd.to_datetime(date_str).date() if date_str else datetime.now().date())\n",
    "    tmpl = _mk_template(df_games, target)\n",
    "\n",
    "    print(f\"\\nTarget date: {target} | games found: {len(tmpl)}\")\n",
    "    nearby = _slate_counts_nearby(df_games, target, span=3)\n",
    "    print(\"Nearby slates (games per day):\")\n",
    "    for d, n in nearby:\n",
    "        mark = \"  (today)\" if d == target else \"\"\n",
    "        print(f\"  {d}: {n}{mark}\")\n",
    "\n",
    "    if tmpl.empty:\n",
    "        print(\"No games for this date in df_all. Pick another date (e.g., enter_american_odds(df_all, '2025-10-12')).\")\n",
    "        return tmpl  # empty\n",
    "\n",
    "    print(\"\\nEnter AMERICAN odds (e.g., -120, +135).\")\n",
    "    print(\"Press Enter to leave a side blank, 's' to skip a game, 'q' to quit.\\n\")\n",
    "\n",
    "    for i in range(len(tmpl)):\n",
    "        away = tmpl.at[i, \"Away Team\"]\n",
    "        home = tmpl.at[i, \"Home Team\"]\n",
    "        header = f\"[{i+1}/{len(tmpl)}]  {away}  @  {home}\"\n",
    "        print(\"=\"*len(header))\n",
    "        print(header)\n",
    "        print(\"=\"*len(header))\n",
    "\n",
    "        # Away (AWAY TEAM odds)\n",
    "        while True:\n",
    "            a_in = input(f\"  (AWAY)  {away}  American odds: \").strip()\n",
    "            if a_in == \"\":  a_american, a_decimal, cmd = (None, None, None); break\n",
    "            a_american, a_decimal, cmd = _parse_odds(a_in)\n",
    "            if cmd in {\"quit\",\"skip\"} or a_decimal is not None or a_american is None: break\n",
    "            print(\"    -> invalid (try -120, +135, or 1.95)\")\n",
    "        if cmd == \"quit\": break\n",
    "        if cmd == \"skip\": print(\"  skipped game\\n\"); continue\n",
    "\n",
    "        # Home (HOME TEAM odds)\n",
    "        while True:\n",
    "            h_in = input(f\"  (HOME)  {home}  American odds: \").strip()\n",
    "            if h_in == \"\":  h_american, h_decimal, cmd2 = (None, None, None); break\n",
    "            h_american, h_decimal, cmd2 = _parse_odds(h_in)\n",
    "            if cmd2 in {\"quit\",\"skip\"} or h_decimal is not None or h_american is None: break\n",
    "            print(\"    -> invalid (try -120, +135, or 1.95)\")\n",
    "        if cmd2 == \"quit\": break\n",
    "        if cmd2 == \"skip\": print(\"  skipped game\\n\"); continue\n",
    "\n",
    "        tmpl.at[i, \"Away American Odds\"] = a_american\n",
    "        tmpl.at[i, \"Away Odds\"]          = a_decimal\n",
    "        tmpl.at[i, \"Home American Odds\"] = h_american\n",
    "        tmpl.at[i, \"Home Odds\"]          = h_decimal\n",
    "        print()\n",
    "\n",
    "    complete = tmpl.dropna(subset=[\"Away Odds\",\"Home Odds\"]).reset_index(drop=True)\n",
    "    complete.to_csv(CSV_PATH, index=False)\n",
    "    print(f\"\\n✅ Saved {len(complete)} matchup(s) with odds to {CSV_PATH}\")\n",
    "    return complete\n",
    "\n",
    "# ===== RUN =====\n",
    "# Today by default (change to a specific date string if you want):\n",
    "df_odds = enter_american_odds(df_games_master, TARGET_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print(\"\\nSaved rows preview:\")\n",
    "print(df_odds.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c88034-7149-4649-b9b9-d43c1e4ab3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SlateDate            Away Team  Away Bet  Away Odds            Home Team  \\\n",
      "0  2025-12-03         Utah Mammoth         0   1.925926        Anaheim Ducks   \n",
      "1  2025-12-03       Buffalo Sabres         0   1.970874  Philadelphia Flyers   \n",
      "2  2025-12-03  Washington Capitals         6   1.699301      San Jose Sharks   \n",
      "3  2025-12-03         Dallas Stars         0   1.990099    New Jersey Devils   \n",
      "4  2025-12-03        Winnipeg Jets         0   1.877193   Montreal Canadiens   \n",
      "\n",
      "   Home Bet  Home Odds  p_home_ens  Scaled  \n",
      "0        26   1.909091      0.5706   False  \n",
      "1        74   1.877193      0.6663   False  \n",
      "2         0   2.210000      0.4024   False  \n",
      "3         0   1.862069      0.4976   False  \n",
      "4         3   1.970874      0.5134   False  \n",
      "\n",
      "Saved 5 rows to predictions.csv (mode='a', header=False)\n"
     ]
    }
   ],
   "source": [
    "# ===================== CONFIG (edit if needed) =====================\n",
    "MODEL_LOG_PATH = \"model_Logistic_TUNED.joblib\"\n",
    "MODEL_MLP_PATH = \"model_MLP_TUNED.joblib\"\n",
    "ENSEMBLE_WEIGHTS = (0.5, 0.5)     # (logistic, mlp)\n",
    "BANKROLL = 260\n",
    "PREDICTIONS_CSV = \"predictions.csv\"\n",
    "DATE_OFFSET = 0                   # 0=today, +1=tomorrow, etc.\n",
    "DATE_COL_IN_HISTORY = \"Date\"      # must exist in df_final\n",
    "# ===================================================================\n",
    "\n",
    "# ---- imports you MUST have ----\n",
    "import os, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ---- target date ----\n",
    "TARGET_DATE = (datetime.now() + timedelta(days=DATE_OFFSET)).date()\n",
    "\n",
    "# ---- safety: required dataframes/objects ----\n",
    "\n",
    "required = {\n",
    "    \"df_odds\": \"DataFrame of today's games with columns: Home Team, Away Team, Home Odds, Away Odds\",\n",
    "    \"df_hist_for_pred\": \"Historical features per game (used to build X_one)\",\n",
    "    \"rename_map\": \"dict mapping training feature names (keys in feats) to model input names\"\n",
    "}\n",
    "\n",
    "for name in required:\n",
    "    if name not in globals():\n",
    "        raise RuntimeError(f\"Missing required object `{name}`: {required[name]}\")\n",
    "\n",
    "\n",
    "# ===== MODELS & ENSEMBLE SETUP =====\n",
    "assert os.path.exists(MODEL_LOG_PATH), f\"Missing model file: {MODEL_LOG_PATH}\"\n",
    "assert os.path.exists(MODEL_MLP_PATH), f\"Missing model file: {MODEL_MLP_PATH}\"\n",
    "log_model = joblib.load(MODEL_LOG_PATH)\n",
    "mlp_model = joblib.load(MODEL_MLP_PATH)\n",
    "\n",
    "assert hasattr(log_model, \"predict_proba\"), \"log_model must support predict_proba()\"\n",
    "assert hasattr(mlp_model, \"predict_proba\"), \"mlp_model must support predict_proba()\"\n",
    "\n",
    "# ensemble weights (normalized)\n",
    "try:\n",
    "    w_log, w_mlp = ENSEMBLE_WEIGHTS\n",
    "except Exception:\n",
    "    w_log, w_mlp = 0.5, 0.5\n",
    "ws = (w_log or 0) + (w_mlp or 0)\n",
    "if ws <= 0:\n",
    "    w_log, w_mlp = 0.5, 0.5\n",
    "else:\n",
    "    w_log, w_mlp = w_log / ws, w_mlp / ws\n",
    "\n",
    "# ---- helpers ----\n",
    "def _kelly(p_win: float, dec_odds: float) -> float:\n",
    "    b = dec_odds - 1.0\n",
    "    if b <= 0:\n",
    "        return 0.0\n",
    "    q = 1.0 - p_win\n",
    "    return max(0.0, (b * p_win - q) / b)\n",
    "\n",
    "def _assert_sorted(df_hist: pd.DataFrame, date_col: str):\n",
    "    if not df_hist[date_col].is_monotonic_increasing:\n",
    "        df_hist.sort_values(date_col, inplace=True, kind=\"mergesort\")  # stable\n",
    "\n",
    "def _latest_value_asof(df_hist: pd.DataFrame, team: str, col_if_home: str, col_if_away: str,\n",
    "                       as_of_dt: pd.Timestamp, date_col: str):\n",
    "    # history strictly before slate day boundary (prevent leakage)\n",
    "    m = (((df_hist[\"Home Team\"] == team) | (df_hist[\"Away Team\"] == team))\n",
    "         & (df_hist[date_col] < as_of_dt))\n",
    "    if not m.any():\n",
    "        raise ValueError(f\"No history for {team} up to {as_of_dt}\")\n",
    "    last = df_hist.loc[m].iloc[-1]\n",
    "    return last[col_if_home] if last[\"Home Team\"] == team else last[col_if_away]\n",
    "\n",
    "def build_features_for_match(home_team, away_team, df_hist, as_of_dt, date_col: str):\n",
    "    \"\"\"\n",
    "    Construit une ligne de features pour un match Home vs Away à la date as_of_dt,\n",
    "    en utilisant les mêmes features que le training (base_feature_cols + Home_Team/Away_Team).\n",
    "    \"\"\"\n",
    "\n",
    "    _assert_sorted(df_hist, date_col)\n",
    "\n",
    "    # Helper : dernière valeur dispo avant as_of_dt pour une équipe donnée\n",
    "    L = lambda tm, ch, ca: _latest_value_asof(df_hist, tm, ch, ca, as_of_dt, date_col)\n",
    "\n",
    "    # Home side\n",
    "    home_played_yesterday = int(bool(L(home_team, \"Home Played Yesterday\", \"Away Played Yesterday\")))\n",
    "    away_played_yesterday = int(bool(L(away_team, \"Away Played Yesterday\", \"Home Played Yesterday\")))\n",
    "\n",
    "    feats = {\n",
    "        # Game context / rest\n",
    "        \"Home Played Yesterday\": home_played_yesterday,\n",
    "        \"Away Played Yesterday\": away_played_yesterday,\n",
    "        \"Home Rest Days Since Last Game\": L(home_team, \"Home Rest Days Since Last Game\", \"Away Rest Days Since Last Game\"),\n",
    "        \"Away Rest Days Since Last Game\": L(away_team, \"Away Rest Days Since Last Game\", \"Home Rest Days Since Last Game\"),\n",
    "\n",
    "        # Absolute form\n",
    "        \"Home Last 10 Wins\": L(home_team, \"Home Last 10 Wins\", \"Away Last 10 Wins\"),\n",
    "        \"Away Last 10 Wins\": L(away_team, \"Home Last 10 Wins\", \"Away Last 10 Wins\"),  # note: symétrique mais côté équipe\n",
    "        \"Home Win Rate\": L(home_team, \"Home Win Rate\", \"Away Win Rate\"),\n",
    "        \"Away Win Rate\": L(away_team, \"Home Win Rate\", \"Away Win Rate\"),\n",
    "        \"Home Team Overall Win Streak Before Game\": L(\n",
    "            home_team,\n",
    "            \"Home Team Overall Win Streak Before Game\",\n",
    "            \"Away Team Overall Win Streak Before Game\"\n",
    "        ),\n",
    "        \"Away Team Overall Win Streak Before Game\": L(\n",
    "            away_team,\n",
    "            \"Home Team Overall Win Streak Before Game\",\n",
    "            \"Away Team Overall Win Streak Before Game\"\n",
    "        ),\n",
    "        \"Home Opponent Strength\": L(home_team, \"Home Opponent Strength\", \"Away Opponent Strength\"),\n",
    "        \"Away Opponent Strength\": L(away_team, \"Home Opponent Strength\", \"Away Opponent Strength\"),\n",
    "\n",
    "        # Saison / force structurelle (snapshots)\n",
    "        \"Home_SRS\": L(home_team, \"Home_SRS\", \"Away_SRS\"),\n",
    "        \"Away_SRS\": L(away_team, \"Home_SRS\", \"Away_SRS\"),\n",
    "        \"Home_PP%\": L(home_team, \"Home_PP%\", \"Away_PP%\"),\n",
    "        \"Away_PP%\": L(away_team, \"Home_PP%\", \"Away_PP%\"),\n",
    "        \"Home_PK%\": L(home_team, \"Home_PK%\", \"Away_PK%\"),\n",
    "        \"Away_PK%\": L(away_team, \"Home_PK%\", \"Away_PK%\"),\n",
    "        \"Home_SV%\": L(home_team, \"Home_SV%\", \"Away_SV%\"),\n",
    "        \"Away_SV%\": L(away_team, \"Home_SV%\", \"Away_SV%\"),\n",
    "        \"Home_xGF%\": L(home_team, \"Home_xGF%\", \"Away_xGF%\"),\n",
    "        \"Away_xGF%\": L(away_team, \"Home_xGF%\", \"Away_xGF%\"),\n",
    "    }\n",
    "\n",
    "    # Map vers les noms utilisés au training (espaces -> \"_\")\n",
    "    row = {rename_map.get(k, k): v for k, v in feats.items()}\n",
    "\n",
    "    # Ajout des features catégorielles (les modèles s'attendent à les voir)\n",
    "    row[\"Home_Team\"] = home_team\n",
    "    row[\"Away_Team\"] = away_team\n",
    "\n",
    "    X = pd.DataFrame([row])\n",
    "    return X\n",
    "\n",
    "\n",
    "# ==== PREDICT & SIZE BETS ====\n",
    "as_of_dt = pd.Timestamp(TARGET_DATE)  # naive local midnight of target day\n",
    "\n",
    "# clean team strings\n",
    "for c in [\"Home Team\", \"Away Team\"]:\n",
    "    if c in df_odds.columns:\n",
    "        df_odds[c] = df_odds[c].astype(str).str.strip()\n",
    "    if c in df_hist_for_pred.columns:\n",
    "        df_hist_for_pred[c] = df_hist_for_pred[c].astype(str).str.strip()\n",
    "\n",
    "pred_rows, pre_bets, total_pre = [], [], 0.0\n",
    "\n",
    "for _, r in df_odds.iterrows():\n",
    "    h, a = str(r[\"Home Team\"]), str(r[\"Away Team\"])\n",
    "\n",
    "    # odds cleaning\n",
    "    try:\n",
    "        oh, oa = float(r[\"Home Odds\"]), float(r[\"Away Odds\"])\n",
    "    except Exception:\n",
    "        # skip rows with missing/invalid odds\n",
    "        continue\n",
    "\n",
    "    # build feature row\n",
    "    X_one = build_features_for_match(h, a, df_hist_for_pred, as_of_dt=as_of_dt, date_col=DATE_COL_IN_HISTORY)\n",
    "\n",
    "\n",
    "\n",
    "    # model probabilities\n",
    "    p_h = (\n",
    "        w_log * log_model.predict_proba(X_one)[:, 1].item()\n",
    "        + w_mlp * mlp_model.predict_proba(X_one)[:, 1].item()\n",
    "    )\n",
    "\n",
    "    # Kelly stakes (unscaled)\n",
    "    bh_pre = _kelly(p_h, oh) * BANKROLL\n",
    "    ba_pre = _kelly(1.0 - p_h, oa) * BANKROLL\n",
    "    pre_bets.append((bh_pre, ba_pre))\n",
    "    total_pre += bh_pre + ba_pre\n",
    "\n",
    "    pred_rows.append({\n",
    "        \"SlateDate\": TARGET_DATE.isoformat(),\n",
    "        \"Away Team\": a, \"Away Odds\": oa,\n",
    "        \"Home Team\": h, \"Home Odds\": oh,\n",
    "        \"p_home_ens\": round(p_h, 4)\n",
    "    })\n",
    "\n",
    "# scale proportionally if total stake > bankroll\n",
    "for i, row in enumerate(pred_rows):\n",
    "    bh, ba = pre_bets[i]\n",
    "    if BANKROLL > 0 and total_pre > BANKROLL:\n",
    "        s = BANKROLL / total_pre\n",
    "        bh, ba = bh * s, ba * s\n",
    "        row[\"Scaled\"] = True\n",
    "    else:\n",
    "        row[\"Scaled\"] = False\n",
    "    row[\"Home Bet\"] = int(round(bh)) if bh > 0 else 0\n",
    "    row[\"Away Bet\"] = int(round(ba)) if ba > 0 else 0\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows)\n",
    "cols = [\"SlateDate\",\"Away Team\",\"Away Bet\",\"Away Odds\",\"Home Team\",\"Home Bet\",\"Home Odds\",\"p_home_ens\",\"Scaled\"]\n",
    "print(pred_df[cols] if set(cols).issubset(pred_df.columns) else pred_df)\n",
    "\n",
    "# append/save\n",
    "mode = \"a\" if os.path.exists(PREDICTIONS_CSV) else \"w\"\n",
    "header = not os.path.exists(PREDICTIONS_CSV)\n",
    "pred_df.to_csv(PREDICTIONS_CSV, index=False, mode=mode, header=header)\n",
    "print(f\"\\nSaved {len(pred_df)} rows to {PREDICTIONS_CSV} (mode='{mode}', header={header})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568bdca5-2c5b-42e1-b5eb-c1806ae625da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
