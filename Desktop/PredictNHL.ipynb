{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff83a0ed-6a04-4c9c-826e-1539be93a94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Desktop/PredictNHL.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main d621900] Add PredictNHL.ipynb\n",
      " 1 file changed, 195 insertions(+), 141 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/nic01as1/NHLPredictor\n",
      " * branch            main       -> FETCH_HEAD\n",
      "   ce31350..bcea535  main       -> origin/main\n",
      "warning: in the working copy of 'PredictNHL.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "error: Your local changes to the following files would be overwritten by merge:\n",
      "\tPredictNHL.ipynb\n",
      "Please commit your changes or stash them before you merge.\n",
      "Aborting\n",
      "Merge with strategy ort failed.\n",
      "To https://github.com/nic01as1/NHLPredictor.git\n",
      " ! [rejected]        main -> main (non-fast-forward)\n",
      "error: failed to push some refs to 'https://github.com/nic01as1/NHLPredictor.git'\n",
      "hint: Updates were rejected because the tip of your current branch is behind\n",
      "hint: its remote counterpart. If you want to integrate the remote changes,\n",
      "hint: use 'git pull' before pushing again.\n",
      "hint: See the 'Note about fast-forwards' in 'git push --help' for details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git add PredictNHL.ipynb\n",
    "\n",
    "\n",
    "!git commit -m \"Add PredictNHL.ipynb\"\n",
    "\n",
    "\n",
    "!git pull origin main\n",
    "\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7733f86c-ce56-4bee-b86a-750ec87462f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/nic01as1/NHLPredictor.git\n",
      " + bcea535...d621900 main -> main (forced update)\n"
     ]
    }
   ],
   "source": [
    "#if stuck :\n",
    "!git push origin main --force\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0af2c54-99e1-49ea-a78d-1509524b2587",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (2.18.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (70.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from xgboost) (2.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from xgboost) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (1.41.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (2.0.0)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (5.29.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.19.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (2.0.0)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (1.6.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (2.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (2.0.0)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (1.14.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nic\\desktop\\pythondrop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install xgboost\n",
    "!pip install streamlit\n",
    "!pip install imbalanced-learn\n",
    "!pip install shap\n",
    "!pip install statsmodels\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72e8701d-ae59-47be-acc0-320e91c564b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, TimeSeriesSplit, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score, brier_score_loss, accuracy_score, log_loss, classification_report, make_scorer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import mutual_info_classif, RFECV, SelectFromModel, SelectKBest\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import re\n",
    "from scipy.stats import loguniform, uniform\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25a78d45-fb52-49b6-b4ea-0d46d29c6729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Team  Rank                 Team Rank\n",
      "0           Winnipeg Jets     1          Winnipeg Jets* 1\n",
      "1     Washington Capitals     2    Washington Capitals* 2\n",
      "2    Vegas Golden Knights     3   Vegas Golden Knights* 3\n",
      "3     Toronto Maple Leafs     4    Toronto Maple Leafs* 4\n",
      "4            Dallas Stars     5           Dallas Stars* 5\n",
      "5       Los Angeles Kings     6      Los Angeles Kings* 6\n",
      "6     Tampa Bay Lightning     7    Tampa Bay Lightning* 7\n",
      "7      Colorado Avalanche     8     Colorado Avalanche* 8\n",
      "8         Edmonton Oilers     9        Edmonton Oilers* 9\n",
      "9     Carolina Hurricanes    10   Carolina Hurricanes* 10\n",
      "10       Florida Panthers    11      Florida Panthers* 11\n",
      "11         Minnesota Wild    12        Minnesota Wild* 12\n",
      "12        Ottawa Senators    13       Ottawa Senators* 13\n",
      "13         Calgary Flames    14         Calgary Flames 14\n",
      "14        St. Louis Blues    15       St. Louis Blues* 15\n",
      "15     Montreal Canadiens    16    Montreal Canadiens* 16\n",
      "16      New Jersey Devils    17     New Jersey Devils* 17\n",
      "17      Vancouver Canucks    18      Vancouver Canucks 18\n",
      "18  Columbus Blue Jackets    19  Columbus Blue Jackets 19\n",
      "19       Utah Hockey Club    20       Utah Hockey Club 20\n",
      "20      Detroit Red Wings    21      Detroit Red Wings 21\n",
      "21       New York Rangers    22       New York Rangers 22\n",
      "22     New York Islanders    23     New York Islanders 23\n",
      "23    Pittsburgh Penguins    24    Pittsburgh Penguins 24\n",
      "24          Anaheim Ducks    25          Anaheim Ducks 25\n",
      "25         Buffalo Sabres    26         Buffalo Sabres 26\n",
      "26          Boston Bruins    27          Boston Bruins 27\n",
      "27         Seattle Kraken    28         Seattle Kraken 28\n",
      "28    Philadelphia Flyers    29    Philadelphia Flyers 29\n",
      "29    Nashville Predators    30    Nashville Predators 30\n",
      "30     Chicago Blackhawks    31     Chicago Blackhawks 31\n",
      "31        San Jose Sharks    32        San Jose Sharks 32\n"
     ]
    }
   ],
   "source": [
    "#Retrieve the rank of each teams\n",
    "\n",
    "url = 'https://www.hockey-reference.com/leagues/NHL_2025.html#all_stats'\n",
    "\n",
    "with webdriver.Chrome() as driver:\n",
    "    driver.get(url)\n",
    "    time.sleep(2) \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "table = soup.find('table', id='stats')\n",
    "\n",
    "if table is None:\n",
    "    print(\"Team Statistics table not found\")\n",
    "else:\n",
    "    \n",
    "    rows = table.find_all('tr')[1:] \n",
    "    teams = [\n",
    "        row.find_all('td')[0].text.strip()\n",
    "        for row in rows\n",
    "        if row.find_all('td')\n",
    "    ]\n",
    "    ranks = list(range(1, len(teams) + 1)) \n",
    "\n",
    "    \n",
    "    df_rank = pd.DataFrame({\n",
    "        'Team': teams,\n",
    "        'Rank': ranks,\n",
    "        'Team Rank': [f\"{team} {rank}\" for team, rank in zip(teams, ranks)]\n",
    "    })\n",
    "    df_rank = df_rank[df_rank['Team'] != 'League Average'].reset_index(drop=True)\n",
    "    df_rank['Team'] = df_rank['Team'].str.replace('*', '', regex=False).str.strip()\n",
    "\n",
    "print(df_rank)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f00ddb38-a370-48ed-a70a-f0bea4f8315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2624 | Played: 1333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "UA = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "to_csv = lambda u: re.sub(r\"/results/(nhl-\\d{4})$\", r\"/download/\\1-UTC.csv\", u)\n",
    "TIMEZONE = \"America/Toronto\" \n",
    "\n",
    "def _parse_utc_datetime(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Parse the CSV 'Date' column (which is UTC text) into tz-aware UTC timestamps.\n",
    "    Tries multiple formats and both day-first and month-first just in case.\n",
    "    \"\"\"\n",
    "    s = series.astype(str)\n",
    "\n",
    "    # 1) Try day-first (site is typically DD/MM/YYYY HH:MM[:SS]) \n",
    "    dt = pd.to_datetime(s, errors=\"coerce\", utc=True, dayfirst=True)\n",
    "\n",
    "    # 2) For anything still NaT, try month-first (fallback for odd rows)\n",
    "    m = dt.isna()\n",
    "    if m.any():\n",
    "        dt.loc[m] = pd.to_datetime(s[m], errors=\"coerce\", utc=True, dayfirst=False)\n",
    "\n",
    "    return dt\n",
    "\n",
    "def load(u: str) -> pd.DataFrame:\n",
    "    url = to_csv(u)  \n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "    except Exception:\n",
    "        r = requests.get(url, headers=UA, timeout=20); r.raise_for_status()\n",
    "        df = pd.read_csv(StringIO(r.text))\n",
    "\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    lc = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    date_col = lc.get(\"date\") or next(c for c in df.columns if \"date\" in c.lower())\n",
    "    home_col = lc.get(\"home team\") or lc.get(\"home\") or next(c for c in df.columns if \"home\" in c.lower())\n",
    "    away_col = lc.get(\"away team\") or lc.get(\"away\") or next(c for c in df.columns if \"away\" in c.lower())\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"Date_str\": df[date_col].astype(str),\n",
    "        \"Home Team\": df[home_col].astype(str),\n",
    "        \"Away Team\": df[away_col].astype(str),\n",
    "    })\n",
    "\n",
    "    # --- scores/result mapping (unchanged idea) ---\n",
    "    if {\"Home Score\",\"Away Score\"}.issubset(df.columns):\n",
    "        out[\"Home Score\"] = pd.to_numeric(df[\"Home Score\"], errors=\"coerce\")\n",
    "        out[\"Away Score\"] = pd.to_numeric(df[\"Away Score\"], errors=\"coerce\")\n",
    "    elif \"Score\" in df.columns:\n",
    "        s = (df[\"Score\"].astype(str)\n",
    "             .str.replace(\"\\u2013\",\"-\",regex=False)\n",
    "             .str.replace(\"\\u2212\",\"-\",regex=False))\n",
    "        g = s.str.extract(r\"(\\d+)\\s*-\\s*(\\d+)\")\n",
    "        out[\"Home Score\"] = pd.to_numeric(g[0], errors=\"coerce\")\n",
    "        out[\"Away Score\"] = pd.to_numeric(g[1], errors=\"coerce\")\n",
    "    else:\n",
    "        out[\"Home Score\"] = pd.NA; out[\"Away Score\"] = pd.NA\n",
    "\n",
    "    out[\"Result\"] = df[lc[\"result\"]] if \"result\" in lc else \"\"\n",
    "\n",
    "    need = out[\"Home Score\"].isna() | out[\"Away Score\"].isna()\n",
    "    if need.any():\n",
    "        rnum = out.loc[need, \"Result\"].astype(str).str.extract(r\"(\\d+)\\s*-\\s*(\\d+)\")\n",
    "        out.loc[need, \"Home Score\"] = pd.to_numeric(rnum[0], errors=\"coerce\")\n",
    "        out.loc[need, \"Away Score\"] = pd.to_numeric(rnum[1], errors=\"coerce\")\n",
    "\n",
    "    # --- team name cleanup (keep accents; remove weird chars/spaces) ---\n",
    "    for c in (\"Home Team\",\"Away Team\"):\n",
    "        out[c] = (out[c].str.replace(r\"[^A-Za-zÀ-ÿ .'\\-]\", \"\", regex=True)\n",
    "                        .str.replace(r\"\\s{2,}\", \" \", regex=True)\n",
    "                        .str.strip())\n",
    "\n",
    "    # === CRITICAL: keep UTC and derive Local ===\n",
    "    out[\"Date_UTC\"]   = _parse_utc_datetime(out[\"Date_str\"])\n",
    "    out[\"Date_Local\"] = out[\"Date_UTC\"].dt.tz_convert(TIMEZONE)\n",
    "    out[\"LocalDate\"]  = out[\"Date_Local\"].dt.date\n",
    "\n",
    "    # sort/dedupe on UTC (stable total order)\n",
    "    out = (out.dropna(subset=[\"Date_UTC\"])\n",
    "              .sort_values(\"Date_UTC\")\n",
    "              .drop_duplicates([\"Date_UTC\",\"Home Team\",\"Away Team\"], keep=\"last\")\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "    return out[[\n",
    "        \"Date_UTC\",\"Date_Local\",\"LocalDate\",\n",
    "        \"Home Team\",\"Away Team\",\"Home Score\",\"Away Score\",\"Result\"\n",
    "    ]]\n",
    "\n",
    "# --- load seasons, merge, save ---\n",
    "df_2024 = load(\"https://fixturedownload.com/results/nhl-2024\"); df_2024[\"Season\"], df_2024[\"weight\"] = \"2024-2025\", 1.0\n",
    "df_2025 = load(\"https://fixturedownload.com/results/nhl-2025\"); df_2025[\"Season\"], df_2025[\"weight\"] = \"2025-2026\", 2.0\n",
    "\n",
    "df_all = pd.concat([df_2024, df_2025], ignore_index=True)\n",
    "df_all[\"Played\"] = df_all[\"Home Score\"].notna() & df_all[\"Away Score\"].notna()\n",
    "print(f\"Total rows: {len(df_all)} | Played: {int(df_all['Played'].sum())}\")\n",
    "\n",
    "df_all.to_csv(\"nhl_results_2024_2026_weighted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78714b40-09da-4645-94c4-7e5a42897d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize both data sources\n",
    "team_name_mapping = {\n",
    "    \"Montréal Canadiens\": \"Montreal Canadiens\"\n",
    "}\n",
    "\n",
    "df_all[\"Home Team\"] = df_all[\"Home Team\"].replace(team_name_mapping)\n",
    "df_all[\"Away Team\"] = df_all[\"Away Team\"].replace(team_name_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc1bdd65-499a-43fd-b2f3-ef4c1c9e38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Normalize team names to avoid silent mismatches ---\n",
    "for c in [\"Home Team\", \"Away Team\"]:\n",
    "    df_all[c] = df_all[c].astype(str).str.strip()\n",
    "\n",
    "df_rank = df_rank.copy()\n",
    "df_rank[\"Team\"] = df_rank[\"Team\"].astype(str).str.strip()\n",
    "df_rank[\"Rank\"] = pd.to_numeric(df_rank[\"Rank\"], errors=\"coerce\")\n",
    "\n",
    "# --- Build minimal rank frames (only needed columns!) ---\n",
    "rank_home = (df_rank.loc[:, [\"Team\", \"Rank\"]]\n",
    "                     .rename(columns={\"Team\": \"Home Team\", \"Rank\": \"Home Team Rank\"}))\n",
    "\n",
    "rank_away = (df_rank.loc[:, [\"Team\", \"Rank\"]]\n",
    "                     .rename(columns={\"Team\": \"Away Team\", \"Rank\": \"Away Team Rank\"}))\n",
    "\n",
    "# --- Drop any stale columns from previous merges to avoid collisions ---\n",
    "for col in [\"Home Team Rank\", \"Away Team Rank\", \"Rank\", \"Team\", \"Team Rank_x\", \"Team Rank_y\"]:\n",
    "    if col in df_all.columns:\n",
    "        df_all = df_all.drop(columns=col)\n",
    "\n",
    "# --- Merge one side at a time (no suffixes needed) ---\n",
    "df_all = df_all.merge(rank_home, on=\"Home Team\", how=\"left\")\n",
    "df_all = df_all.merge(rank_away, on=\"Away Team\", how=\"left\")\n",
    "\n",
    "# --- Home Win indicator (safe when scores are present) ---\n",
    "df_all[\"Home Win\"] = (\n",
    "    df_all[\"Home Score\"].notna() &\n",
    "    df_all[\"Away Score\"].notna() &\n",
    "    (df_all[\"Home Score\"] > df_all[\"Away Score\"])\n",
    ").astype(int)\n",
    "\n",
    "# --- If you want a naive local datetime \"Date\" for downstream code ---\n",
    "if \"Date_Local\" in df_all.columns:\n",
    "    df_all[\"Date\"] = df_all[\"Date_Local\"].dt.tz_localize(None)\n",
    "\n",
    "# --- Pick your final view ---\n",
    "final_columns = [\n",
    "    \"LocalDate\", \"Date_Local\", \"Date\",  # keep all three if useful\n",
    "    \"Home Team\", \"Home Score\", \"Away Team\", \"Away Score\",\n",
    "    \"Home Team Rank\", \"Away Team Rank\", \"Home Win\"\n",
    "]\n",
    "df_final = df_all.loc[:, [c for c in final_columns if c in df_all.columns]].copy()\n",
    "\n",
    "# --- Sanity checks ---\n",
    "for col in [\"Home Team Rank\", \"Away Team Rank\"]:\n",
    "    miss = df_final[col].isna().sum()\n",
    "    if miss:\n",
    "        print(f\"⚠️ Missing {miss} ranks in {col} (check team name aliases).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad1682fe-26a9-4a15-92ba-893ccb32f182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date            Home Team              Away Team  \\\n",
      "1323 2025-10-09 19:00:00       Buffalo Sabres       New York Rangers   \n",
      "1324 2025-10-09 19:00:00        Boston Bruins     Chicago Blackhawks   \n",
      "1325 2025-10-09 19:30:00  Carolina Hurricanes      New Jersey Devils   \n",
      "1326 2025-10-09 20:00:00  Nashville Predators  Columbus Blue Jackets   \n",
      "1327 2025-10-09 20:00:00        Winnipeg Jets           Dallas Stars   \n",
      "1328 2025-10-09 20:00:00      St. Louis Blues         Minnesota Wild   \n",
      "1329 2025-10-09 21:00:00   Colorado Avalanche       Utah Hockey Club   \n",
      "1330 2025-10-09 22:00:00      San Jose Sharks   Vegas Golden Knights   \n",
      "1331 2025-10-09 22:00:00       Seattle Kraken          Anaheim Ducks   \n",
      "1332 2025-10-09 22:00:00    Vancouver Canucks         Calgary Flames   \n",
      "\n",
      "      Home Opponent Strength  Away Opponent Strength  Home Last 10 Wins  \\\n",
      "1323                    12.9                    17.2                  6   \n",
      "1324                    16.6                    14.6                  4   \n",
      "1325                    15.6                    20.0                  3   \n",
      "1326                    14.3                    15.0                  3   \n",
      "1327                    14.9                    21.2                  7   \n",
      "1328                    16.5                    17.5                  7   \n",
      "1329                    15.2                    17.1                  5   \n",
      "1330                    14.4                    14.6                  0   \n",
      "1331                    11.9                    11.8                  5   \n",
      "1332                    13.6                    16.7                  4   \n",
      "\n",
      "      Away Last 10 Wins  Home Played Yesterday  Away Played Yesterday  \\\n",
      "1323                  5                  False                  False   \n",
      "1324                  4                  False                  False   \n",
      "1325                  5                  False                  False   \n",
      "1326                  7                  False                  False   \n",
      "1327                  3                  False                  False   \n",
      "1328                  5                  False                  False   \n",
      "1329                  6                  False                  False   \n",
      "1330                  5                  False                  False   \n",
      "1331                  3                  False                  False   \n",
      "1332                  7                  False                   True   \n",
      "\n",
      "      Home Win Rate  Away Win Rate  Home Team Overall Win Streak Before Game  \\\n",
      "1323       0.560976       0.487805                                         1   \n",
      "1324       0.487805       0.238095                                         1   \n",
      "1325       0.756098       0.560976                                         0   \n",
      "1326       0.487805       0.341463                                         1   \n",
      "1327       0.731707       0.536585                                         1   \n",
      "1328       0.585366       0.560976                                         1   \n",
      "1329       0.634146       0.487805                                         2   \n",
      "1330       0.292683       0.512195                                         0   \n",
      "1331       0.439024       0.341463                                         0   \n",
      "1332       0.414634       0.452381                                         0   \n",
      "\n",
      "      Away Team Overall Win Streak Before Game  \\\n",
      "1323                                         0   \n",
      "1324                                         0   \n",
      "1325                                         0   \n",
      "1326                                         6   \n",
      "1327                                         0   \n",
      "1328                                         2   \n",
      "1329                                         0   \n",
      "1330                                         0   \n",
      "1331                                         0   \n",
      "1332                                         5   \n",
      "\n",
      "      Away Rest Days Since Last Game  Home Rest Days Since Last Game  \n",
      "1323                             1.0                             NaN  \n",
      "1324                             2.0                             0.0  \n",
      "1325                             NaN                             NaN  \n",
      "1326                             NaN                             NaN  \n",
      "1327                             NaN                             NaN  \n",
      "1328                             NaN                             NaN  \n",
      "1329                             NaN                             1.0  \n",
      "1330                             1.0                             NaN  \n",
      "1331                             NaN                             NaN  \n",
      "1332                             1.0                             NaN  \n"
     ]
    }
   ],
   "source": [
    "#DATA MANIPULATION\n",
    "\n",
    "\n",
    "# Filter out the Unplayed Games\n",
    "df_final = df_final.dropna(subset=[\"Home Score\", \"Away Score\"])\n",
    "\n",
    "# Convert Scores and Dates to Appropriate Data Types\n",
    "df_final[\"Date\"] = pd.to_datetime(df_final[\"Date\"], format=\"%d/%m/%Y\")\n",
    "df_final[[\"Home Score\", \"Away Score\"]] = df_final[[\"Home Score\", \"Away Score\"]].astype(int)\n",
    "df_final[\"Home Win\"] = df_final[\"Home Win\"].astype(bool)\n",
    "\n",
    "# Sort Data by Date for Chronological Calculations\n",
    "df_final = df_final.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Function: Calculate Last 10 Games Stats\n",
    "def calculate_last_10_stats(df, team_column):\n",
    "    last_10_wins = []\n",
    "    team_games = {team: [] for team in pd.concat([df[\"Home Team\"], df[\"Away Team\"]]).unique()}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        team = row[team_column]\n",
    "        recent_games = team_games[team][-10:]  # Last 10 games\n",
    "        last_10_wins.append(sum(recent_games))\n",
    "        team_games[row[\"Home Team\"]].append(row[\"Home Win\"])\n",
    "        team_games[row[\"Away Team\"]].append(not row[\"Home Win\"])\n",
    "    return last_10_wins\n",
    "\n",
    "# Add Last 10 Wins for Home and Away Teams\n",
    "df_final[\"Home Last 10 Wins\"] = calculate_last_10_stats(df_final, \"Home Team\")\n",
    "df_final[\"Away Last 10 Wins\"] = calculate_last_10_stats(df_final, \"Away Team\")\n",
    "\n",
    "# Add Whether Teams Played Yesterday\n",
    "def calculate_played_yesterday(df, team_column):\n",
    "    played_yesterday = []\n",
    "    last_game_date = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        team = row[team_column]\n",
    "        played_yesterday.append(last_game_date.get(team) == row[\"Date\"] - pd.Timedelta(days=1))\n",
    "        last_game_date[team] = row[\"Date\"]\n",
    "    return played_yesterday\n",
    "\n",
    "df_final[\"Home Played Yesterday\"] = calculate_played_yesterday(df_final, \"Home Team\")\n",
    "df_final[\"Away Played Yesterday\"] = calculate_played_yesterday(df_final, \"Away Team\")\n",
    "\n",
    "# Add Win Rate for Home and Away Teams\n",
    "def calculate_win_rate(df, team_column, is_home_column):\n",
    "    win_rate = []\n",
    "    team_stats = {team: {\"wins\": 0, \"games\": 0} for team in pd.concat([df[\"Home Team\"], df[\"Away Team\"]]).unique()}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        team = row[team_column]\n",
    "        stats = team_stats[team]\n",
    "        win_rate.append(stats[\"wins\"] / stats[\"games\"] if stats[\"games\"] > 0 else 0)\n",
    "        \n",
    "        \n",
    "        if is_home_column:\n",
    "            stats[\"wins\"] += row[\"Home Win\"]\n",
    "        else:\n",
    "            stats[\"wins\"] += not row[\"Home Win\"]\n",
    "        stats[\"games\"] += 1\n",
    "    return win_rate\n",
    "\n",
    "df_final[\"Home Win Rate\"] = calculate_win_rate(df_final, \"Home Team\", is_home_column=True)\n",
    "df_final[\"Away Win Rate\"] = calculate_win_rate(df_final, \"Away Team\", is_home_column=False)\n",
    "\n",
    "# Add Overall Win Streak for Home and Away Teams\n",
    "def calculate_overall_win_streak(df):\n",
    "    streak = {}\n",
    "    home_streaks = []\n",
    "    away_streaks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        home_team = row[\"Home Team\"]\n",
    "        away_team = row[\"Away Team\"]\n",
    "\n",
    "        \n",
    "        home_streaks.append(streak.get(home_team, 0))\n",
    "        away_streaks.append(streak.get(away_team, 0))\n",
    "\n",
    "        \n",
    "        if row[\"Home Win\"]:\n",
    "            streak[home_team] = streak.get(home_team, 0) + 1\n",
    "            streak[away_team] = 0\n",
    "        else:\n",
    "            streak[home_team] = 0\n",
    "            streak[away_team] = streak.get(away_team, 0) + 1\n",
    "    return home_streaks, away_streaks\n",
    "\n",
    "home_streaks, away_streaks = calculate_overall_win_streak(df_final)\n",
    "df_final[\"Home Team Overall Win Streak Before Game\"] = home_streaks\n",
    "df_final[\"Away Team Overall Win Streak Before Game\"] = away_streaks\n",
    "\n",
    "# Add Average Opponent Strength for Home and Away Teams\n",
    "def calculate_avg_opponent_rank(df, team_column, opponent_rank_column):\n",
    "    avg_opponent_rank = []\n",
    "    opponent_stats = {team: [] for team in pd.concat([df[\"Home Team\"], df[\"Away Team\"]]).unique()}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        team = row[team_column]\n",
    "        avg_opponent_rank.append(\n",
    "            np.mean(opponent_stats[team][-10:]) if opponent_stats[team] else np.nan\n",
    "        )\n",
    "        opponent_stats[row[\"Home Team\"]].append(row[\"Away Team Rank\"])\n",
    "        opponent_stats[row[\"Away Team\"]].append(row[\"Home Team Rank\"])\n",
    "    return avg_opponent_rank\n",
    "\n",
    "df_final[\"Home Opponent Strength\"] = calculate_avg_opponent_rank(df_final, \"Home Team\", \"Away Team Rank\")\n",
    "df_final[\"Away Opponent Strength\"] = calculate_avg_opponent_rank(df_final, \"Away Team\", \"Home Team Rank\")\n",
    "\n",
    "OFFSEASON_GAP_DAYS = 45  \n",
    "\n",
    "def calculate_days_since_last_game(df, gap=OFFSEASON_GAP_DAYS):\n",
    "    last_game_date = {}\n",
    "    home_rest, away_rest = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        d = row[\"Date\"]\n",
    "        h = row[\"Home Team\"]; a = row[\"Away Team\"]\n",
    "\n",
    "        # home\n",
    "        prev = last_game_date.get(h)\n",
    "        if prev is None:\n",
    "            home_rest.append(None)\n",
    "        else:\n",
    "            delta = (d - prev).days\n",
    "            home_rest.append(delta if delta <= gap else None)\n",
    "\n",
    "        # away\n",
    "        prev = last_game_date.get(a)\n",
    "        if prev is None:\n",
    "            away_rest.append(None)\n",
    "        else:\n",
    "            delta = (d - prev).days\n",
    "            away_rest.append(delta if delta <= gap else None)\n",
    "\n",
    "        # update last seen dates\n",
    "        last_game_date[h] = d\n",
    "        last_game_date[a] = d\n",
    "\n",
    "    return home_rest, away_rest\n",
    "\n",
    "# Apply\n",
    "home_days, away_days = calculate_days_since_last_game(df_final)\n",
    "df_final[\"Home Rest Days Since Last Game\"] = home_days\n",
    "df_final[\"Away Rest Days Since Last Game\"] = away_days\n",
    "\n",
    "print(df_final[[\"Date\", \"Home Team\", \"Away Team\", \"Home Opponent Strength\", \"Away Opponent Strength\",\"Home Last 10 Wins\",\"Away Last 10 Wins\",\"Home Played Yesterday\",\"Away Played Yesterday\",\"Home Win Rate\",\"Away Win Rate\",\"Home Team Overall Win Streak Before Game\",\"Away Team Overall Win Streak Before Game\",\"Away Rest Days Since Last Game\",\"Home Rest Days Since Last Game\"]].tail(10))\n",
    "\n",
    "\n",
    "df_final.to_csv(\"enhanced_game_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6507280b-353c-4375-ac48-415d2b8060dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"Rank Difference\"] = df_final[\"Home Team Rank\"] - df_final[\"Away Team Rank\"]\n",
    "df_final[\"Home Advantage\"] = df_final[\"Home Win Rate\"] - df_final[\"Away Win Rate\"]\n",
    "df_final[\"Win Streak Impact\"] = df_final[\"Home Team Overall Win Streak Before Game\"] - df_final[\"Away Team Overall Win Streak Before Game\"]\n",
    "df_final[\"Opponent Strength\"] = df_final[\"Home Opponent Strength\"] - df_final[\"Away Opponent Strength\"]\n",
    "df_final[\"Last 10 Wins\"] = df_final[\"Home Last 10 Wins\"] - df_final[\"Away Last 10 Wins\"]\n",
    "df_final[\"Opponent Strength\"] = df_final[\"Home Opponent Strength\"] - df_final[\"Away Opponent Strength\"]\n",
    "df_final = df_final.dropna().reset_index(drop=True)\n",
    "\n",
    "results1 = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89c7fdff-562e-4210-8890-a4e8a975d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Always Home) — F1: 0.4102, ROC AUC: 0.5, Brier: 0.4331\n",
      "Baseline (Always Away) — F1: 0.2618, ROC AUC: 0.5, Brier: 0.5669\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scorer = make_scorer(f1_score, pos_label=None, average='weighted')\n",
    "\n",
    "y_true = df_final[\"Home Win\"].astype(int).values\n",
    "\n",
    "y_pred = np.ones_like(y_true)                   \n",
    "y_proba = np.ones_like(y_true, dtype=float)     \n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "\n",
    "try:\n",
    "    roc = roc_auc_score(y_true, y_proba)\n",
    "except ValueError:\n",
    "    roc = float(\"nan\")  # undefined for constant scores\n",
    "\n",
    "\n",
    "brier = brier_score_loss(y_true, y_proba)\n",
    "\n",
    "print(f\"Baseline (Always Home) — F1: {f1:.4f}, ROC AUC: {roc}, Brier: {brier:.4f}\")\n",
    "y_pred_away = np.zeros_like(y_true)\n",
    "y_proba_away = np.zeros_like(y_true, dtype=float)\n",
    "\n",
    "f1_away = f1_score(y_true, y_pred_away, average=\"weighted\")\n",
    "try:\n",
    "    roc_away = roc_auc_score(y_true, y_proba_away)\n",
    "except ValueError:\n",
    "    roc_away = float(\"nan\")\n",
    "brier_away = brier_score_loss(y_true, y_proba_away)\n",
    "\n",
    "print(f\"Baseline (Always Away) — F1: {f1_away:.4f}, ROC AUC: {roc_away}, Brier: {brier_away:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ae520b5-6880-4f84-ad35-8524ec7fb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_final.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "feature_cols = [\n",
    "    \"Opponent Strength\",\"Rank Difference\",\"Last 10 Wins\",\n",
    "    \"Home Played Yesterday\",\"Away Played Yesterday\",\n",
    "    \"Home Advantage\",\"Win Streak Impact\",\n",
    "    \"Away Rest Days Since Last Game\",\"Home Rest Days Since Last Game\"\n",
    "]\n",
    "target_col = \"Home Win\"\n",
    "\n",
    "X_all = df_sorted[feature_cols]\n",
    "y_all = df_sorted[target_col].astype(int)\n",
    "\n",
    "split_idx = int(0.8 * len(df_sorted))\n",
    "X_train, X_test = X_all.iloc[:split_idx], X_all.iloc[split_idx:]\n",
    "y_train, y_test = y_all.iloc[:split_idx], y_all.iloc[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bd3ea4a-bdd7-4c69-ad7d-5ead3e5f0d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF:\n",
      " Home Rest Days Since Last Game    2.095341\n",
      "Away Rest Days Since Last Game    2.094086\n",
      "Last 10 Wins                      1.773812\n",
      "Rank Difference                   1.524821\n",
      "Home Advantage                    1.430042\n",
      "Win Streak Impact                 1.306215\n",
      "Opponent Strength                 1.036626\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_vif(df):\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "    X = sm.add_constant(df)\n",
    "    vif = pd.Series(\n",
    "        [variance_inflation_factor(X.values, i) for i in range(1, X.shape[1])],\n",
    "        index=df.columns\n",
    "    )\n",
    "    return vif.sort_values(ascending=False)\n",
    "\n",
    "vif_series = compute_vif(X_train.select_dtypes(include=[np.number]))\n",
    "print(\"VIF:\\n\", vif_series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3905c7bd-49ec-4e30-9814-104e15413bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 579, number of negative: 455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 619\n",
      "[LightGBM] [Info] Number of data points in the train set: 1034, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.559961 -> initscore=0.241005\n",
      "[LightGBM] [Info] Start training from score 0.241005\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 1034, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.559961 -> initscore=0.241005\n",
      "[LightGBM] [Info] Start training from score 0.241005\n",
      "\n",
      "=== Models ===\n",
      "           Model        F1   ROC_AUC     Brier\n",
      "0           MLP  0.631320  0.673995  0.221418\n",
      "1      Logistic  0.627614  0.668955  0.222220\n",
      "2  RandomForest  0.589427  0.619109  0.235825\n",
      "3      LightGBM  0.592889  0.607607  0.260170\n",
      "\n",
      "Selected features:\n",
      " {'Logistic': ['Opponent_Strength', 'Rank_Difference', 'Last_10_Wins', 'Home_Played_Yesterday', 'Away_Played_Yesterday', 'Home_Advantage', 'Away_Rest_Days_Since_Last_Game', 'Home_Rest_Days_Since_Last_Game'], 'MLP': ['Rank_Difference', 'Away_Played_Yesterday', 'Win_Streak_Impact', 'Away_Rest_Days_Since_Last_Game'], 'RandomForest': ['Opponent_Strength', 'Rank_Difference', 'Last_10_Wins', 'Home_Advantage', 'Win_Streak_Impact'], 'LightGBM': ['Opponent_Strength', 'Rank_Difference', 'Last_10_Wins', 'Home_Advantage', 'Win_Streak_Impact']}\n",
      "\n",
      "Best: MLP\n",
      "Final metrics: {'F1': 0.6392485511021142, 'ROC_AUC': np.float64(0.6718614718614718), 'Brier': np.float64(0.22092151978121563)}\n"
     ]
    }
   ],
   "source": [
    "# 0) Features & split\n",
    "feature_cols = [\n",
    "    \"Opponent Strength\",\"Rank Difference\",\"Last 10 Wins\",\n",
    "    \"Home Played Yesterday\",\"Away Played Yesterday\",\n",
    "    \"Home Advantage\",\"Win Streak Impact\",\n",
    "    \"Away Rest Days Since Last Game\",\"Home Rest Days Since Last Game\"\n",
    "]\n",
    "target_col = \"Home Win\"\n",
    "\n",
    "df = df_final.sort_values(\"Date\").reset_index(drop=True)\n",
    "rename_map = {c: c.replace(\" \", \"_\") for c in feature_cols}\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "feat = [rename_map[c] for c in feature_cols]\n",
    "X, y = df[feat], df[target_col].astype(int)\n",
    "\n",
    "split = int(0.8 * len(df))\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "cv5 = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# 1) Name-preserving selectors\n",
    "class NamePreservingSelectFromModel(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, estimator, threshold=\"median\"):\n",
    "        self.estimator = estimator\n",
    "        self.threshold = threshold\n",
    "        self.selected_cols_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        if not hasattr(X, \"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        est = clone(self.estimator).fit(X, y)\n",
    "        sfm = SelectFromModel(est, threshold=self.threshold, prefit=True)\n",
    "        self.selected_cols_ = list(X.columns[sfm.get_support()])\n",
    "        return self\n",
    "    def transform(self, X): return X[self.selected_cols_]\n",
    "\n",
    "class NamePreservingSelectKBest(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, score_func=mutual_info_classif, k=5):\n",
    "        self.score_func = score_func; self.k = k; self.selected_cols_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        if not hasattr(X, \"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        skb = SelectKBest(self.score_func, k=self.k).fit(X, y)\n",
    "        self.selected_cols_ = list(X.columns[skb.get_support()])\n",
    "        return self\n",
    "    def transform(self, X): return X[self.selected_cols_]\n",
    "\n",
    "class NamePreservingRFECV(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, estimator, step=1, cv=None, scoring=\"neg_brier_score\", min_features_to_select=1):\n",
    "        self.estimator = estimator; self.step = step; self.cv = cv\n",
    "        self.scoring = scoring; self.min_features_to_select = min_features_to_select\n",
    "        self.selected_cols_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        if not hasattr(X, \"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        r = RFECV(self.estimator, step=self.step, cv=self.cv, scoring=self.scoring,\n",
    "                  min_features_to_select=self.min_features_to_select).fit(X, y)\n",
    "        self.selected_cols_ = list(X.columns[r.support_]); return self\n",
    "    def transform(self, X): return X[self.selected_cols_]\n",
    "\n",
    "# 2) Pipelines\n",
    "pipe_logistic = Pipeline([\n",
    "    (\"rfe\", NamePreservingRFECV(LogisticRegression(max_iter=1000), step=1, cv=cv5, scoring=\"neg_brier_score\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipe_mlp = Pipeline([\n",
    "    (\"skb\", NamePreservingSelectKBest(k=max(3, len(feat)//2))),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", MLPClassifier(max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "pipe_lgbm = Pipeline([\n",
    "    (\"sfm\", NamePreservingSelectFromModel(LGBMClassifier(random_state=42), threshold=\"median\")),\n",
    "    (\"clf\", LGBMClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    (\"sfm\", NamePreservingSelectFromModel(RandomForestClassifier(n_estimators=400, random_state=42), threshold=\"median\")),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=400, random_state=42))\n",
    "])\n",
    "\n",
    "candidates = {\n",
    "    \"Logistic\": pipe_logistic,\n",
    "    \"MLP\": pipe_mlp,\n",
    "    \"RandomForest\": pipe_rf,\n",
    "    \"LightGBM\": pipe_lgbm,\n",
    "}\n",
    "\n",
    "# 3) Fit / evaluate / save\n",
    "def evaluate(model, X_te, y_te):\n",
    "    y_hat = model.predict(X_te)\n",
    "    p = model.predict_proba(X_te)[:, 1]\n",
    "    return {\"F1\": f1_score(y_te, y_hat, average=\"weighted\"),\n",
    "            \"ROC_AUC\": roc_auc_score(y_te, p),\n",
    "            \"Brier\": brier_score_loss(y_te, p)}\n",
    "\n",
    "results, selected = [], {}\n",
    "\n",
    "for name, model in candidates.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    results.append({\"Model\": name, **evaluate(model, X_test, y_test)})\n",
    "    # grab selected cols from whichever selector exists\n",
    "    sel_cols = None\n",
    "    for key in (\"rfe\", \"skb\", \"sfm\"):\n",
    "        if key in model.named_steps and hasattr(model.named_steps[key], \"selected_cols_\"):\n",
    "            sel_cols = model.named_steps[key].selected_cols_\n",
    "    selected[name] = sel_cols\n",
    "    joblib.dump(model, f\"model_{name}.joblib\")\n",
    "\n",
    "with open(\"selected_features.json\", \"w\") as f:\n",
    "    json.dump({\"rename_map\": rename_map, \"selected_features\": selected}, f, indent=2)\n",
    "\n",
    "res = (pd.DataFrame(results)\n",
    "         .sort_values([\"Brier\",\"ROC_AUC\",\"F1\"], ascending=[True, False, False])\n",
    "         .reset_index(drop=True))\n",
    "print(\"\\n=== Models ===\\n\", res[[\"Model\",\"F1\",\"ROC_AUC\",\"Brier\"]])\n",
    "print(\"\\nSelected features:\\n\", selected)\n",
    "\n",
    "# 4) Best by Brier; calibrate if not Logistic\n",
    "best = res.iloc[0][\"Model\"]\n",
    "pipe = joblib.load(f\"model_{best}.joblib\")\n",
    "\n",
    "final_model = pipe if best == \"Logistic\" else CalibratedClassifierCV(pipe, method=\"isotonic\", cv=5).fit(X_train, y_train)\n",
    "joblib.dump(final_model, f\"model_{best}_CALIBRATED.joblib\")\n",
    "\n",
    "print(\"\\nBest:\", best)\n",
    "print(\"Final metrics:\", evaluate(final_model, X_test, y_test))\n",
    "\n",
    "# 5) Load & predict helper\n",
    "def load_model_and_predict(model_name: str, X_new: pd.DataFrame) -> np.ndarray:\n",
    "    with open(\"selected_features.json\", \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    Xn = X_new.rename(columns={k: v for k, v in meta[\"rename_map\"].items() if k in X_new.columns})\n",
    "    path = f\"model_{model_name}_CALIBRATED.joblib\"\n",
    "    if not os.path.exists(path): path = f\"model_{model_name}.joblib\"\n",
    "    mdl = joblib.load(path)\n",
    "    return mdl.predict_proba(Xn)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5245cfd9-5b3f-4445-86f0-4df61557dd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n",
      "Fitting 6 folds for each of 150 candidates, totalling 900 fits\n",
      "L2: {'F1': 0.6358443549932912, 'ROC_AUC': np.float64(0.6705627705627706), 'Brier': np.float64(0.22248184108964386)} \n",
      "EN: {'F1': 0.6313199478296333, 'ROC_AUC': np.float64(0.6695423623995054), 'Brier': np.float64(0.2223111809585435)} \n",
      "MLP: {'F1': 0.628529568517234, 'ROC_AUC': np.float64(0.6746444032158317), 'Brier': np.float64(0.22233319372244176)}\n",
      "Final Logistic: {'F1': 0.6313199478296333, 'ROC_AUC': np.float64(0.6695423623995054), 'Brier': np.float64(0.2223111809585435)} \n",
      "Final MLP: {'F1': 0.636218155954998, 'ROC_AUC': np.float64(0.6686765615337045), 'Brier': np.float64(0.2216908301975163)}\n",
      "Ensemble: {'F1': 0.6255497231154612, 'ROC_AUC': np.float64(0.6728509585652444), 'Brier': np.float64(0.22129796506557733)}\n"
     ]
    }
   ],
   "source": [
    "# ==== CONFIG ====\n",
    "SEED=42\n",
    "CV_SPLITS=6\n",
    "N_ITER_LOG_L2=40\n",
    "N_ITER_LOG_EN=40\n",
    "N_ITER_MLP=150              # ↑ more tries for twitchy MLP\n",
    "RFE_MIN_FEATS=1\n",
    "MLP_MAX_ITER=2000           # ↑ relies on early stopping anyway\n",
    "MLP_EARLY_STOP=True\n",
    "MLP_VAL_FRAC=0.12           # ↓ slightly smaller val set\n",
    "MLP_PATIENCE=20             # ↑ give early stopping time to work\n",
    "TEST_RATIO=0.2\n",
    "\n",
    "FEATURE_COLS=[\n",
    "    \"Opponent Strength\",\"Rank Difference\",\"Last 10 Wins\",\n",
    "    \"Home Played Yesterday\",\"Away Played Yesterday\",\n",
    "    \"Home Advantage\",\"Win Streak Impact\",\n",
    "    \"Away Rest Days Since Last Game\",\"Home Rest Days Since Last Game\"\n",
    "]\n",
    "TARGET_COL=\"Home Win\"\n",
    "\n",
    "# seeds\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ==== DATA (time-ordered split) ====\n",
    "df = df_final.sort_values(\"Date\").reset_index(drop=True)\n",
    "rename_map = {c: c.replace(\" \",\"_\") for c in FEATURE_COLS}\n",
    "df = df.rename(columns=rename_map)\n",
    "feat = [rename_map[c] for c in FEATURE_COLS]\n",
    "X, y = df[feat], df[TARGET_COL].astype(int)\n",
    "\n",
    "cut = int((1-TEST_RATIO)*len(df))\n",
    "X_tr, X_te = X.iloc[:cut], X.iloc[cut:]\n",
    "y_tr, y_te = y.iloc[:cut], y.iloc[cut:]\n",
    "\n",
    "# --- IMPORTANT: time-series CV with a small gap to reduce leakage ---\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=CV_SPLITS, gap=3)\n",
    "\n",
    "# ==== HELPERS ====\n",
    "def evaluate(m, Xt, yt):\n",
    "    p = m.predict_proba(Xt)[:,1]; yhat = (p>=0.5).astype(int)\n",
    "    return {\"F1\": f1_score(yt,yhat,average=\"weighted\"),\n",
    "            \"ROC_AUC\": roc_auc_score(yt,p),\n",
    "            \"Brier\": brier_score_loss(yt,p)}\n",
    "\n",
    "# name-preserving selectors\n",
    "class NPSFM(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self,estimator,threshold=\"median\"):\n",
    "        self.estimator=estimator; self.threshold=threshold; self.selected_cols_=None\n",
    "    def fit(self,X,y=None):\n",
    "        if not hasattr(X,\"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        sfm=SelectFromModel(clone(self.estimator).fit(X,y),threshold=self.threshold,prefit=True)\n",
    "        self.selected_cols_=list(X.columns[sfm.get_support()]); return self\n",
    "    def transform(self,X): return X[self.selected_cols_]\n",
    "\n",
    "class NPSKB(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self,score_func=mutual_info_classif,k=\"all\"):   # default: keep all\n",
    "        self.score_func=score_func; self.k=k; self.selected_cols_=None\n",
    "    def fit(self,X,y=None):\n",
    "        if not hasattr(X,\"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        skb=SelectKBest(self.score_func,k=self.k).fit(X,y)\n",
    "        self.selected_cols_=list(X.columns[skb.get_support()]); return self\n",
    "    def transform(self,X): return X[self.selected_cols_]\n",
    "\n",
    "class NPRFECV(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self,estimator,step=1,cv=None,scoring=\"neg_brier_score\",min_features_to_select=1):\n",
    "        self.estimator=estimator; self.step=step; self.cv=cv; self.scoring=scoring; self.min_features_to_select=min_features_to_select\n",
    "        self.selected_cols_=None\n",
    "    def fit(self,X,y=None):\n",
    "        if not hasattr(X,\"columns\"): raise TypeError(\"Need pandas DataFrame.\")\n",
    "        r=RFECV(self.estimator,step=self.step,cv=self.cv,scoring=self.scoring,\n",
    "                min_features_to_select=self.min_features_to_select).fit(X,y)\n",
    "        self.selected_cols_=list(X.columns[r.support_]); return self\n",
    "    def transform(self,X): return X[self.selected_cols_]\n",
    "\n",
    "# ==== PIPELINES ====\n",
    "from sklearn.preprocessing import RobustScaler  # more robust than StandardScaler for MLP\n",
    "pipe_log_l2 = Pipeline([\n",
    "    (\"rfe\",NPRFECV(LogisticRegression(max_iter=2000,solver=\"lbfgs\"),\n",
    "                   step=1,cv=tscv,scoring=\"neg_brier_score\",min_features_to_select=RFE_MIN_FEATS)),\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"clf\",LogisticRegression(max_iter=2000,solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "pipe_log_en = Pipeline([\n",
    "    (\"rfe\",NPRFECV(LogisticRegression(max_iter=2000,solver=\"saga\",penalty=\"elasticnet\",l1_ratio=0.5,random_state=SEED),\n",
    "                   step=1,cv=tscv,scoring=\"neg_brier_score\",min_features_to_select=RFE_MIN_FEATS)),\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"clf\",LogisticRegression(max_iter=2000,solver=\"saga\",penalty=\"elasticnet\",random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_mlp = Pipeline([\n",
    "    (\"skb\",NPSKB(k=\"all\")),                   # allow 'all' features as an option\n",
    "    (\"scaler\",RobustScaler()),                # swap to RobustScaler for outlier resistance\n",
    "    (\"clf\",MLPClassifier(max_iter=MLP_MAX_ITER,random_state=SEED,\n",
    "                         early_stopping=MLP_EARLY_STOP,n_iter_no_change=MLP_PATIENCE,\n",
    "                         validation_fraction=MLP_VAL_FRAC,learning_rate=\"adaptive\"))\n",
    "])\n",
    "\n",
    "# ==== SEARCH SPACES ====\n",
    "param_log_l2={\"clf__C\":loguniform(1e-3,1e1),\"clf__class_weight\":[None,\"balanced\"]}\n",
    "param_log_en={\"clf__C\":loguniform(1e-3,1e1),\"clf__l1_ratio\":uniform(0,1),\"clf__class_weight\":[None,\"balanced\"]}\n",
    "\n",
    "# broadened MLP space; SGD options are ignored automatically if solver='adam'\n",
    "param_mlp={\n",
    "    \"skb__k\":[\"all\", max(4,len(feat)//2), max(6,len(feat)//2+2)],\n",
    "    \"clf__solver\":[\"adam\",\"sgd\"],\n",
    "    \"clf__hidden_layer_sizes\":[(64,),(128,),(256,),(64,32),(128,64)],\n",
    "    \"clf__activation\":[\"relu\",\"tanh\"],\n",
    "    \"clf__alpha\":loguniform(1e-6,1e-1),\n",
    "    \"clf__learning_rate_init\":loguniform(5e-4,1e-2),\n",
    "    \"clf__batch_size\":[32,64,128],\n",
    "    \"clf__learning_rate\":[\"adaptive\",\"invscaling\"],  # sgd only\n",
    "    \"clf__momentum\":uniform(0.6,0.39),               # sgd only, 0.6–0.99\n",
    "    \"clf__nesterovs_momentum\":[True,False],          # sgd only\n",
    "}\n",
    "\n",
    "scoring={\"brier\":\"neg_brier_score\",\"roc_auc\":\"roc_auc\",\"f1w\":\"f1_weighted\"}\n",
    "\n",
    "# ==== TUNE + TRAIN ====\n",
    "rs_log_l2=RandomizedSearchCV(pipe_log_l2,param_log_l2,n_iter=N_ITER_LOG_L2,scoring=scoring,\n",
    "                             refit=\"brier\",cv=tscv,n_jobs=-1,verbose=1,random_state=SEED).fit(X_tr,y_tr)\n",
    "rs_log_en=RandomizedSearchCV(pipe_log_en,param_log_en,n_iter=N_ITER_LOG_EN,scoring=scoring,\n",
    "                             refit=\"brier\",cv=tscv,n_jobs=-1,verbose=1,random_state=SEED).fit(X_tr,y_tr)\n",
    "rs_mlp   =RandomizedSearchCV(pipe_mlp,   param_mlp,   n_iter=N_ITER_MLP,   scoring=scoring,\n",
    "                             refit=\"brier\",cv=tscv,n_jobs=-1,verbose=1,random_state=SEED).fit(X_tr,y_tr)\n",
    "\n",
    "best_log_l2, best_log_en, best_mlp = rs_log_l2.best_estimator_, rs_log_en.best_estimator_, rs_mlp.best_estimator_\n",
    "\n",
    "# ==== HOLDOUT ====\n",
    "m_l2, m_en, m_mlp = evaluate(best_log_l2,X_te,y_te), evaluate(best_log_en,X_te,y_te), evaluate(best_mlp,X_te,y_te)\n",
    "print(\"L2:\",m_l2,\"\\nEN:\",m_en,\"\\nMLP:\",m_mlp)\n",
    "\n",
    "# choose logistic winner; calibrate MLP if it helps Brier\n",
    "log_final, log_metrics = (best_log_l2,m_l2) if m_l2[\"Brier\"]<=m_en[\"Brier\"] else (best_log_en,m_en)\n",
    "\n",
    "def calibrate_if_better(model,Xtr,ytr,Xte,yte):\n",
    "    base=evaluate(model,Xte,yte)\n",
    "    cal=CalibratedClassifierCV(model,method=\"isotonic\",cv=5).fit(Xtr,ytr)\n",
    "    calm=evaluate(cal,Xte,yte)\n",
    "    return (cal,calm) if calm[\"Brier\"]<=base[\"Brier\"] else (model,base)\n",
    "\n",
    "mlp_final, mlp_metrics = calibrate_if_better(best_mlp,X_tr,y_tr,X_te,y_te)\n",
    "print(\"Final Logistic:\",log_metrics,\"\\nFinal MLP:\",mlp_metrics)\n",
    "\n",
    "# ==== SAVE MODELS ====\n",
    "joblib.dump(log_final,\"model_Logistic_TUNED.joblib\")\n",
    "joblib.dump(mlp_final,\"model_MLP_TUNED.joblib\")\n",
    "\n",
    "# ==== SELECTED FEATURES (SAFE WITH CALIBRATION WRAPPER) ====\n",
    "def _unwrap_pipeline(model):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    if isinstance(model, Pipeline):\n",
    "        return model\n",
    "    if isinstance(model, CalibratedClassifierCV):\n",
    "        be = getattr(model, \"base_estimator\", None)\n",
    "        if isinstance(be, Pipeline):\n",
    "            return be\n",
    "        ccs = getattr(model, \"calibrated_classifiers_\", None)\n",
    "        if ccs and hasattr(ccs[0], \"estimator\") and isinstance(ccs[0].estimator, Pipeline):\n",
    "            return ccs[0].estimator\n",
    "    return None\n",
    "\n",
    "def selected_cols_from(model, default=None):\n",
    "    pipe = _unwrap_pipeline(model)\n",
    "    if pipe is None:\n",
    "        return default\n",
    "    for k in (\"rfe\",\"skb\",\"sfm\"):\n",
    "        step = pipe.named_steps.get(k)\n",
    "        if step is not None and hasattr(step,\"selected_cols_\"):\n",
    "            return step.selected_cols_\n",
    "    return default\n",
    "\n",
    "with open(\"selected_features.json\",\"w\") as f:\n",
    "    json.dump({\n",
    "        \"rename_map\": rename_map,\n",
    "        \"selected_features\": {\n",
    "            \"Logistic\": selected_cols_from(log_final, default=feat),\n",
    "            \"MLP\":      selected_cols_from(mlp_final,  default=feat)\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "# ==== SIMPLE ENSEMBLE (avg probs) ====\n",
    "p_log = log_final.predict_proba(X_te)[:,1]\n",
    "p_mlp = mlp_final.predict_proba(X_te)[:,1]\n",
    "p_avg = 0.5*p_log + 0.5*p_mlp\n",
    "ens = {\"F1\": f1_score(y_te,(p_avg>=0.5).astype(int),average=\"weighted\"),\n",
    "       \"ROC_AUC\": roc_auc_score(y_te,p_avg),\n",
    "       \"Brier\": brier_score_loss(y_te,p_avg)}\n",
    "print(\"Ensemble:\", ens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba443596-9d98-4844-9d90-d1d72ab03dca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Away Team  Away Odds             Home Team  Home Odds\n",
      "0   Chicago Blackhawks       3.40      Florida Panthers       1.33\n",
      "1  Pittsburgh Penguins       2.75      New York Rangers       1.50\n",
      "2   Colorado Avalanche       1.90     Los Angeles Kings       1.90\n",
      "3   Montreal Canadiens       2.25   Toronto Maple Leafs       1.66\n",
      "4        Boston Bruins       2.60   Washington Capitals       1.52\n",
      "5       Calgary Flames       2.85       Edmonton Oilers       1.44\n",
      "6    Los Angeles Kings       2.60  Vegas Golden Knights       1.52\n"
     ]
    }
   ],
   "source": [
    "# Betway Scraping\n",
    "with webdriver.Chrome() as driver:\n",
    "    url = \"https://betway.com/en/sports/grp/ice-hockey/north-america/nhl\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Step 2: Extract match odds\n",
    "matches_data = []\n",
    "games = soup.find_all(class_=\"oneLineEventItem\")\n",
    "\n",
    "for game in games:\n",
    "    try:\n",
    "        teams = game.find_all(class_=\"teamNameFirstPart\")\n",
    "        odds = game.find_all(class_=\"odds\")\n",
    "\n",
    "        if len(teams) >= 2 and len(odds) >= 2:\n",
    "            matches_data.append({\n",
    "                \"Away Team\": teams[0].text.strip(),\n",
    "                \"Away Odds\": float(odds[0].text.strip()),\n",
    "                \"Home Team\": teams[1].text.strip(),\n",
    "                \"Home Odds\": float(odds[1].text.strip())\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "\n",
    "df_odds = pd.DataFrame(matches_data)\n",
    "\n",
    "# ---- Team-name normalization (specific to this site) ----\n",
    "# 1) quick alias fixes for common sportsbook abbreviations\n",
    "team_alias = {\n",
    "    \"LA Kings\": \"Los Angeles Kings\",\n",
    "    \"Montréal Canadiens\": \"Montreal Canadiens\",\n",
    "\n",
    "}\n",
    "\n",
    "def apply_alias(name: str) -> str:\n",
    "    name = (name or \"\").strip()\n",
    "    return team_alias.get(name, name)\n",
    "\n",
    "df_odds[\"Home Team\"] = df_odds[\"Home Team\"].apply(apply_alias)\n",
    "df_odds[\"Away Team\"] = df_odds[\"Away Team\"].apply(apply_alias)\n",
    "\n",
    "# 2) optional: fuzzy match to your historical team list if df_final is available\n",
    "try:\n",
    "    from difflib import get_close_matches\n",
    "    teams_known = set(pd.concat([df_final[\"Home Team\"], df_final[\"Away Team\"]]).dropna().unique())\n",
    "\n",
    "    def normalize_team_smart(name: str) -> str:\n",
    "        if name in teams_known:\n",
    "            return name\n",
    "        # find closest known team name if reasonably similar\n",
    "        m = get_close_matches(name, list(teams_known), n=1, cutoff=0.75)\n",
    "        return m[0] if m else name\n",
    "\n",
    "    df_odds[\"Home Team\"] = df_odds[\"Home Team\"].apply(normalize_team_smart)\n",
    "    df_odds[\"Away Team\"] = df_odds[\"Away Team\"].apply(normalize_team_smart)\n",
    "except Exception:\n",
    "    # if df_final isn't defined yet or difflib not available, just skip fuzzy step\n",
    "    pass\n",
    "# ---- end normalization ----\n",
    "\n",
    "print(df_odds)\n",
    "\n",
    "# Step 3: Automated Prediction for All Games\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e7f9c39-f517-410f-829e-4ec807dec136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Team  Rank                 Team Rank\n",
      "0           Winnipeg Jets     1          Winnipeg Jets* 1\n",
      "1     Washington Capitals     2    Washington Capitals* 2\n",
      "2    Vegas Golden Knights     3   Vegas Golden Knights* 3\n",
      "3     Toronto Maple Leafs     4    Toronto Maple Leafs* 4\n",
      "4            Dallas Stars     5           Dallas Stars* 5\n",
      "5       Los Angeles Kings     6      Los Angeles Kings* 6\n",
      "6     Tampa Bay Lightning     7    Tampa Bay Lightning* 7\n",
      "7      Colorado Avalanche     8     Colorado Avalanche* 8\n",
      "8         Edmonton Oilers     9        Edmonton Oilers* 9\n",
      "9     Carolina Hurricanes    10   Carolina Hurricanes* 10\n",
      "10       Florida Panthers    11      Florida Panthers* 11\n",
      "11         Minnesota Wild    12        Minnesota Wild* 12\n",
      "12        Ottawa Senators    13       Ottawa Senators* 13\n",
      "13         Calgary Flames    14         Calgary Flames 14\n",
      "14        St. Louis Blues    15       St. Louis Blues* 15\n",
      "15     Montreal Canadiens    16    Montreal Canadiens* 16\n",
      "16      New Jersey Devils    17     New Jersey Devils* 17\n",
      "17      Vancouver Canucks    18      Vancouver Canucks 18\n",
      "18  Columbus Blue Jackets    19  Columbus Blue Jackets 19\n",
      "19       Utah Hockey Club    20       Utah Hockey Club 20\n",
      "20      Detroit Red Wings    21      Detroit Red Wings 21\n",
      "21       New York Rangers    22       New York Rangers 22\n",
      "22     New York Islanders    23     New York Islanders 23\n",
      "23    Pittsburgh Penguins    24    Pittsburgh Penguins 24\n",
      "24          Anaheim Ducks    25          Anaheim Ducks 25\n",
      "25         Buffalo Sabres    26         Buffalo Sabres 26\n",
      "26          Boston Bruins    27          Boston Bruins 27\n",
      "27         Seattle Kraken    28         Seattle Kraken 28\n",
      "28    Philadelphia Flyers    29    Philadelphia Flyers 29\n",
      "29    Nashville Predators    30    Nashville Predators 30\n",
      "30     Chicago Blackhawks    31     Chicago Blackhawks 31\n",
      "31        San Jose Sharks    32        San Jose Sharks 32\n"
     ]
    }
   ],
   "source": [
    "print(df_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d293965c-875a-40c1-9e52-cfe330c48b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Target slate date set to: 2025-10-11\n",
      "\n",
      "Target date: 2025-10-11 | games found: 16\n",
      "Nearby slates (games per day):\n",
      "  2025-10-10: 0\n",
      "  2025-10-11: 16  (today)\n",
      "  2025-10-12: 1\n",
      "  2025-10-13: 10\n",
      "  2025-10-14: 8\n",
      "\n",
      "Enter AMERICAN odds (e.g., -120, +135).\n",
      "Press Enter to leave a side blank, 's' to skip a game, 'q' to quit.\n",
      "\n",
      "===========================================\n",
      "[1/16]  Los Angeles Kings  @  Winnipeg Jets\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Los Angeles Kings  American odds:  110\n",
      "  (HOME)  Winnipeg Jets  American odds:  -130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================\n",
      "[2/16]  St. Louis Blues  @  Calgary Flames\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  St. Louis Blues  American odds:  -122\n",
      "  (HOME)  Calgary Flames  American odds:  103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "[3/16]  Montreal Canadiens  @  Chicago Blackhawks\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Montreal Canadiens  American odds:  -144\n",
      "  (HOME)  Chicago Blackhawks  American odds:  123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================\n",
      "[4/16]  New York Rangers  @  Pittsburgh Penguins\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  New York Rangers  American odds:  -147\n",
      "  (HOME)  Pittsburgh Penguins  American odds:  125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "[5/16]  Washington Capitals  @  New York Islanders\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Washington Capitals  American odds:  -115\n",
      "  (HOME)  New York Islanders  American odds:  -102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================\n",
      "[6/16]  Philadelphia Flyers  @  Carolina Hurricanes\n",
      "===================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Philadelphia Flyers  American odds:  215\n",
      "  (HOME)  Carolina Hurricanes  American odds:  -263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "[7/16]  New Jersey Devils  @  Tampa Bay Lightning\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  New Jersey Devils  American odds:  121\n",
      "  (HOME)  Tampa Bay Lightning  American odds:  -143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "[8/16]  Toronto Maple Leafs  @  Detroit Red Wings\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Toronto Maple Leafs  American odds:  -154\n",
      "  (HOME)  Detroit Red Wings  American odds:  130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "[9/16]  Buffalo Sabres  @  Boston Bruins\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Buffalo Sabres  American odds:  100\n",
      "  (HOME)  Boston Bruins  American odds:  -118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "[10/16]  Ottawa Senators  @  Florida Panthers\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Ottawa Senators  American odds:  130\n",
      "  (HOME)  Florida Panthers  American odds:  -154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "[11/16]  Utah Hockey Club  @  Nashville Predators\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Utah Hockey Club  American odds:  -115\n",
      "  (HOME)  Nashville Predators  American odds:  -102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "[12/16]  Columbus Blue Jackets  @  Minnesota Wild\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Columbus Blue Jackets  American odds:  140\n",
      "  (HOME)  Minnesota Wild  American odds:  -164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "[13/16]  Dallas Stars  @  Colorado Avalanche\n",
      "============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Dallas Stars  American odds:  113\n",
      "  (HOME)  Colorado Avalanche  American odds:  -133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "[14/16]  Vancouver Canucks  @  Edmonton Oilers\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Vancouver Canucks  American odds:  148\n",
      "  (HOME)  Edmonton Oilers  American odds:  -175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================\n",
      "[15/16]  Anaheim Ducks  @  San Jose Sharks\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Anaheim Ducks  American odds:  -118\n",
      "  (HOME)  San Jose Sharks  American odds:  100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================\n",
      "[16/16]  Vegas Golden Knights  @  Seattle Kraken\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  (AWAY)  Vegas Golden Knights  American odds:  -164\n",
      "  (HOME)  Seattle Kraken  American odds:  140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "✅ Saved 16 matchup(s) with odds to odds.csv\n",
      "\n",
      "Saved rows preview:\n",
      "                 Date            Away Team Away American Odds Away Odds  \\\n",
      "0 2025-10-11 13:30:00    Los Angeles Kings                110       2.1   \n",
      "1 2025-10-11 16:00:00      St. Louis Blues               -122  1.819672   \n",
      "2 2025-10-11 19:00:00   Montreal Canadiens               -144  1.694444   \n",
      "3 2025-10-11 19:00:00     New York Rangers               -147  1.680272   \n",
      "4 2025-10-11 19:00:00  Washington Capitals               -115  1.869565   \n",
      "5 2025-10-11 19:00:00  Philadelphia Flyers                215      3.15   \n",
      "6 2025-10-11 19:00:00    New Jersey Devils                121      2.21   \n",
      "7 2025-10-11 19:00:00  Toronto Maple Leafs               -154  1.649351   \n",
      "8 2025-10-11 19:00:00       Buffalo Sabres                100       2.0   \n",
      "9 2025-10-11 19:00:00      Ottawa Senators                130       2.3   \n",
      "\n",
      "             Home Team Home American Odds Home Odds  \n",
      "0        Winnipeg Jets               -130  1.769231  \n",
      "1       Calgary Flames                103      2.03  \n",
      "2   Chicago Blackhawks                123      2.23  \n",
      "3  Pittsburgh Penguins                125      2.25  \n",
      "4   New York Islanders               -102  1.980392  \n",
      "5  Carolina Hurricanes               -263  1.380228  \n",
      "6  Tampa Bay Lightning               -143  1.699301  \n",
      "7    Detroit Red Wings                130       2.3  \n",
      "8        Boston Bruins               -118  1.847458  \n",
      "9     Florida Panthers               -154  1.649351  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATE_OFFSET = +1\n",
    "TARGET_DATE = (datetime.now() + timedelta(days=DATE_OFFSET)).date()\n",
    "print(f\"📅 Target slate date set to: {TARGET_DATE}\")\n",
    "\n",
    "CSV_PATH = \"odds.csv\"\n",
    "\n",
    "def _strip_accents(s: str) -> str:\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFKD\", str(s)) if not unicodedata.combining(c))\n",
    "\n",
    "def _american_to_decimal(a):\n",
    "    try: a = int(a)\n",
    "    except Exception: return None\n",
    "    if a == 0 or abs(a) < 100 or a == -100: return None\n",
    "    return 1.0 + (a/100.0) if a > 0 else 1.0 + (100.0/abs(a))\n",
    "\n",
    "def _parse_odds(s: str):\n",
    "    if s is None: return (None, None, None)\n",
    "    s = s.strip().lower().replace(\" \", \"\")\n",
    "    if s in {\"s\",\"skip\"}:  return (None, None, \"skip\")\n",
    "    if s in {\"q\",\"quit\"}:  return (None, None, \"quit\")\n",
    "    if \".\" in s or \",\" in s:   # accept decimal as a convenience\n",
    "        try:\n",
    "            dec = float(s.replace(\",\", \".\"))\n",
    "            return (None, dec if dec > 1.01 else None, None)\n",
    "        except Exception:\n",
    "            return (None, None, None)\n",
    "    m = re.fullmatch(r\"([+-]?)(\\d{2,4})\", s)\n",
    "    if not m: return (None, None, None)\n",
    "    sign, num = m.groups(); num = int(num)\n",
    "    american = -num if sign == \"-\" else +num\n",
    "    if american == 0 or abs(american) < 100 or american == -100: return (None, None, None)\n",
    "    return (american, _american_to_decimal(american), None)\n",
    "\n",
    "def _mk_template(df_games, target_date):\n",
    "    g = df_games.copy()\n",
    "    g[\"Date\"] = pd.to_datetime(g[\"Date\"], errors=\"coerce\")\n",
    "    g = g[g[\"Date\"].dt.date == target_date]\n",
    "    out = (g.drop_duplicates(subset=[\"Date\",\"Home Team\",\"Away Team\"])\n",
    "             .loc[:, [\"Date\",\"Away Team\",\"Home Team\"]]\n",
    "             .assign(**{\"Away American Odds\": None, \"Away Odds\": None,\n",
    "                        \"Home American Odds\": None, \"Home Odds\": None})\n",
    "             .loc[:, [\"Date\",\"Away Team\",\"Away American Odds\",\"Away Odds\",\n",
    "                      \"Home Team\",\"Home American Odds\",\"Home Odds\"]]\n",
    "             .reset_index(drop=True))\n",
    "    out[\"Away Team\"] = out[\"Away Team\"].map(_strip_accents)\n",
    "    out[\"Home Team\"] = out[\"Home Team\"].map(_strip_accents)\n",
    "    return out\n",
    "\n",
    "def _slate_counts_nearby(df_games, center_date, span=3):\n",
    "    g = df_games.copy()\n",
    "    g[\"Date\"] = pd.to_datetime(g[\"Date\"], errors=\"coerce\")\n",
    "    counts = []\n",
    "    for delta in range(-1, span+1):\n",
    "        d = center_date + timedelta(days=delta)\n",
    "        n = int((g[\"Date\"].dt.date == d).sum())\n",
    "        counts.append((d, n))\n",
    "    return counts\n",
    "\n",
    "def enter_american_odds(df_games, date_str=None):\n",
    "    target = (pd.to_datetime(date_str).date() if date_str else datetime.now().date())\n",
    "    tmpl = _mk_template(df_games, target)\n",
    "\n",
    "    print(f\"\\nTarget date: {target} | games found: {len(tmpl)}\")\n",
    "    nearby = _slate_counts_nearby(df_games, target, span=3)\n",
    "    print(\"Nearby slates (games per day):\")\n",
    "    for d, n in nearby:\n",
    "        mark = \"  (today)\" if d == target else \"\"\n",
    "        print(f\"  {d}: {n}{mark}\")\n",
    "\n",
    "    if tmpl.empty:\n",
    "        print(\"No games for this date in df_all. Pick another date (e.g., enter_american_odds(df_all, '2025-10-12')).\")\n",
    "        return tmpl  # empty\n",
    "\n",
    "    print(\"\\nEnter AMERICAN odds (e.g., -120, +135).\")\n",
    "    print(\"Press Enter to leave a side blank, 's' to skip a game, 'q' to quit.\\n\")\n",
    "\n",
    "    for i in range(len(tmpl)):\n",
    "        away = tmpl.at[i, \"Away Team\"]\n",
    "        home = tmpl.at[i, \"Home Team\"]\n",
    "        header = f\"[{i+1}/{len(tmpl)}]  {away}  @  {home}\"\n",
    "        print(\"=\"*len(header))\n",
    "        print(header)\n",
    "        print(\"=\"*len(header))\n",
    "\n",
    "        # Away (AWAY TEAM odds)\n",
    "        while True:\n",
    "            a_in = input(f\"  (AWAY)  {away}  American odds: \").strip()\n",
    "            if a_in == \"\":  a_american, a_decimal, cmd = (None, None, None); break\n",
    "            a_american, a_decimal, cmd = _parse_odds(a_in)\n",
    "            if cmd in {\"quit\",\"skip\"} or a_decimal is not None or a_american is None: break\n",
    "            print(\"    -> invalid (try -120, +135, or 1.95)\")\n",
    "        if cmd == \"quit\": break\n",
    "        if cmd == \"skip\": print(\"  skipped game\\n\"); continue\n",
    "\n",
    "        # Home (HOME TEAM odds)\n",
    "        while True:\n",
    "            h_in = input(f\"  (HOME)  {home}  American odds: \").strip()\n",
    "            if h_in == \"\":  h_american, h_decimal, cmd2 = (None, None, None); break\n",
    "            h_american, h_decimal, cmd2 = _parse_odds(h_in)\n",
    "            if cmd2 in {\"quit\",\"skip\"} or h_decimal is not None or h_american is None: break\n",
    "            print(\"    -> invalid (try -120, +135, or 1.95)\")\n",
    "        if cmd2 == \"quit\": break\n",
    "        if cmd2 == \"skip\": print(\"  skipped game\\n\"); continue\n",
    "\n",
    "        tmpl.at[i, \"Away American Odds\"] = a_american\n",
    "        tmpl.at[i, \"Away Odds\"]          = a_decimal\n",
    "        tmpl.at[i, \"Home American Odds\"] = h_american\n",
    "        tmpl.at[i, \"Home Odds\"]          = h_decimal\n",
    "        print()\n",
    "\n",
    "    complete = tmpl.dropna(subset=[\"Away Odds\",\"Home Odds\"]).reset_index(drop=True)\n",
    "    complete.to_csv(CSV_PATH, index=False)\n",
    "    print(f\"\\n✅ Saved {len(complete)} matchup(s) with odds to {CSV_PATH}\")\n",
    "    return complete\n",
    "\n",
    "# ===== RUN =====\n",
    "# Today by default (change to a specific date string if you want):\n",
    "df_odds = enter_american_odds(df_all, TARGET_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print(\"\\nSaved rows preview:\")\n",
    "print(df_odds.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f30bf1f-93fc-4c17-8693-c0ff71605d40",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Odds loaded:\n",
      "             Away Team  Away Odds            Home Team  Home Odds\n",
      "0   Montreal Canadiens       2.13    Detroit Red Wings       1.75\n",
      "1  Philadelphia Flyers       2.70     Florida Panthers       1.50\n",
      "2   New York Islanders       1.75  Pittsburgh Penguins       2.13\n",
      "3      Ottawa Senators       2.43  Tampa Bay Lightning       1.59\n",
      "4     New York Rangers       1.88       Buffalo Sabres       1.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CSV_PATH = \"odds.csv\"   \n",
    "MANUAL_GAMES = [\n",
    "    {\"Away Team\": \"Montreal Canadiens\", \"Away Odds\": 2.13, \"Home Team\": \"Detroit Red Wings\", \"Home Odds\": 1.75},\n",
    "    {\"Away Team\": \"Philadelphia Flyers\",  \"Away Odds\": 2.7, \"Home Team\": \"Florida Panthers\",    \"Home Odds\": 1.5},\n",
    "    {\"Away Team\": \"New York Islanders\",  \"Away Odds\": 1.75, \"Home Team\": \"Pittsburgh Penguins\",    \"Home Odds\": 2.13},\n",
    "    {\"Away Team\": \"Ottawa Senators\",  \"Away Odds\": 2.43, \"Home Team\": \"Tampa Bay Lightning\",    \"Home Odds\": 1.59},\n",
    "    {\"Away Team\": \"New York Rangers\",  \"Away Odds\": 1.88, \"Home Team\": \"Buffalo Sabres\",    \"Home Odds\": 1.97},\n",
    "]\n",
    "\n",
    "\n",
    "_alias = lambda x: x  \n",
    "\n",
    "def _validate_decimal(x) -> float | None:\n",
    "    try:\n",
    "        v = float(str(x).replace(\",\", \".\"))\n",
    "        return v if v > 1.01 else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def load_df_odds() -> pd.DataFrame:\n",
    "    if os.path.exists(CSV_PATH):\n",
    "        df = pd.read_csv(CSV_PATH)\n",
    "    elif MANUAL_GAMES:\n",
    "        df = pd.DataFrame(MANUAL_GAMES)\n",
    "    else:\n",
    "        raise SystemExit(f\"No odds provided. Create {CSV_PATH} or fill MANUAL_GAMES list.\")\n",
    "\n",
    "    required = [\"Away Team\", \"Away Odds\", \"Home Team\", \"Home Odds\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise SystemExit(f\"Missing columns in odds input: {missing}\")\n",
    "\n",
    "    # clean\n",
    "    df[\"Away Team\"] = df[\"Away Team\"].map(_alias)\n",
    "    df[\"Home Team\"] = df[\"Home Team\"].map(_alias)\n",
    "    df[\"Away Odds\"] = df[\"Away Odds\"].map(_validate_decimal)\n",
    "    df[\"Home Odds\"] = df[\"Home Odds\"].map(_validate_decimal)\n",
    "\n",
    "    \n",
    "    bad = df[df[[\"Away Odds\",\"Home Odds\"]].isna().any(axis=1)]\n",
    "    if not bad.empty:\n",
    "        print(f\"⚠️ Dropping {len(bad)} row(s) with invalid odds:\")\n",
    "        print(bad[[\"Away Team\",\"Away Odds\",\"Home Team\",\"Home Odds\"]])\n",
    "\n",
    "    df = df.dropna(subset=[\"Away Team\",\"Home Team\",\"Away Odds\",\"Home Odds\"]).copy()\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_odds = load_df_odds()\n",
    "print(\"✅ Odds loaded:\")\n",
    "print(df_odds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97c88034-7149-4649-b9b9-d43c1e4ab3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date              Away Team  Away Odds            Home Team  \\\n",
      "0   2025-10-10      Los Angeles Kings   2.100000        Winnipeg Jets   \n",
      "1   2025-10-10        St. Louis Blues   1.819672       Calgary Flames   \n",
      "2   2025-10-10     Montreal Canadiens   1.694444   Chicago Blackhawks   \n",
      "3   2025-10-10       New York Rangers   1.680272  Pittsburgh Penguins   \n",
      "4   2025-10-10    Washington Capitals   1.869565   New York Islanders   \n",
      "5   2025-10-10    Philadelphia Flyers   3.150000  Carolina Hurricanes   \n",
      "6   2025-10-10      New Jersey Devils   2.210000  Tampa Bay Lightning   \n",
      "7   2025-10-10    Toronto Maple Leafs   1.649351    Detroit Red Wings   \n",
      "8   2025-10-10         Buffalo Sabres   2.000000        Boston Bruins   \n",
      "9   2025-10-10        Ottawa Senators   2.300000     Florida Panthers   \n",
      "10  2025-10-10       Utah Hockey Club   1.869565  Nashville Predators   \n",
      "11  2025-10-10  Columbus Blue Jackets   2.400000       Minnesota Wild   \n",
      "12  2025-10-10           Dallas Stars   2.130000   Colorado Avalanche   \n",
      "13  2025-10-10      Vancouver Canucks   2.480000      Edmonton Oilers   \n",
      "14  2025-10-10          Anaheim Ducks   1.847458      San Jose Sharks   \n",
      "15  2025-10-10   Vegas Golden Knights   1.609756       Seattle Kraken   \n",
      "\n",
      "    Home Odds  p_home_ens  Home Bet  Away Bet  Scaled  \n",
      "0    1.769231      0.6291        24         0    True  \n",
      "1    2.030000      0.6448        50         0    True  \n",
      "2    2.230000      0.3471         0        26    True  \n",
      "3    2.250000      0.5971        46         0    True  \n",
      "4    1.980392      0.2275         0        85    True  \n",
      "5    1.380228      0.7541        18         0    True  \n",
      "6    1.699301      0.6119         9         0    True  \n",
      "7    2.300000      0.4312         0         0    True  \n",
      "8    1.847458      0.5400         0         0    True  \n",
      "9    1.649351      0.6306        10         0    True  \n",
      "10   1.980392      0.5379        11         0    True  \n",
      "11   1.609756      0.6155         0         0    True  \n",
      "12   1.751880      0.4341         0        30    True  \n",
      "13   1.571429      0.6825        21         0    True  \n",
      "14   2.000000      0.5494        16         0    True  \n",
      "15   2.400000      0.2601         0        52    True  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATE_OFFSET = +1  # 0=today, +1=tomorrow, etc.\n",
    "TARGET_DATE = (datetime.now() + timedelta(days=DATE_OFFSET)).date()\n",
    "\n",
    "# ---- helpers ----\n",
    "def _kelly(p_win: float, dec_odds: float) -> float:\n",
    "    b = dec_odds - 1.0\n",
    "    if b <= 0: return 0.0\n",
    "    q = 1.0 - p_win\n",
    "    return max(0.0, (b * p_win - q) / b)\n",
    "\n",
    "def _assert_sorted(df_hist: pd.DataFrame, date_col: str):\n",
    "    if not df_hist[date_col].is_monotonic_increasing:\n",
    "        df_hist.sort_values(date_col, inplace=True, kind=\"mergesort\")  # stable\n",
    "\n",
    "def _latest_value_asof(df_hist: pd.DataFrame, team: str, col_if_home: str, col_if_away: str,\n",
    "                       as_of_dt: pd.Timestamp, date_col: str):\n",
    "    # filter history strictly before slate day boundary (prevent leakage)\n",
    "    m = (((df_hist[\"Home Team\"] == team) | (df_hist[\"Away Team\"] == team))\n",
    "         & (df_hist[date_col] < as_of_dt))\n",
    "    if not m.any():\n",
    "        raise ValueError(f\"No history for {team} up to {as_of_dt}\")\n",
    "    last = df_hist.loc[m].iloc[-1]\n",
    "    return last[col_if_home] if last[\"Home Team\"] == team else last[col_if_away]\n",
    "\n",
    "def build_features_for_match(home_team, away_team, df_hist, df_rank, as_of_dt, date_col: str):\n",
    "    # ranks with guard\n",
    "    def _rank(team):\n",
    "        r = df_rank.loc[df_rank[\"Team\"] == team, \"Rank\"]\n",
    "        if r.empty:\n",
    "            # fallback: try stripped / alias later if needed\n",
    "            raise ValueError(f\"Rank missing for team: {team}\")\n",
    "        return int(r.iloc[0])\n",
    "\n",
    "    r_home, r_away = _rank(home_team), _rank(away_team)\n",
    "    _assert_sorted(df_hist, date_col)\n",
    "\n",
    "    L = lambda tm, ch, ca: _latest_value_asof(df_hist, tm, ch, ca, as_of_dt, date_col)\n",
    "    feats = {\n",
    "        \"Rank Difference\": r_home - r_away,\n",
    "        \"Last 10 Wins\": L(home_team, \"Home Last 10 Wins\", \"Away Last 10 Wins\") \\\n",
    "                        - L(away_team, \"Away Last 10 Wins\", \"Home Last 10 Wins\"),\n",
    "        \"Home Played Yesterday\": int(bool(L(home_team, \"Home Played Yesterday\", \"Away Played Yesterday\"))),\n",
    "        \"Away Played Yesterday\": int(bool(L(away_team, \"Away Played Yesterday\", \"Home Played Yesterday\"))),\n",
    "        \"Home Advantage\": L(home_team, \"Home Win Rate\", \"Away Win Rate\") \\\n",
    "                          - L(away_team, \"Away Win Rate\", \"Home Win Rate\"),\n",
    "        \"Win Streak Impact\": L(home_team, \"Home Team Overall Win Streak Before Game\", \"Away Team Overall Win Streak Before Game\") \\\n",
    "                             - L(away_team, \"Away Team Overall Win Streak Before Game\", \"Home Team Overall Win Streak Before Game\"),\n",
    "        \"Away Rest Days Since Last Game\": L(away_team, \"Away Rest Days Since Last Game\", \"Home Rest Days Since Last Game\"),\n",
    "        \"Home Rest Days Since Last Game\": L(home_team, \"Home Rest Days Since Last Game\", \"Away Rest Days Since Last Game\"),\n",
    "        \"Opponent Strength\": L(home_team, \"Home Opponent Strength\", \"Away Opponent Strength\") \\\n",
    "                             - L(away_team, \"Away Opponent Strength\", \"Home Opponent Strength\"),\n",
    "    }\n",
    "\n",
    "    row = {rename_map[k]: feats[k] for k in feats if k in rename_map}\n",
    "    X = pd.DataFrame([row])\n",
    "\n",
    "    # IMPORTANT: don't subselect columns for a pipeline; let its selector run\n",
    "    # If you insist, ensure selected_cols is a superset of what the pipeline expects.\n",
    "\n",
    "    return X\n",
    "\n",
    "# ==== PREDICT & SIZE BETS ====\n",
    "# decide which date column your history uses; prefer the one used in training\n",
    "DATE_COL_IN_HISTORY = \"Date\"       # if you saved naive local datetime in df_final\n",
    "# DATE_COL_IN_HISTORY = \"Date_Local\"  # if you kept tz-aware; then pass a tz-aware as_of_dt\n",
    "\n",
    "# slate boundary: all history strictly before midnight of target local day\n",
    "as_of_dt = pd.Timestamp(TARGET_DATE)  # naive local midnight of target day\n",
    "\n",
    "pred_rows, pre_bets, total_pre = [], [], 0.0\n",
    "\n",
    "# (Optional) normalize team names to avoid hidden whitespace mismatches\n",
    "for c in [\"Home Team\", \"Away Team\"]:\n",
    "    df_odds[c] = df_odds[c].astype(str).str.strip()\n",
    "    df_final[c] = df_final[c].astype(str).str.strip()\n",
    "df_rank[\"Team\"] = df_rank[\"Team\"].astype(str).str.strip()\n",
    "\n",
    "for _, r in df_odds.iterrows():\n",
    "    h, a = r[\"Home Team\"], r[\"Away Team\"]\n",
    "\n",
    "    # odds cleaning\n",
    "    try:\n",
    "        oh, oa = float(r[\"Home Odds\"]), float(r[\"Away Odds\"])\n",
    "    except Exception:\n",
    "        # skip rows with missing odds\n",
    "        continue\n",
    "\n",
    "    # build feature row with leakage-safe cutoff\n",
    "    X_one = build_features_for_match(h, a, df_final, df_rank, as_of_dt=as_of_dt, date_col=DATE_COL_IN_HISTORY)\n",
    "\n",
    "    # ensemble prob\n",
    "    p_h = (w_log * log_model.predict_proba(X_one)[:, 1].item()\n",
    "           + w_mlp * mlp_model.predict_proba(X_one)[:, 1].item())\n",
    "\n",
    "    # Kelly stakes (unscaled)\n",
    "    bh_pre, ba_pre = _kelly(p_h, oh) * BANKROLL, _kelly(1.0 - p_h, oa) * BANKROLL\n",
    "    pre_bets.append((bh_pre, ba_pre)); total_pre += bh_pre + ba_pre\n",
    "\n",
    "    pred_rows.append({\n",
    "        \"SlateDate\": TARGET_DATE.isoformat(),\n",
    "        \"Home Team\": h, \"Away Team\": a,\n",
    "        \"Home Odds\": oh, \"Away Odds\": oa,\n",
    "        \"p_home_ens\": round(p_h, 4)\n",
    "    })\n",
    "\n",
    "# scale proportionally if total stake > bankroll\n",
    "for i, row in enumerate(pred_rows):\n",
    "    bh, ba = pre_bets[i]\n",
    "    if total_pre > BANKROLL > 0:\n",
    "        s = BANKROLL / total_pre\n",
    "        bh, ba = bh * s, ba * s\n",
    "        row[\"Scaled\"] = True\n",
    "    else:\n",
    "        row[\"Scaled\"] = False\n",
    "    row[\"Home Bet\"] = int(round(bh)) if bh > 0 else 0\n",
    "    row[\"Away Bet\"] = int(round(ba)) if ba > 0 else 0\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows)\n",
    "cols = [\"SlateDate\",\"Away Team\",\"Away Odds\",\"Home Team\",\"Home Odds\",\"p_home_ens\",\"Home Bet\",\"Away Bet\",\"Scaled\"]\n",
    "print(pred_df[cols])\n",
    "\n",
    "\n",
    "mode = \"a\" if os.path.exists(PREDICTIONS_CSV) else \"w\"\n",
    "header = not os.path.exists(PREDICTIONS_CSV)\n",
    "pred_df.to_csv(PREDICTIONS_CSV, index=False, mode=mode, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c96873f-6600-4d79-b4a0-1b34964c4ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
